[{"content":"One of the themes of my previous Apple Silicon M1 article - Apple Silicon M1: Black. Magic. Fuckery. - was the stupendous battery life offered by the new M1-based MacBooks. While unveiling the M1 chip, Apple touted the new M1-based MacBook Air and MacBook Pro\u0026rsquo;s energy efficiency with up to 18 hours and 20 hours of movie playback, 6 and 10 hours more than previous models.\n  Apple M1 MacBook Pro and MacBook Air battery video playback numbers [Source: Apple]\n    Apple M1 MacBook Air battery improvement [Source: Apple M1 unveiling event]\n    Apple M1 MacBook Pro battery improvement [Source: Apple M1 unveiling event]\n  These battery life advances are massive and typically once-in-a-generation improvements. These are made possible because of Apple\u0026rsquo;s focus on low-power design and decoding video using specialized hardware engines rather than relying on the general-purpose CPU. Decoding video using a chip built for the sole purpose of decoding video can dramatically affect power consumption, as you will see later in this blog.\n  Apple M1 block diagram. Highlighted components are dedicated to low-power video playback [Source: Apple M1 unveiling event]\n  This blog is Part 1 of a multi-part series of investigations into the actual power these M1 chips consume in some of the most common scenarios. This Part 1 focuses on one of the most critical Pandemic activities - streaming a video from YouTube or Netflix. The lower the power consumption, the longer your battery will last (if you\u0026rsquo;re not connected to the charger).\nTesting Methodology Software \u0026amp; Hardware  MacOS 11.2.2 running in safe mode to limit the effect of background processes and other applications on power consumption Safari 14.0.3 Chrome 89 (Apple Silicon version) VLC 3.0.12.1 (Apple Silicon version) Mac Mini M1 16GB RAM, 256GB SSD (I didn\u0026rsquo;t have a MacBook so this test represents the power of the M1 components, not the overall system power) Peripherels attached: Apple Magic Keyboard and Magic Trackpad (Bluetooth)  Power Consumption Measurement Power Consumption was measured using Apple\u0026rsquo;s powermetrics utility. powermetrics is a Mac-only command-line utility that provides many high-quality power-related measurements. It is most useful for getting CPU, GPU and wakeup measurements in a precise and easily scriptable fashion (unlike Activity Monitor and top)\nBelow is a sample log from powermetrics output after running the following command:\nsudo powermetrics -i 1000 --samplers cpu_power,gpu_power -a --hide-cpu-duty-cycle --show-usage-summary --show-extra-power-info -u ~/powerlogs.txt *** Sampled system activity (Thu Feb 11 00:10:50 2021 -0800) (1004.97ms elapsed) *** **** Processor usage **** E-Cluster Power: 14 mW E-Cluster HW active frequency: 1031 MHz E-Cluster HW active residency: 11.15% (600 MHz: 2.8% 972 MHz: 88% 1332 MHz: 2.5% 1704 MHz: 3.0% 2064 MHz: 3.5%) E-Cluster idle residency: 88.85% P-Cluster Power: 16 mW P-Cluster HW active frequency: 712 MHz P-Cluster HW active residency: 2.34% (600 MHz: 90% 828 MHz: .42% 1056 MHz: 1.4% 1284 MHz: 3.0% 1500 MHz: .49% 1728 MHz: .79% 1956 MHz: 1.2% 2184 MHz: .59% 2388 MHz: 1.0% 2592 MHz: 0% 2772 MHz: .40% 2988 MHz: .20% 3096 MHz: 0% 3144 MHz: .20% 3204 MHz: .36%) P-Cluster idle residency: 97.66% ANE Power: 0 mW DRAM Power: 14 mW Clusters Total Power: 30 mW GPU Power: 14 mW Package Power: 99 mW **** GPU usage **** GPU active frequency: 709 MHz GPU active residency: 1.51% (396 MHz: .05% 528 MHz: 0% 720 MHz: 1.5% 924 MHz: 0% 1128 MHz: 0% 1278 MHz: 0%) GPU requested frequency: (396 MHz: 0% 528 MHz: 0% 720 MHz: 1.5% 924 MHz: 0% 1128 MHz: 0% 1278 MHz: 0%) GPU idle residency: 98.49% GPU Power: 14 mW I wrote a custom Python script to parse out these logs and plot the graphs below. For our purpose, I extracted the following fields:\n   Extracted Field Description Represented as     E-Cluster Power Total power consumption of the 4 high-efficiency cores Efficiency Cluster   P-Cluster Power Total power consumption of the 4 high-performance cores Performance Cluster   DRAM Power Power consumption of the embedded RAM DRAM   GPU Power Power consumption of the M1 GPU GPU   Package Power Total power consumption of the M1 chip including the CPU, GPU, DRAM and other components like Thunderbolt and SSD controller, media decoding engines, ISP, Secure Enclave etc. Other    For an overview of the M1 architecture, see Apple\u0026rsquo;s official product page and the press release.\nTest 1: YouTube streaming I tested the following video - \u0026ldquo;Japan in 8K\u0026rdquo; - while streaming from YouTube in Safari, Chrome browsers and VLC players.\n   I included the VLC player in this test to compare against the local playback. VLC currently cannot use the hardware VP9 decoder. Therefore the video is played using the software-based decoder. I also tested Chrome in software-decode mode by forcing the hardware VP9 decoder off using the Chrome flag at chrome://flags/#videotoolbox-vp9-decoding.\nThis gave us the following test matrix:\n   Player Codec Resolution Represented as     VLC (Software) VP9 4K VLC-SW   Chrome (Software) VP9 4K Chrome-SW   Chrome (Hardware) VP9 4K Chrome-HW   Safari (Hardware) VP9 4K Safari-HW    To compare against idle state, there was an idle period of 60 seconds before and after playing the video in both scenarios.\n INFO: The charts are interactive. Here\u0026rsquo;s what you can do:\n Hover over the charts to view the data points. Select and zoom over a specific time period in the line-charts to take a closer look. Single click on a legend item to remove it from the chart. Double-click to isolate it. Double click anywhere on the chart to zoom out   Power Consumption Right off the bat, you can see the difference between the power consumption between hardware decoding and software decoding. Surprisingly, Chrome\u0026rsquo;s power consumption is higher than Safari\u0026rsquo;s while both are decoding hardware decoding of VP9 codec. Looking at the average and total power consumption, I made the following observations:\n Power Consumption for Chrome hardware decoding = 2x Safari hardware decoding ü§® Power Consumption for Chrome software decoding is more efficient than VLC software decoding üßê    Plotly.d3.json(\"./json/plotly-power-total-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-total-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-power-average-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-average-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-power-average-total-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-average-total-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-power-package-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-package-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });  CPU \u0026amp; GPU Usage Looking at the CPU and GPU usage leads to some interesting observations:\n The GPU usage on Safari hardware decoding is nearly 0%. Chrome software decoding uses more of the efficiency cluster than VLC software decoding but less of the performance cluster. The performance cluster usage jumps between 0% and ~50% in the browsers compared whereas it constantly hovers around 50% in software decoding scenarios. (Select and Zoom in on the graphs to take a closer look.)    Plotly.d3.json(\"./json/plotly-usage-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-usage-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-usage-average-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-usage-average-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });  CPU \u0026amp; GPU Frequency Looking at the CPU and GPU usage, I made the following observations:\n In Safari hardware decoding, the GPU frequency is 0 Hz for a sustained period of time. Does this mean the M1 chip can turn the GPU off? This is quite possible because if you look at the Average Power Consumption chart for the same test (Safari hardware decoding), the GPU\u0026rsquo;s average power consumption was 2mw! Let me type that again. Over 4-5 minutes where the Apple M1 chip played a 4K video in Safari browser, the GPU consumed only 2 milliwatts! The average frequencies are almost neck and neck for hardware decoding modes (except GPU) and higher in software decoding modes. With VLC, the GPU is consistently around 715 MHz, even in the idle phase (i.e. video not playing).    Plotly.d3.json(\"./json/plotly-frequency-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-frequency-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-frequency-average-browser.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-frequency-average-browser.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });  Test 2: Netflix streaming For this test, I streamed Queen\u0026rsquo;s Gambit from Netflix in both Safari and Chrome browsers. Just like the last test to compare against the idle state, there was an idle period of 60 seconds before and after playing the video in both scenarios. The footage in this test was played for 60 seconds.\nThe are two interesting parts to Netflix streaming between these browsers:\n Safari can stream in 1080p and 4K, while Chrome is limited to 720p due to hardware-based DRM limitations. Netflix states that to stream in Ultra HD, one needs a device with an Apple T2 Security chip.    Netflix requirements for streaming in Ultra HD on Mac [Source: Netflix]\n  Safari streamed this title in H.265/HEVC codec while Chrome streams in VP9.    Netflix Queen\u0026rsquo;s Gambit streaming on Safari [Source: Netflix]\n    Netflix Queen\u0026rsquo;s Gambit streaming on Chrome [Source: Netflix]\n   INFO: The charts are interactive. Here\u0026rsquo;s what you can do:\n Hover over the charts to view the data points. Select and zoom over a specific time period in the line-charts to take a closer look. Single click on a legend item to remove it from the chart. Double-click to isolate it. Double click anywhere on the chart to zoom out   Power Consumption Overall, both browsers end up being similar in the average and total power consumption numbers.\n  Plotly.d3.json(\"./json/plotly-power-average-total-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-average-total-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });     Plotly.d3.json(\"./json/plotly-power-package-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-package-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });  However, once you dig down into individual components, we notice some interesting details.\n On the M1, the DRAM usage in Safari is really high! It\u0026rsquo;s more than both the CPU clusters. It\u0026rsquo;s most likely because Safari is streaming 1080p vs. Chrome\u0026rsquo;s 720p stream. The \u0026ldquo;Other\u0026rdquo; component is consuming ~2x the power in Safari vs. Chrome. This is most likely due to the T2 chip being leveraged because of hardware DRM implementation. Just like the YouTube test, Chrome seems to be leveraging quite a bit of GPU. It\u0026rsquo;s the component that consumes the most power.    Plotly.d3.json(\"./json/plotly-power-total-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-total-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-power-average-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-power-average-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });  CPU \u0026amp; GPU Usage No surprises looking at the usage charts than what we already gleaned from the power consumption charts i.e. GPU usage in Chrome is much higher.\n  Plotly.d3.json(\"./json/plotly-usage-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-usage-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-usage-average-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-usage-average-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });  CPU \u0026amp; GPU Frequency Some interesting things are going on with the GPU on the frequency charts.\n In Safari, the GPU is clocking up and down (zoom in on the details), while in Chrome, the GPU is constantly running around 710 MHz. The performance cluster runs around 600 Mhz most of the time but has periodic jumps to almost 3.2 GHz (max frequency for the cluster as confirmed by Anandtech).    Plotly.d3.json(\"./json/plotly-frequency-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-frequency-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });    Plotly.d3.json(\"./json/plotly-frequency-average-netflix.json\", function(err, fig) { Plotly.react('.\\/json\\/plotly-frequency-average-netflix.json', fig.data, fig.layout, config = {\"responsive\": true, \"displaylogo\": false, \"modeBarButtonsToRemove\": [\"toggleSpikelines\", \"hoverClosestCartesian\", \"hoverCompareCartesian\", \"select2d\", \"lasso2d\"]}); });  Conclusion Hopefully, that was an insightful look into the M1 power characteristics! Stay tuned for Part 2, where I\u0026rsquo;ll dig into similar details but this time with local playback.\nAlso, I hear Big Sur 11.3 will finally allow Safari to play VP9 files. If it changes any of the numbers here in any meaningful way, I\u0026rsquo;ll update this blog.\nStay tuned for the updates by subscribing to the RSS Feed or the Mailing List\nBuy If you\u0026rsquo;re planning on buying an Apple M1 product, you can support this blog by using my affiliate links below:\nMacBook Air M1 (2020)\n Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 256GB SSD Storage) - Space Gray Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 512GB SSD Storage) - Space Gray Apple MacBook Air with Apple M1 Chip (13-inch, 16GB RAM, 1TB SSD Storage) - Space Gray  MacBook Pro M1 (2020)\n Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 256GB SSD Storage) - Space Gray Apple MacBook Pro with Apple M1 Chip (13-inch, 8GB RAM, 512GB SSD Storage) - Silver Apple MacBook Pro with Apple M1 Chip (13-inch, 16GB RAM, 256GB SSD Storage) - Space Gray   Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/apple-silicon-m1-video-power-consumption-pt-1/","summary":"Apple M1 is an amazingly efficient piece of silicon. How much power do you think it consumes while streaming from YouTube or Netflix? Read on to find out.","title":"Apple Silicon M1 Power Consumption Deep Dive Part 1: Safari vs Chrome"},{"content":"Hello internet friend! If you\u0026rsquo;ve landed here from an internet search hoping to find more info on this Philips monitor, then let me keep it short and save you some time.\n  To support this blog, you can use my affiliate link to buy this monitor - https://amzn.to/3uw7gat\nI\u0026rsquo;m coming up on 6 months of ownership according to my order date above. Now if you want to find out more about why you should buy this monitor, then read on. I\u0026rsquo;m not going to do any technical tests measuing color volume or how bright this monitor get, it\u0026rsquo;s my impressions of using this monitor as my main display everyday i.e. 10+ hours everyday.\nWhat I enjoy IR Sensor Perhaps my favorite feature. I walk away and the monitor turns the display off saving me power. When I get back to the desk, it turns back on. So simple and effective!\nBuilt-in USB-C dock Another of my favorite features! I hook up my MacBook with just a USB-C cable and it acts as both display output and charging cable. Helps with keeping desk free of cable clutter.\n10-bit display This is a true 10-bit display so you get the expanded color range i.e. Billions of Colors I talked about in my Apple M1 color article. If you\u0026rsquo;re doing any sort of photo or video editing, you\u0026rsquo;ll appreciate the expanded color range.\nHeight and Rotation Adjustments The base of the monitor allows height, swivel, tilt and rotation angle adjustments but my favorite is the height adjustment. I usually adjust the height depending on whether I\u0026rsquo;m standing or sitting.\nThin Bezels Thankfully the bezels are pretty thin. Although I don\u0026rsquo;t actively look at them or notice them day-to-day, it still makes the monitor more attractive to look at.\nWhat I wish was included Nothing much really. Sure it could\u0026rsquo;ve included HDR or a higher refresh rate (120Hz) but then I woud\u0026rsquo;ve paid much more than ~$300.\nGotchas Monitor not running at 4K 60 Hz/FPS using the USB-C cable I thought I should mention this because it took me a while to find how to solve this issue when I hooked up my MacBook with a USB-C cable and couldn\u0026rsquo;t 4K60 output.\nTo fix this issue, in your monitor settings OSD, scroll down to \u0026ldquo;USB settings\u0026rdquo; and then change the \u0026ldquo;USB\u0026rdquo; mode to \u0026ldquo;USB 2.0\u0026rdquo;. This should allow 4K60 output instead of 4K30.\nContact Reach out if you have any questions reach out on Twitter (DMs open) - @singhkays\n(DISCLOSURE: This post includes affiliate links. Should you click an affiliate link and make a purchase I may receive a small commission at no extra cost to you.)\n","permalink":"https://singhkays.com/blog/philips-brilliance-27-4k-uhd-p272p7vu/","summary":"Hello internet friend! If you\u0026rsquo;ve landed here from an internet search hoping to find more info on this Philips monitor, then let me keep it short and save you some time.","title":"Philips Brilliance 4K UHD 27\" Monitor Review"},{"content":"Annual reports are part and parcel of every public company\u0026rsquo;s life. It is a document that the public corporations must provide annually to shareholders that describes their operations and financial conditions. In the U.S., companies typically file the Form 10-K with the Securities and Exchange Commission (SEC). One fine day, as I was following the internet rathole, I landed myself on the Netflix investor page for some reason. One thing to understand about these 10-K forms is that these are \u0026hellip;. pretty basic. Imagine being transported back in time from the current beautifully designed web interfaces back to a text-based interface. This is what I was dealing with, and all the reports looked like these fine specimens from Facebook and Amazon.\n Facebook and Amazon 10-K Annual Report filings\n  Then 2002 happened!\nI landed on an Annual Report unlike any I had seen before. And it was not just the 2002 Annual Report - the reports from 2003, 2004, 2005, 2006 were similar! Somebody had actually put a lot of time into designing these ‚ÄºÔ∏è\nHere are my favorite examples.\n2002 What I love about this report is the play on introducing the report as an opening sequence of a movie.\n    2003 2003 report begins with a Netflix-DVD-in-the-mail envelope design - very on-brand! It then plays on movie titles like Edward Scissorhands to explain benefits and features. Then, it ends with an infographic that makes it very easy to digest the annual numbers.\n      2004 The 2004 report continues the tradition of a grand opening. It then uses direct integrations with famous movie characters like Spiderman, Austin Powers, and Frankenstein. This is my favorite report!\n        2005 For the 2005 report, the focus seems to have been on the subscribers. I\u0026rsquo;m not sure if the profile pics are of the subscribers to Netflix at the time, but it\u0026rsquo;s very likely. The now-defunct star-based rating system shows up as a way to represent horizontal bar charts. Somebody really put some serious thought into this design!\n      2006 2006 is the first year when the design was toned down and only a couple of pages worth calling out. This report\u0026rsquo;s theme seems to be the mailbox and a mailbox bar chart that I can only describe as \u0026ldquo;atrocious.\u0026rdquo; What are they trying to do with the shadows? üßêüëÄ\n    2007, 2008, 2009 2007, 2008, and 2009 are basically clones of each other. The design has been reduced to bare bones with only a couple of \u0026ldquo;designed\u0026rdquo; pages before the 10-K form. There are only a few pages worth calling out, but at least the bar charts are sensible and easily readable. üéâ\n      2010-Present Year From 2010 onwards, we\u0026rsquo;re basically back to the SEC template without any \u0026ldquo;designed\u0026rdquo; pages. Not sure what happened to the design team in 2010. ü§∑\nIf anybody knows the answer, please reach out.\n  Link to all Netflix Annual Reports  2002 2003 2004 2005 2006 2007 2008 2009 2010 Others  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/netflix-annual-reports-work-of-art/","summary":"Netflix put some serious design resources into its Annual Reports pre-2010. What changed?","title":"Netflix's Annual Reports (10-Ks) used to be a work of art. What happened?"},{"content":"When most people hear Apple in a sentence, their next thought is likely the color. This is because color has always played an exciting role in Apple\u0026rsquo;s history: from the original Mac to the iMac, from the G3 to the Cube, from Bondi Blue to Snow White. The introduction of color played a vital part in these products' success as it helped create strong visual brand recognition.\nThe prominent use of color no doubt stems from Steve Jobs obsessing over the smallest details. For instance, there was a time when Steve spent 30 minutes picking the perfect shade of gray for the restroom signs! and another time when he insisted on making the circuit board inside the Mac look great. An engineer told him:\n \u0026ldquo;The only thing that matters is how well it works. Nobody is going to see the PC board.\u0026rdquo;\n Jobs response was:\n \u0026ldquo;I want it to be as beautiful as possible, even if it‚Äôs inside the box. A great carpenter isn‚Äôt going to use lousy wood for the back of a cabinet, even though nobody‚Äôs going to see it.\u0026rdquo;\n   iMac G3 in Bondi Blue released in 1998 [Wikipedia]\n  For as long as we\u0026rsquo;ve had TVs, color has been an important metric to judge the display\u0026rsquo;s quality. We\u0026rsquo;ve witnessed technologies such as CRT, Plasma, and LCD compete to display the most life-like color. The newest technology to enter this fray is High Dynamic Range, aka HDR. The aim remains the same i.e. to recreate an image closer to that seen by the human eye. Traditionally, every video has been delivered in an 8-bit specification known as Rec. 709, displaying up to millions of shades of colors. HDR improves upon this by stepping up to 10 or 12-bit standard known as Rec. 2020 or BT.2020, representing 60 times more color combinations with smoother shade gradations aka \u0026ldquo;Billions of colors\u0026rdquo;.\nApple has generally been at the forefront of adopting the latest display technology. Some notable examples include - introducing high-resolution Retina Displays when 1366x768 was a very common resolution for Windows laptops, Shipping 2015 Retina iMacs with 10-bit displays i.e. \u0026ldquo;Billions of colors\u0026rdquo;, Apple TV 4K, which was one of the first consumer devices to support Dolby Vision HDR in 2017, automatic upgrades of HD titles to Dolby Vision for iTunes users - a move that is still unrivaled, iPhone 12 which is the first smartphone to be able to record videos in the Dolby Vision HDR format. Apple also sells Pro Display XDR, that costs upward of ~$5000 and ticks all the right boxes for any professional doing color-accurate work.\nTherefore, with Apple\u0026rsquo;s color pedigree, it was surprising to see that on the M1 device specification page, there is no mention of whether M1 devices can output \u0026ldquo;Billions of colors\u0026rdquo;. In contrast, the Intel-based devices clearly outline this support.\n Specs for the Intel MacBook Pro show that it can output \u0026ldquo;Billions of Colors\u0026rdquo; [Source: Apple Technical Specifications]\n   No mention of \u0026ldquo;Billions of Colors\u0026rdquo; for M1 MacBook [Source: Apple Technical Specifications]\n  EDIT: 1/25/21 - Adding specs for Mac Mini as that\u0026rsquo;s what was tested. The MacBook spec comparison was for apples-to-apples similar device class purposes.\n No mention of \u0026ldquo;Billions of Colors\u0026rdquo; for M1 Mac Mini [Source: Apple Technical Specifications]\n  Even the trusty method of viewing the value in \u0026quot;About this mac\u0026quot; -\u0026gt; \u0026quot;System Report\u0026quot; -\u0026gt; \u0026quot;Graphics/Displays\u0026quot; doesn\u0026rsquo;t show anything. Usually, this would list a value of 30-bit here (i.e. 10-bit per RGB channel). On M1 devices, the below is what you see when connected to an HDR capable display i.e. no mention of whether the M1 Mini is outputting a 10-bit video signal.\n  So I set about testing 10-bit output support myself.\nTest Setup  TV - 2017 Vizio M65-E0 (Display Specifications) Monitor - Philips Brilliance P272P7VU 4K UHD 27\u0026quot; (Display Specifications) 2020 Mac Mini M1 connected through a HDMI cable  Test 1: Connect to HDR TV For this test, I used my trusty 2017 Vizio M65-E0 TV that has a 10-bit panel. I connected the Mac Mini to my Denon AVR-X1300 receiver. The \u0026ldquo;Displays\u0026rdquo; settings on Mac OS immediately gave me an option of enabling HDR.\n  Apple TV HDR test Next, I fired up the Apple TV app. Immediately on the \u0026ldquo;Library\u0026rdquo; tab, I saw another menu item for HDR titles that\u0026rsquo;s not visible when connected to a non-HDR display.\n  Then I used the Apple TV app to play 2017\u0026rsquo;s Wonder Woman and confirmed through the TV info that it received an HDR10 signal.\n  YouTube HDR test Next, I played an HDR video from YouTube on Safari. I confirmed that I could select the HDR formats for this video, and the video was playing in HDR mode using \u0026ldquo;Stats for nerds\u0026rdquo; info. The \u0026ldquo;Color\u0026rdquo; values of smpte2084 (PQ) / bt2020 confirmed that the video was playing in HDR mode.\n    Spears Munsil quantization test I also found a video with an 8-bit and 10-bit quantization artifact test pattern here. When I played this video on the TV, the 10-bit pattern was completely smooth.\nNOTE: In the image below, both 8-bit and 10-bit appear equally banded because of the 8-bit capture from my smartphone. In reality, the 10-bit pattern is completely smooth compared to the 8-bit pattern.\n  Download test video from here\nTest 2: Connect to a 10-bit Monitor At this point, it\u0026rsquo;s clear that the Mac Mini can output an HDR10 signal when connected to an HDR capable display. Next, I explored if it can output a 10-bit signal / Billions of colors to a non-HDR 10-bit display. This was done by connecting to the Philips Brilliance P272P7VU monitor.\n10-bit PSD test The first test was done by displaying a 10-bit PSD file in \u0026ldquo;Preview\u0026rdquo;, which supports 10-bit files. If the M1 outputs a 10-bit signal, then the gradients in the file would be smooth. Opening the file in \u0026ldquo;Preview\u0026rdquo; confirmed the 10-bit output as the test pattern was completely smooth. I also opened the same file in another image viewer called \u0026ldquo;Pixea\u0026rdquo; and observed banding which most likely is because \u0026ldquo;Pixea\u0026rdquo; doesn\u0026rsquo;t support 10-bit files. In the image below, the same file is open in \u0026ldquo;Preview\u0026rdquo; on the left and \u0026ldquo;Pixea\u0026rdquo; on the right.\nNOTE: You might not observe the difference between the two images below as during the upload and publishing this image might get converted to 8-bit. On my machine the left image is completely smooth while the right displays banding.\n  Download the 10-bit PSD file from here\nSpears Munsil quantization test I also ran the \u0026ldquo;Spears Munsil\u0026rdquo; quntaization pattern on this monitor and observed the 10-bit pattern had less banding. I ran the test with the latest version of VLC Player - 3.12.1 that is a native Apple Silicon binary.\n Spears Munsil Quantization Test shows 10-bit pattern has less banding\n  SwitchResX test Using SwitchResX, I confirmed that the display was set to \u0026ldquo;Billions of colors\u0026rdquo; mode i.e. outputting a 10-bit signal.\n  Buy If you\u0026rsquo;re planning on buying an Apple M1 product, you can support this blog by using my affiliate links below:\nMac Mini M1 (2020)\n Apple Mac Mini with Apple M1 Chip (8GB RAM, 256GB SSD Storage) - (2020) Apple Mac Mini with Apple M1 Chip (16GB RAM, 256GB SSD Storage) - (2020) Apple Mac Mini with Apple M1 Chip (16GB RAM, 1TB SSD Storage) - (2020)  MacBook Air M1 (2020)\n Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 256GB SSD Storage) - Space Gray Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 512GB SSD Storage) - Space Gray Apple MacBook Air with Apple M1 Chip (13-inch, 16GB RAM, 1TB SSD Storage) - Space Gray  MacBook Pro M1 (2020)\n Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 256GB SSD Storage) - Space Gray Apple MacBook Pro with Apple M1 Chip (13-inch, 8GB RAM, 512GB SSD Storage) - Silver Apple MacBook Pro with Apple M1 Chip (13-inch, 16GB RAM, 256GB SSD Storage) - Space Gray   Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  (DISCLOSURE: This post includes affiliate links. Should you click an affiliate link and make a purchase I may receive a small commission at no extra cost to you.)\n","permalink":"https://singhkays.com/blog/apple-silicon-m1-hdr-10bit-billion-colors/","summary":"When most people hear Apple in a sentence, their next thought is likely the color. Does Apple Silicon M1 output \u0026ldquo;billion colors\u0026rdquo;?","title":"Apple Silicon M1 supports \"billion of colors\" aka HDR 10-bit output"},{"content":"The Problem With many of us knowledge workers working from home in the COVID-19 era, our trusty Apple MacBook\u0026rsquo;s retina displays often need a bigger friend to take over the display duties. It\u0026rsquo;s no fault of our MacBook\u0026rsquo;s though - this is the tradeoff we make for portability.\nThe problem starts when we start hooking up an external monitor to match the clarity and DPI of the MacBook\u0026rsquo;s retina screen i.e., a 4K or 5K monitor. 4K monitors have only recently become mainstream. Now, the external display can be on par with the retina screens' crispness and clarity. This, though, is the root of the problem. The refresh rate on the MacBook retina displays is 60 Hz, which means the screen updates with new images 60 times each second. A higher refresh rate results in a smoother picture, which is why an iPad Pro screen that refreshes at 120 Hz is smoother to use. To run a 4K monitor at 60 Hz requires the right combination of hardware, cables, and adapters.\nHere are two kinds of problems you might encounter:\n MacBook does not allow you to select a 4K resolution when connected to a 4K monitor MacBook only runs the 4K resolution at 30 Hz aka animations and mouse movement is choppy  To figure out a solution, here\u0026rsquo;s what I recommend.\nStep 1: Check if your MacBook supports 4K resolution The first step is to make sure your MacBook supports outputting 4K signal to an external monitor. The best place to check is on Apple‚Äôs Support website. A search query like the following will usually bring up the correct model.\n apple macbook 13 inch 2016 technical specifications\n NOTE: You‚Äôll need to specify the year and screen size (13, 15, 16 inches etc.) to match your machine.\nThen the supported resolution‚Äôs are usually specified in the ‚ÄúVideo Support‚Äù section. Here are two examples of the 2016 models.\nMacBook 2016\n Graphics and Video Support Intel HD Graphics 515 Dual display and video mirroring: simultaneously supports full native resolution on the built-in display and up to 3840 by 2160 pixels at 30Hz on an external display, both at millions of colors\n MacBook Pro 2016\n Video Support Simultaneously supports full native resolution on the built-in display at millions of colors and: One display with 5120-by-2880 resolution at 60Hz at over a billion colors Up to two displays with 4096-by-2304 resolution at 60Hz at over a billion colors\n Notice the difference above in the bolded text. Both these 2016 models support 4K resolution (3840 by 2160 pixels or higher), but the 2016 MacBook only supports running an external display at 30 Hz. So, this is the first order of business to tackle and find out if your machine can support 4K external display and, more importantly, at 60 Hz.\nStep 2: Make sure you\u0026rsquo;ve got the right adapter In recent MacBook models, Apple has removed the full HDMI ports and replaced them with USB-C Thunderbolt ports that perform video-out duties. This is great if you want to reduce the number of cables because the USB-C cable can also charge the MacBook. Still, the majority of users have legacy type connections i.e. HDMI or Display Port cables. Apple sells a USB-C adapter that lets you plug in an HDMI cable. There are actually two Apple USB-C adapters, and this is where Apple makes it more challenging than it needs to be. Both these adapters look exactly the same as the below image, but only one supports 4K 60Hz.\n Model¬†A2119 is the newest model that supports HDMI 2.0 and up to 4K 60 Hz. Model A1621¬†supports HDMI 1.4b and 4K up to 30 Hz.    If you\u0026rsquo;re using this adapter and seeing only 4K 30Hz resolution options, make sure you\u0026rsquo;ve got the newest model. The model number is written on the adapter but is very faint and small, so you might have to squint üëÄ\n(DISCLOSURE: This post includes affiliate links. Should you click an affiliate link and make a purchase I may receive a small commission at no extra cost to you.)\nOfficial Adapter costs $60-70 If you want to buy the official Apple adapter, it\u0026rsquo;s normally $69.99 on Apple\u0026rsquo;s website but it\u0026rsquo;s going for $61 on Amazon at the time of this writing.\n Apple USB-C Digital AV Multiport Adapter A2119 MUF82AM/A  Third-party adapters for \u0026lt; $20 If the Apple adapter is too expensive, then I\u0026rsquo;d recommend the following third-party adapters. You have to read the fine print on these as some of these only work at 4K 30 Hz. Here are a few recommendations with the first one that personally worked for me:\n CHOETECH USB Type C (Thunderbolt 3 Compatible) to HDMI Adapter Cable Anker USB C to HDMI Adapter (4K@60Hz) Uni USB C to DisplayPort Cable Uni USB C to HDMI Adapter UGREEN USB C to HDMI Cable 4K 60HZ Thunderbolt 3  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn  ","permalink":"https://singhkays.com/blog/4k-60fps-external-monitor-macbook/","summary":"Getting 4K 60 Hz output on a Macbook is more challenging than it needs to be. Here\u0026rsquo;s what to watch out for.","title":"How to get 4K 60 FPS working on an external monitor with Macbooks"},{"content":"I ran into a very weird error today. While trying to automate the deployment for this blog, I needed to replace a string in a file. The internet tutorials [1, 2, 3, 4] told me that sed would be perfect for this job and the following command should work:\nsed -i \u0026#39;s/search_string/replace_string/\u0026#39; filename The Error However, I kept getting tripped up by the following error:\nsed: 1: \u0026#34;i2.html\u0026#34;: command i expects \\ followed by text I spent a bunch of time trying to make sure I escaped the right characters in my strings but the error was persistent! What a nuisance! üò≠\nThe Issue Upon further searching, the issue turns out to be differences in sed on Mac systems vs Linux. As is with every question asked, StackOverflow has an answer. High Performance Mark explains:\n Your Mac does indeed run a BASH shell, but this is more a question of which implementation of sed you are dealing with. On a Mac sed comes from BSD and is subtly different from the sed you might find on a typical Linux box. I suggest you man sed.\n The Fix It turns out that providing the backup extension is required when using the -i switch. chipiik provides the answer that works!\n This works with both GNU and BSD versions of sed:\nsed -i\u0026#39;\u0026#39; -e \u0026#39;s/old_link/new_link/g\u0026#39; * or with backup:\nsed -i\u0026#39;.bak\u0026#39; -e \u0026#39;s/old_link/new_link/g\u0026#39; * Note missing space after -i option! (Necessary for GNU sed)\n Conclusion HowToGeek described it perfectly:\n The sed command is a bit like chess: it takes an hour to learn the basics and a lifetime to master them (or, at least a lot of practice).\n Happy editing!\n","permalink":"https://singhkays.com/blog/sed-error-i-expects-followed-by-text/","summary":"I ran into a very weird error today. While trying to automate the deployment for this blog, I needed to replace a string in a file. The internet tutorials [1, 2, 3, 4] told me that sed would be perfect for this job and the following command should work:\nsed -i \u0026#39;s/search_string/replace_string/\u0026#39; filename The Error However, I kept getting tripped up by the following error:\nsed: 1: \u0026#34;i2.html\u0026#34;: command i expects \\ followed by text I spent a bunch of time trying to make sure I escaped the right characters in my strings but the error was persistent!","title":"Fixing \"sed: command i expects \\ followed by text\" error"},{"content":"The release of Apple M1 Silicon has laid to rest many questions about whether ARM CPUs can go toe-to-toe with the best of the bunch from Intel and AMD. The question now is not whether ARM chips can perform better than Intel/AMD but whether others can build similarly powerful ARM CPUs. Today, companies like Marvell, Ampere and AWS are shipping ARM CPUs that keep getting better with each generation and close to the level of performance of top-end X86 CPUs. It only feels like a matter of time before ARM CPUs will provide tough competition to the X86 CPUs from Intel and AMD. This feels a bit like standing on the Florida coast and watching the first bands of a hurricane arrive. This reminds me of the iconic scene in the movie \u0026ldquo;The Dark Knight Rises\u0026rdquo; when Selina Kyle (Catwoman) tells Bruce Wayne (Batman) that there\u0026rsquo;s a storm (Bane) coming. The full dialogue goes something like:\n Selina Kyle (Catwoman): There\u0026rsquo;s a storm coming, Mr. Wayne. You and your friends better batten down the hatches, because when it hits, you\u0026rsquo;re all gonna wonder how you ever thought you could live so large and leave so little for the rest of us.\n‚ÄîThe Dark Knight Rises (2012)\n If you read between the lines, there are many parallels that you can draw from the characterization in the movie to real life.\n  Batman and Catwoman are frenemies, which is not much different from Intel and AMD\u0026rsquo;s relationship. They are often competitors, just like Batman \u0026amp; Catwoman. Still, they managed to work together once and ship this baby - Intel¬Æ Core i7-8809G - a rare Intel CPU with AMD integrated graphics.\n  Intel has dominated a large part of the CPU market\u0026rsquo;s profits for a very long time. In contrast, everyone else has had to contend with using lower cost as a vector to compete against Intel\u0026rsquo;s hegemony. For e.g. Intel dominates about 95.5% of the server chip market.\n  (SPOILER ALERT) Selina ends up joining up with Bane by giving up Batman. This might be very similar to the rumors that AMD is planning its own ARM CPUs in real life.\nAMD has an M1 competitor in prototype stages, one version with integrated RAM, and one without it\nhe said \u0026quot;almost ready\u0026quot;\nbut -imo- idk\nleak is only a few days old, the chip idk\n\u0026mdash; Mauri QHD (@MauriQHD) November 28, 2020    The King Apple Silicon M1 has taken the CPU market by storm and, in doing so, answered every doubt whether it can compete with the best of the best. The M1 is currently sitting at the top of Geekbench\u0026rsquo;s single-core throne, all while using less power than competing CPUs. The M1 has completely reset the Performance per Watt expectations. It\u0026rsquo;s even more astonishing to think that as Apple has introduced the M1 for only the lowest-end Macs, this is the slowest SoC that Apple will ever make (for Macs). Based on Apple\u0026rsquo;s history of consistently delivering year-over-year performance improvements, the follow-ups to the M1 will likely improve upon the current single-core performance very rapidly. It is not clear whether Intel and AMD have something in the pipeline that could shift the balance back in X86\u0026rsquo;s favor.\nFrom: https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested/2\nHowever, this could change soon.\nA Challenger Emerges   Nuvia is a startup founded in early 2019 that is building an ARM CPU for the server market. The company was founded by John Bruno, Manu Gulati, and Gerard Williams III. They bring a breadth of experience in system engineering and silicon design for more than 20 chips and more than 100 patents. Nuvia\u0026rsquo;s leadership team holds an impressive resume with various architect and leadership roles at Google, Apple, ARM, Broadcom, and AMD (See here for the leadership team\u0026rsquo;s full details). It is quite possible that Nuvia\u0026rsquo;s leadership was involved with the previous Apple Silicon designs and bring with them the ideas and strategies that have made Apple\u0026rsquo;s chips a market-leader.\nHere is more on Nuvia\u0026rsquo;s design goals and philosophy (emphasis on key talking points mine):\n Our focus at NUVIA is to develop an SoC that will deliver industry-leading performance with the highest levels of efficiency, at the same time. To do this, we are creating a server CPU that is built in a new way, with a complete overhaul of the CPU pipeline. Our first-generation CPU, code-named ‚ÄúPhoenix‚Äù will be a custom core based on the ARM architecture and central to our ‚ÄúOrion‚Äù SoC.\n  With X86 solutions claiming most of the market, only a small percentage of niche customers are willing to accept a lower per-core performance, high core count product. Arguably the most successful ARM-based design today is Amazon‚Äôs Graviton. Graviton is a captive design, aimed solely for a limited portion of AWS that values cost over performance. While there will likely be additional growth in this area, the heart of the market clearly demands the highest single-thread performance at TDP and the highest all-core performance at TDP. This is the fastest way to improve Performance/TCO for the most demanding hyperscale customers.\n  While these new entrant‚Äôs products show improvements, they still fall short of disrupting their X86 incumbents. At NUVIA, we are taking a different approach, with a clean-sheet CPU design that will deliver an elegant balance of performance leadership and power efficiency that maximizes memory bandwidth and core utilization. Our solution does not need to add extraneous cores to try and make up for a single-threaded performance deficit. Also, there would be no need to employ marketing-inflated boost clocks that are not achievable in any real-world applications of server SoCs, due to running into TDP constraints. In real-world scenarios, server SoCs are designed to be heavily loaded to make the best use of the capitalized hardware and allocated power and cooling budgets. The optimal solution is one where a workload finishes in the shortest time possible while consuming the least possible power.\n I\u0026rsquo;ve highlighted the key design goals, but the gist of it is that:\n Nuvia is likely working on a custom ARM design like Apple rather than reusing ARM\u0026rsquo;s reference architecture like some other ARM licensees. The goal is the highest single-thread performance possible without the use of boost or turbo clocks.  Testing Methodology Nuvia recently published their findings on how their Phoenix CPU fares against the latest X86 and ARM CPUs. Here are the systems that were tested:\n   Device SoC Process Technology CPU Microarchitecture Frequency     2020 Apple 13\u0026quot; MacBook Pro Intel Core i7 -1068NG7 Intel 10nm Sunny Cove 2.3GHz Base 4.1GHz Boost   2018 Apple 15\u0026quot; MacBook Pro Intel Core i7 - 8750H Intel 14nm Skylake 2.2GHz Base 4.1GHz Boost   2020 Lenovo 14\u0026quot; Flex 5 AMD Ryzen 7 - 4700U TSMC 7nm Zen 2 2.OGHz Base 4.1GHz Boost   Samsung Galaxy S20 Qualcomm Snapdragon 865 TSMC 7nm ARM A77, ARM A55 2.84GHz (xl-A77) 2.42GHz (x3-A77) 1.8GHz (x4-A55)   2020 Apple iPad Pro Apple A12Z Bionic TSMC 7nm Vortex, Tempest 2.5GHz (x4-Vortex) 1.59GHz (x4-Tempest)   Apple iPhone 11 Apple A13 Bionic TSMC 7nm Lightning, Thunder 2.66 GHz (x2- Lightning) 1.73 GHz (x4-Thunder)    The reasons for choosing these CPUs were as follows:\n The devices tested demonstrate the current state of the art from the majority of the major players, both ARM and X86 based platforms. Intel‚Äôs Core i7‚Äì1068NG7 Ice Lake based SoC is the highest performance variant currently available utilizing the new Sunny Cove CPU microarchitecture, based on Intel‚Äôs 10nm process node. We are also assuming that Intel‚Äôs next-generation Ice Lake Server will utilize a CPU core built upon a similar base architecture as Sunny Cove. The Intel Core i7‚Äì8750H is the last generation of the Skylake microarchitecture and is more closely related to the CPU core shipping in today‚Äôs latest Xeon processors. AMD‚Äôs Ryzen 4700U utilizes the latest Zen 2 CPU core on TSMC‚Äôs 7nm process node. AMD uses the same Zen 2 CPU core within the CCX chiplet in the Rome EPYC family of processors. Qualcomm‚Äôs Snapdragon 865 utilizes ARM‚Äôs latest A77 as its performance core and is implemented on TSMC‚Äôs 7nm process node. The latest announced Ampere Altra and Amazon Graviton 2 both use an ARM N1 CPU core that is more closely related to the older A76, and both are built upon TSMC‚Äôs 7nm process node. Lastly, the Apple A13 and A12Z demonstrate the current fastest ARM-based processors, also both built upon TSMC‚Äôs 7nm process node.\n The Results Nuvia released the expected single-core Performance-Per-Watt curve of their upcoming CPU. To get an idea of how this ranks against the M1, I\u0026rsquo;ve added the single-core Geekbench score for M1 based Mac Mini to Nuvia\u0026rsquo;s graph. Nuvia is not disclosing the actual score, just giving estimates for now. The actual scores will be released at a later date. My best estimate based on their current projections is that these are higher than Apple M1\u0026rsquo;s single-core score. Based on the posted graph, I would put the single-core score between 1900 to 2250 range which is about a 10-30% improvement on single-core performance.\n  Nuvia Phoenix CPU performance compared to X86 and ARM CPUs\n  How to read these results? From Nuvia:\n When measured against current products available in-market in the 1W-4.5W power envelope (per core), the Phoenix CPU core performs up to 2X faster than the competition.\n The 2X claim should now change since the results were published in August before the Apple M1 and the Zen 3 launch. These products now have higher single-core performance than the products Nuvia tested.\nNuvia did, however, expect such a scenario:\n We realize the companies we have measured against in these tests are not standing still and will have new products in the market over the next 18 months. That said, we believe that even with significant performance gains (20%+) with new CPU architectures, we will continue to hold a clear position of leadership in performance-per-watt.\n Why is Nuvia focusing on this 1W-4.5W per core power envelope? I\u0026rsquo;ll let Nuvia answer this:\n All current and future flagship server SoCs are power constrained, very much like mobile SoCs. As core count increases, what is not increasing is the TDP. TDPs are likely going to remain in the 250W ‚Äî 300W range, which is the maximum power that can be dissipated in an air-cooled environment in a typical datacenter. As more cores are added, the power allocation per core shrinks significantly. A rough calculation can be made to determine the high and low bounds of the per-core power allocation in servers. We can assume that future flagship SoCs will have a minimum of 64 cores and a maximum of 128 cores. The TDP range is 250W ‚Äî 300W, and the power outside of the CPU can range between 10W ‚Äî 120W depending upon the workload. Taking into consideration these factors, the amount of power that each CPU can be allocated ranges between 1W ‚Äî 4.5W when heavily utilized, as is the case in a datacenter environment.\n Why was Geekbench used instead of an industry standard benchmark like SPEC? Nuvia explains:\n We believe Geekbench 5 is a good starting point, as it consists of a series of modern real-world kernels that include both integer and floating-point workloads. It runs on multiple platforms, including Linux, iOS, Android, and Windows. It also gives us the ability to conduct these tests on commercially available products .‚Ä¶ You may be wondering how we can make the extrapolation from smartphone and client CPU cores to a server core. In our view, there is no meaningful difference. If anything, these environments now deliver incredibly similar characteristics in how they operate.\n As a follow-up, Nuvia posted comparison of testing Geekbench vs SPEC.\nHow is Nuvia\u0026rsquo;s Performance Per Watt projection calculated? From Nuvia:\n NUVIA‚Äôs Phoenix CPU performance is projected using architectural performance modeling techniques consistent with industry-standard practices on future CPU cores.\n Can these early projections be trusted? There\u0026rsquo;s always a risk with early projections. Still, given the team\u0026rsquo;s experience at Nuvia, I\u0026rsquo;m inclined to give them the benefit of the doubt that they know what they\u0026rsquo;re talking about.\nWhy are we talking about a CPU that\u0026rsquo;s not even released? Well, for a couple of reasons:\n  Nobody else developing ARM chips is projecting similar kinds of performance, which makes me question if anyone else is close to achieving similar performance levels on ARM.\n  It is way easier to underpromise and overdeliver. Nuvia could have chosen to keep this a secret and just released the CPU but releasing performance expectations this early in the design cycle sets a public bar they will now be held to.\n Of course, the other side of that argument is that this is good marketing that can drum up investor interest and make it easier to recruit silicon engineers.    Conclusion It\u0026rsquo;s an exciting time to be a technologist! After a decade of incremental improvements in single-core performance, we\u0026rsquo;re starting to see some real focus on single-core performance. I\u0026rsquo;m excited to see what Nuvia brings to the server market and hope we see some of those gains trickle down to the consumer market as well.\nReferences and Sources  Performance Delivered a New Way Performance Delivered a New Way Part 2 ‚Äî Geekbench versus SPEC  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn  ","permalink":"https://singhkays.com/blog/arm-cpu-faster-than-apple-m1/","summary":"The release of Apple M1 Silicon has laid to rest many questions about whether ARM CPUs can go toe-to-toe with the best of the bunch from Intel and AMD. Can others replicate this?","title":"Upcoming ARM Chip That's Faster Than Apple Silicon M1"},{"content":" Black. Magic. Fuckery.\n These are the words used by the user holdagold on reddit to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system\u0026rsquo;s internals very excited like we saw with Zen 3\u0026rsquo;s launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been \u0026ldquo;perfectly fine\u0026rdquo; for the last decade. We\u0026rsquo;ve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call \u0026ldquo;revolutionary\u0026rdquo;.\nBefore we proceed, it\u0026rsquo;s essential to set the context that I\u0026rsquo;ve only used two Apple devices in my entire life - a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a \u0026ldquo;PC/Android Guy\u0026rdquo;, I have to admit what I saw this week is something special. I believe it\u0026rsquo;ll go down as a significant milestone in computing history on par with some industry-defining chips like Intel\u0026rsquo;s 8086, 386, 486, Pentium, Conroe or AMD\u0026rsquo;s K8, Zen, etc. I hope for the return of Moore\u0026rsquo;s law and awakening of the x86 manufacturers from their slumber as this will be the \u0026ldquo;slowest\u0026rdquo; CPU Apple will ever make. As Henry Clay once said,\n Of all human powers operating on the affairs of mankind, none is greater than that of competition.\n This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.\nWhat Apple Launched Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.\n  The first products and price points the M1 will be going into are:\n Mac Mini - $699 MacBook Air 13\u0026quot; - $999 MacBook Pro 13\u0026quot; - $1299  Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:\n On the MacBook Air - up to 18 hours of video on a single charge (up from 12 hours on this year‚Äôs Intel-powered MacBook Air) and offers up to 15 hours of wireless web browsing per charge (up from 11 hours previously) On the MacBook Pro - up to 17 hours of wireless web browsing (up from 10 hours with this year‚Äôs Intel-powered MacBook Pro), and 20 hours of video playback (up from 10 hours before).  To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.\nPerformance must suck when trying to emulate x86 on ARM, right? Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft\u0026rsquo;s struggles in emulating x86 Windows apps on ARM CPUs. Apple\u0026rsquo;s answer might lie in something called TSO, aka. total store ordering as explained by u/Veedrac and and u/ShaidarHaran2 on reddit:\n TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.\nIn contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That\u0026rsquo;s what the hardware toggle is for.\n In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That\u0026rsquo;s on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they\u0026rsquo;re not currently, and so on, x86_64 performance should be very very decent. I\u0026rsquo;m going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it\u0026rsquo;s all said and done, it doesn\u0026rsquo;t take much working backwards to figure where they\u0026rsquo;d need to be, and Gurman said they were aiming for over 50% faster than Intel.\n  EDIT (11/30/2020): Joe Groff, an Apple engineer working on Swift, clarified that TSO is supported on all the cores on the M1 chips.\nThe A12 only supported TSO on the performance cores. The M1 supports it on all cores\n\u0026mdash; Joe Groff (@jckarter) November 26, 2020  Overwhelmingly postive user-reviews There have been numerous professional reviews and YouTube videos enumerating how Apple\u0026rsquo;s new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who\u0026rsquo;s spending their money on them. There have been plenty of real-world experiences that I\u0026rsquo;ve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.\nThe Speed I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards üëè\n\u0026mdash; DHH (@dhh) November 23, 2020  Purchased a new MacBook Air w/ Apple\u0026#39;s M1 chip. Holy crap. Everything is WICKED fast.\nWindows and prompts pop up instantly. Slowdown NEVER happens ‚Äî even w/ numerous apps going. Evernote, always a resources hog for me, is now a non-issue.\nHuge props, Apple. üëç\n\u0026mdash; JP Mangalindan (@JPManga) November 19, 2020  Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.\n\u0026mdash; Blake Scholl üõ´ (@bscholl) November 24, 2020  u/MagneticGray on reddit:\n Definitely don‚Äôt get near one! I have the 12.9‚Äù iPad Pro, new Max iPhone, older 13‚ÄùMBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.\nPeople keep saying this but it‚Äôs eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn‚Äôt even warm to the touch afterwards either.\n u/leach4_pikes on reddit:\n \u0026gt; It\u0026rsquo;s honestly the best purchase I\u0026rsquo;ve made in the last 10 years.\nThis is exactly how I feel. Feels like I\u0026rsquo;m holding a magical device that shouldn\u0026rsquo;t exist. Haven\u0026rsquo;t felt that in a long long time\n u/lawrencejuliano and u/havaloc on reddit:\n I have a 2018 15‚Äù MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it‚Äôs been painful to say the least. It‚Äôs quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I‚Äôve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor‚Äôs resolution.\nIn comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.\nTo say I‚Äôm impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I‚Äôve ever owned. First computer that hasn‚Äôt had some feeling of compromise in a long time.\n Buyers remorse is real u/afelzz and u/WizardSleeveLoverr on reddit:\n I feel so fucking stupid for ordering a Macbook Air in April this year.\n Same. I‚Äôm mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.\n  u/2shizhtzu4u on reddit:\n I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected\n u/kelev on reddit:\n As someone who got an entry level 2020 MBP in June\u0026hellip; fuck.\n u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit:\n cries in 2020 MBP\n 2020 MacBook Air purchased in August :(:(:(\n  Ha my dad is 5 months into his MBP gutted\n  u/mraheem on reddit:\n Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.\n Battery life is insane! I haven‚Äôt plugged in this M1 Mac in almost 2 days. It‚Äôs only half dead. lol. What is this sorcery? üîã Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. pic.twitter.com/FmX5uVKkFd\n\u0026mdash; Computer Clan (üìåNew EpüëÄ) (@thecomputerclan) November 20, 2020  u/askthepoolboy on reddit:\n I unplugged mine yesterday morning at 5:30am. Worked heavily on it throughout the day (lots of tabs open in chrome, video editing in FCPX, watching videos, photo editing in LrC, and testing lots of apps). When I finally shut it down at 10pm last night, I was at 60%. Yesterday was my heaviest use day in a LONG time, and I just couldn\u0026rsquo;t kill it. My 2015 13\u0026quot; MBP would have died around 10am.\n My 2015 still works fine, so I thought the switch would be lackluster. But the M1 is everything people are saying it is. It is just so damn fast and smooth. I\u0026rsquo;ve had a few very minor things happen like Preview locking up once, and Chrome freezing once, but other than that, this thing just flies. I fired up my 2015 this morning to transfer a few files, and it felt painfully slow. It\u0026rsquo;s honestly the best purchase I\u0026rsquo;ve made in the last 10 years. I\u0026rsquo;ve been on it non-stop this morning for 4 hours and my battery is at 94%. It\u0026rsquo;s insane. And in my two days of trying to kill this thing, the fan hasn\u0026rsquo;t turned on once, and it\u0026rsquo;s never gotten warmer than \u0026ldquo;cool to the touch.\u0026rdquo;\n  u/Rogobono on reddit:\n I‚Äôve said it before and I‚Äôll say it again. Owned soooo many laptops over the years, both Mac and Windows. Never have I ever had something like this. I would say the closest would be an iPad but as we all know, certain tasks can be very limited on an iPad.\nThis thing handles everything like a freaking beast and the battery is quite literally an infinity stone at this point. It just blows everything else out of the water. I‚Äôm on day 3/4 right now. Countless hours of browsing, videos, videos in the background, light gaming for about an hour. The dang thing is still at 40%.\nEverything from here on might as well be posted under r/BlackMagicFuckery because it just doesn‚Äôt make sense.\n u/rennarda on reddit:\n I got my M1 MacBook Pro yesterday. I spent the afternoon setting it up, downloading tons of apps, installing Xcode, doing a couple of test builds, syncing all my photo library and letting Photos do its indexing. At no point did the laptop get warm, and was silent throughout. I probably should have got the Air, because it\u0026rsquo;s clear I\u0026rsquo;m not going to stress this enough to get the fans to even kick in.\nAt no point did I plug the laptop in. I did all this on the charge it had from the factory - about 75% when I received it. By the time I was done for the day, it still had about 40% left.\nIt\u0026rsquo;s absolutely magical. It\u0026rsquo;s not iPad level battery, it\u0026rsquo;s way better than even that!\n u/coding9 on reddit:\n I‚Äôm on day 3 with 6+ hours of use. Code compilations, npm installing benchmarks. Still have 63%\n u/Peabo721 on reddit:\n I bought a base pro and the battery is just bananas. I was working on subordinate performance reports in Adobe reader and listening to music with my AirPods today. From 8am to noon I used 14% battery.\n u/Rogobono on reddit:\n It‚Äôs outta the park. For what I use it for, web browsing and videos, it literally will go a week without a charge. I look at the percentage sometimes just to be like, meh, of course it lost 25%, only to see it‚Äôs down 5% after an hour! LMAO it‚Äôs stupid how amazing it is. I thought my iPad Air battery was great before this.\n Silence is Golden or Cool as a Cucumber? u/tapiringaround on reddit:\n I have a dual boot hackintosh running a ryzen 5 3600xt, 32 gb ram, and a Radeon rx 5600xt.\nMy base MacBook Air M1 basically destroys it at everything except gaming. But I don‚Äôt really game on mac anyways. Everything in the ui just feels immediate. Photo editing has worked great. I had it playing 4 4K videos at once and they were all just fine. It got a bit warm but never hot. And it‚Äôs silent unlike my hackintosh that sounds like a jet engine and keeps my office 15¬∞ warmer than the rest of the house.\nI had a new intel MacBook Air in my hands just a month ago that was burning my lap just trying to watch 4K Netflix. I was getting antsy waiting for apple silicon and needed a new laptop. I decided to send it back and just wait and I‚Äôm glad I did. This is a completely different experience.\n u/havaloc on reddit:\n Contrast this to a 2018 i7 Mac mini that I copied 60gb of files from an external hard drive last night. Sounded like a jet engine and was just as warm.\nI\u0026rsquo;ve been using an M1 MacBook Air and it refuses to get warm\u0026hellip;you don\u0026rsquo;t realize what a jump this is until you\u0026rsquo;ve used an M1 in person.\n Transferring data from my 2020 Intel MacBook Pro, to the 2020 M1 MacBook Pro. The Intel is burning hot and the fans are maxed out. M1 is cool and fans don\u0026#39;t even seem to be running. Damn....\n\u0026mdash; Daniel (@ZONEofTECH) November 20, 2020  Is 8 GB RAM on x86 Intel/AMD the same as 8 GB on Apple Silicon M1? I can\u0026rsquo;t believe I\u0026rsquo;m asking this. All my education and experience with technology has taught me that memory is memory. If you run a lot of programs, you need more of it. 16 GB minimum seems to be the default advice these days, with more if you\u0026rsquo;re doing specialist tasks like video editing, compiling code. However, early M1 users' experience like below testing out with 8 GB seems to indicate otherwise.\n  How can this be so? PC usually dies with just 8 GB of RAM trying to use so many apps. There hasn\u0026rsquo;t been much explanation of this, but a couple of posts might offer hints.\nFirst, David Smith, an engineer at Apple, might have some insight into this.\n‚Ä¶and ~14 nanoseconds on an M1 emulating an Intel üòá\n\u0026mdash; David Smith (@Catfish_Man) November 10, 2020  Second, John Gruber on Daring Fireball explains how this helps explain iPhone like RAM management that seems to be now possible on Macs.\n Retain and release are tiny actions that almost all software, on all Apple platforms, does all the time. \u0026hellip;.. The Apple Silicon system architecture is designed to make these operations as fast as possible. It‚Äôs not so much that Intel‚Äôs x86 architecture is a bad fit for Apple‚Äôs software frameworks, as that Apple Silicon is designed to be a bespoke fit for it \u0026hellip;. retaining and releasing NSObjects is so common on MacOS (and iOS), that making it 5 times faster on Apple Silicon than on Intel has profound implications on everything from performance to battery life.\nBroadly speaking, this is a significant reason why M1 Macs are more efficient with less RAM than Intel Macs. This, in a nutshell, helps explain why iPhones run rings around even flagship Android phones, even though iPhones have significantly less RAM. iOS software uses reference counting for memory management, running on silicon optimized to make reference counting as efficient as possible; Android software uses garbage collection for memory management, a technique that requires more RAM to achieve equivalent performance.\n Third, Marcel Weiher explains Apple\u0026rsquo;s obsession about keeping memory consumption under control from his time at Apple as well as the benefits of reference counting:\n where Apple might have been \u0026ldquo;focused\u0026rdquo; on performance for the last 15 years or so, they have been completely anal about memory consumption. When I was there, we were fixing 32 byte memory leaks. Leaks that happened once. So not an ongoing consumption of 32 bytes again and again, but a one-time leak of 32 bytes.\n  The benefit of sticking to RC is much-reduced memory consumption. It turns out that for a tracing GC to achieve performance comparable with manual allocation, it needs several times the memory (different studies find different overheads, but at least 4x is a conservative lower bound). While I haven\u0026rsquo;t seen a study comparing RC, my personal experience is that the overhead is much lower, much more predictable, and can usually be driven down with little additional effort if needed.\n Fourth, the memory bandwidth might have a role to play in enabling that multi-tasking\n The memory bandwidth on the new Macs is impressive. Benchmarks peg it at around 60GB/sec‚Äìabout 3x faster than a 16‚Äù MBP. Since the M1 CPU only has 16GB of RAM, it can replace the entire contents of RAM 4 times every second. Think about that‚Ä¶\n Pushing the performance boundries at previously unseen price-points Perhaps the most striking feature of these M1 Macs is the value they bring at the sub-$1000 price point (base models). A task like editing 8K RAW RED video file that might have taken a $5000 machine before can now be done on a $699 Mac Mini M1 or a fan-less MacBook Air that costs $999 ü§Ø\n   To those who are still doubting the M1 Macs, imagine if Apple launched a new MacBook Air at the same $999 starting price that came with a Core i7 10750H and RX 560 graphics, but they did it without a fan and added 6 hours more battery life. That‚Äôs basically what they did ü§Ø\n\u0026mdash; Luke Miani (@LukeMiani) November 21, 2020  Apple M1 perf pr0n:\nI compiled all the @libretro cores for comparison:\nMy 2019 12-core Mac Pro with 32GB RAM took 6095.13 seconds.\nMy 13‚Äù M1 MacBook Pro with 16GB ram took‚Ä¶. Wait for it‚Ä¶. 4570.09.\nIf you build code, there is nothing to think about. Get one of these Now!\n\u0026mdash; Lemont (@cocoalabs) November 21, 2020  I tried to build a fresh React Native on the new Apple MBA with M1 / 16GB ram. Cache cleaned.\nIt took 25s.\nTo compare, the same task, executed in exactly the same conditions, on my MBP (13\u0026quot;, 2018, Core i5 2,3GHz, 16GB ram) took‚Ä¶ 1min21s.\n‚Ä¶and without any fan noise ü§Ø pic.twitter.com/DlT7KdehoV\n\u0026mdash; Mathieu A. (@zoontek) November 19, 2020  I don\u0026#39;t think people have *really* understood what @Apple has achieved with their latest M1 chips. The MacBook Air ($999) now:\n-outperforms the latest 16\u0026quot; highest-end model ($3-5K)\n-opens hundreds of Chrome tabs with no issues\n-runs all apps seamlessly without any fans/heating\n\u0026mdash; Ayush Sharma (@ayushswrites) November 21, 2020  Quick Minecraft test... even the MacBook Air running at 10 watts, without a fan, through a translation layer, is running 60fps at native res without getting warm at all. Apple Silicon is nuts lol pic.twitter.com/qpBjCBMv4l\n\u0026mdash; Luke Miani (@LukeMiani) November 21, 2020  Apple M1 ü§ØüöÄ pic.twitter.com/REskldpMap\n\u0026mdash; Mustafa Al Marzooq (@Memo_AlMarzooq) November 18, 2020  Even something as benign as switching the display resolution is faster. I don\u0026rsquo;t know who needed it to be faster but I guess it\u0026rsquo;s the side-effect you get from all that integration üòÇ\nChanging the scaled display resolution on the new #AppleM1 MacBook (left) is absolutely instantaneous üî• compared to the delay and screen blanking required by the Intel graphics on the 16 inch MacBook Pro (right) pic.twitter.com/YybbPF09TF\n\u0026mdash; Daniel Eran Dilger (@DanielEran) November 20, 2020  Server applications will see an uptake on ARM as well With AWS actively developing its own ARM processors (Graviton), it\u0026rsquo;s only a matter of time before the other cloud providers (Azure, Google, Oracle) will follow. Out of the other three, Oracle seems to have the lead with publicly documented plans to bring ARM processors into the mix (FULL DISCLOSURE: I work for Oracle Cloud at the time of writing this blog have no knowledge of the plans around this product). I have a hunch that Google and Azure have plans to compete with AWS because of the scale on which the cloud providers operate; building your own processor is a no-brainer for cost and power efficiencies. It was then interesting to see this comment from ajsfoux234 on Hacker News in one of the discussion threads, as I believe it points to upcoming developer fervor and acceptance for ARM CPUs.\n In my small universe, this was the week of ARM. I submitted multiple PRs to OS projects to get ARM compilations working. I started moving AWS instances off of Intel instances to the new Graviton2 instances.\n A lot of old laptops that are \u0026ldquo;still working\u0026rdquo; are about to get replaced Long gone are the days of meaningful year-over-year increases in performance for CPUs. For the past 6-7 years, the best we get is a single-digit increase. Intel\u0026rsquo;s 10nm node delays are well documented. A node that was once slated to ship in 2015 (!!) finally rolled out to mobile CPU in 2020 and is still missing on the desktop SKUs. This has meant that the incentive to upgrade to the latest CPUs is absent. I personally am perfectly happy running my Core i7 4790K from 2014. On the portable side, the same has generally been confirmed for an everyday user who mainly browses the web, edits documents, and streams Netflix. I have a Mid-2013 MacBook Air that still does the job! So it\u0026rsquo;s no surprise to find so many examples of other users in the same boat. But what is surprising is that many of them are finally considering upgrading.\nPerhaps the most extreme example of \u0026ldquo;it still works\u0026rdquo; :) from u/TctclBacon on reddit:\n I still daily drive my 2005 PowerBook G4 1.5 15\u0026quot;. Maybe it\u0026rsquo;s time for an upgrade\u0026hellip;\n u/Darius_AMS on reddit:\n I\u0026rsquo;ve been using the same shitty windows laptop for ten years. Time to get an upgrade. M1 ftw\n u/mikezer0 on reddit:\n Can‚Äôt wait to replace my almost 8 year old MacBook Air and which is still supported with a new 2020 M1. This is the moment I‚Äôve been waiting for!\n u/siffis on reddit:\n Dammit. Dont need this!!! I keep telling myself. Running a MBP mid 2012.\nImpressive. Definitely wanted to see real world use cases before I take the plunge.\n For coding I am still using a 2012 16GB retina MacBook Pro.\nI almost switched to an 16\u0026quot; i9 MBP last year, but thankfully decided to hold out for the ARM64 transition.\nI made that mistake in 1990, buying a $10K Mac IIfx then a 68040 Quadra 900 less than a year later.\n\u0026mdash; John Brooks (@JBrooksBSI) November 20, 2020  Hackintoshers are ready to say \u0026ldquo;Yes\u0026rdquo; With Apple switching to its own silicon and ending support for x86, the writing is on the wall for the Hackintosh community. These are an exceptionally inventive group of individuals, so there\u0026rsquo;s hope something might be figured out, though! Given that Hackintoshers are a particular bunch who don\u0026rsquo;t take kindly to the Apple-tax, I was astonished to find some of them contemplating making it \u0026ldquo;Official\u0026rdquo; ü§î\nu/themacmeister on reddit\n After seeing the ridiculous performance and thermals of the new M1 chips, I am ready to update once I tire of Mojave :-)\n u/TheGrandFree on reddit\n Probably once these M1 chips hit 2nd gen and i see decent figures for the 16‚Äù i probably will. I do music and honestly a hackintosh isn‚Äôt the best for running a commercial studio space\n u/DoctorTurbo and u/Akhilv1 on reddit:\n I personally went down the Hack route because I wanted a windows machine for gaming/engineering but also wanted to replace my 2014 15‚Äù MacBook Pro for everyday use and Final Cut Pro. I couldn‚Äôt really justify spending $4000 for both computers, so I made the choice of getting a decent desktop and making sure I could make a hackintosh out of it.\nSeeing the performance of these M1 chips though may convince me to get something like a Mac mini for my everyday usage since it‚Äôs also plenty capable of any video editing I would throw at it.\n I\u0026rsquo;m in you\u0026rsquo;re same situation, and ended up pulling the trigger on an M1 Macbooks to replace my 2015 15\u0026quot; Macbook Pro.\nSo far, seems like a good combo\n  u/BrodyBuster on reddit:\n I sold my hack today and decided to pick up the mini. We‚Äôll see if I made the right choice.\n u/accuratecopy on reddit:\n Quitting hackintosh next week waiting for my Mac Mini M1 16/512 to arrive.\nWorking in web and iOS development. My hackintosh will become an unRAID server. I will give My MacBook Pro 2018 to my girlfriend. I will change my Mac Mini M1 with the next MacBook Pro 16 with Apple Silicon.\n u/ksandbergfl on reddit:\n I\u0026rsquo;m thinking of getting myself the MacBook Air M1 for Christmas\u0026hellip; no particular reason, I just think I would like it more than my old Ivy Bridge Hackintosh laptop\n Windows laptops might lose potential buyers u/theodorr and u/Sluisifer on reddit:\n Lol I was pulling my hairs out trying to buy a decent AMD Ryzen 4000 laptop in my region - portable, good battery, good glossy screen, decent price, premium build quality but this just demolishes everything I\u0026rsquo;ve found. Can\u0026rsquo;t wait for mine to arrive!\n 100% same situation. I had looked at macbooks a while ago and was entirely unimpressed, so looking for a cheap-ish ryzen 4000 machine. I did buy one a couple weeks ago, but just returned it.\nFirst Apple product I\u0026rsquo;ll buy in a hair over a decade.\n  No doubt there will be other users who\u0026rsquo;ll look at the performance and battery the Macbook Air can deliver at the $999 price point and not find anything comparable in the PC space. Either the Dells, HPs, and Lenovos will have to drop the price of their premium ultra-books or pressure Intel and AMD to come up with something equally compelling. Either way, the competition can only be good for consumers.\nWhich brings us to: What have others been doing all this time? With such a leap in performance/battery life/heat output/value for money etc., it\u0026rsquo;s natural to ask questions of what other chip makers have been up to and how they will respond.\nChaim Gartenberg, The Verge:\n The conversation has flipped instantly: it‚Äôs no longer ‚Äúwhy would you take a gamble on Apple‚Äôs new, unproven processor‚Äù but ‚Äúhow will competitors like Intel, AMD, and Qualcomm respond?‚Äù\nFor years, Intel and AMD have been playing a chess match, sniping back and forth with improvements in CPU performance, battery life, and onboard graphics. Apple appears to be playing an entirely different game on an entirely different level. The same interplay between hardware and software that has led to such huge successes on the iPhone and iPad has now come to the Mac.\nThe most exciting ‚Äî or frightening, if you‚Äôre a traditional PC chip company ‚Äî part of Apple‚Äôs new chips is that the M1 is just the starting point. It‚Äôs Apple‚Äôs first-generation processor, designed to replace the chips in Apple‚Äôs weakest, cheapest laptops and desktops. Imagine what Apple‚Äôs laptops might do if the company can replicate that success on its high-end laptops and desktops or after a few more years of maturation for the M-series lineup.\nBut when a $1,000 M1 laptop can outdo a maxed-out, $6,000 MacBook Pro with quadruple the RAM and Intel‚Äôs best chip, while also running cooler and quieter in a smaller and lighter form factor and with twice the battery life, where do competitors even go from here?\n Dieter Bohn, The Verge:\n It‚Äôs not difficult to divine the future of Intel and even Qualcomm‚Äôs roadmap ‚Äî they are consistent (and consistently dull) in their year-over-year improvements. Their customers are phone and laptop makers, so they need to be clear and transparent about what‚Äôs up. And I don‚Äôt see either pulling a step change like the M1 out of a hat.\n\u0026hellip;.PC makers have a problem today. So let‚Äôs come back to right now. Apple has a thousand-dollar laptop that beats the pants off anything else in its price class, and so every Windows ultrabook is going to be compared to it for the foreseeable future ‚Äî and may likely be found wanting.\n Walt Mossberg on The Vergecast:\n So in my use of this, I think the single thing that has impressed me most, the battery life has impressed me. I‚Äôve not plugged this in in about 36 hours, and I have 75 percent battery life. So that‚Äôs fantastic. It‚Äôs buttery smooth. It‚Äôs fast as can be.\nBut the thing that really impresses me is their translation layer. This thing called Rosetta 2. They had a Rosetta when they made another processor change some years ago. And what it does is it takes apps that have not been written for this processor that were written for the Intel ‚Äî which is most of the third-party apps so far ‚Äî and it runs them. And I got to tell you, they run fast. They run normally. I mean, fast. If you were doing a blind test and you didn‚Äôt know this was originally written for Intel, still written for Intel, and it was running through this Rosetta thing, you would never know it.\n MOAR user-reviews! u/holdagold on reddit:\n I bought airbook M1 yesterday. Charged it once, sitting at 90% now.\nTried some games, played Wow classic for a bit - graphical settings at 10/10, 55-60 stable fps.\nBlack. Magic. Fuckery.\n u/TheBrainwasher14 on reddit:\n Bro I just borrowed my girlfriend‚Äôs M1 MacBook Air fresh off a charge, used it full brightness for 2 hours, and it was only at 90%. My MBP would be dead with the same use. It‚Äôs un fucking believable.\nThere cannot be enough hype for something like this. This will change the computing industry.\n u/thefourthchime on reddit:\n FWIW: I picked up a M1 Macbook Pro base today, 256gb disk, 8gb RAM. I did have one bad slowdown today. It seemed like Apple\u0026rsquo;s photos app was doing something in the background and ate 3GB of RAM. I rebooted and it\u0026rsquo;s been fine since.\nIn general, the performance has been bonkers good. I\u0026rsquo;m a cloud developer. I needed VSCode, brew, serverless, and python 3 w/ boto3. All not supported on A1, but it didn\u0026rsquo;t matter. They all ran about as well as they do on my 2019 MBP. All this and I\u0026rsquo;m running Evernote, slack, and a billion chrome tabs. With 8GB of ram, it says it\u0026rsquo;s using 6.5GB. I suspect plenty is swapped away, but it\u0026rsquo;s so fast, who cares. Note that Evernote and Slack are slow piggy apps, they run fine.\nThey seem a bit slow, but that\u0026rsquo;s just because it just blows through everything else. Especially web browsing. I\u0026rsquo;m using chrome (I can\u0026rsquo;t get into safari) and it\u0026rsquo;s insanely fast. I feel like my internet speed doubled.\nI took it off the charger around 2pm, it\u0026rsquo;s 7pm. I\u0026rsquo;ve been installing stuff left and right, watching videos, it\u0026rsquo;s 7pm now and I\u0026rsquo;m at 58%. Now that I have most things I needed installed, it seems to barely use any battery at all.\nIt\u0026rsquo;s what they promised, it\u0026rsquo;s just amazing.\n Buy If you\u0026rsquo;re planning on buying an Apple M1 product, you can support this blog by using my affiliate links below:\nMac Mini M1 (2020)\n Apple Mac Mini with Apple M1 Chip (8GB RAM, 256GB SSD Storage) - (2020) Apple Mac Mini with Apple M1 Chip (16GB RAM, 256GB SSD Storage) - (2020) Apple Mac Mini with Apple M1 Chip (16GB RAM, 1TB SSD Storage) - (2020)  MacBook Air M1 (2020)\n Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 256GB SSD Storage) - Space Gray Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 512GB SSD Storage) - Space Gray Apple MacBook Air with Apple M1 Chip (13-inch, 16GB RAM, 1TB SSD Storage) - Space Gray  MacBook Pro M1 (2020)\n Apple MacBook Air with Apple M1 Chip (13-inch, 8GB RAM, 256GB SSD Storage) - Space Gray Apple MacBook Pro with Apple M1 Chip (13-inch, 8GB RAM, 512GB SSD Storage) - Silver Apple MacBook Pro with Apple M1 Chip (13-inch, 16GB RAM, 256GB SSD Storage) - Space Gray   Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/apple-silicon-m1-black-magic/","summary":"These are the words used by the user \u003ca href=\"https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/\"\u003eholdagold on reddit\u003c/a\u003e to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week.","title":"Apple Silicon M1: Black. Magic. Fuckery."},{"content":"Earlier this year, when Spotify announced that \u0026ldquo;The Joe Rogan Experience\u0026rdquo; would stream exclusively on Spotify, it sent shockwaves throughout the podcast ecosystem. This deal \u0026ndash; reportedly worth over $100 million \u0026ndash; is one of the most lucrative podcast deals. The presence of this deal, let alone the magnitude, is rare for the podcast ecosystem, which is built on open principles i.e. all podcasts are available everywhere. Therefore, the concept of exclusivity does not exist in the vocabulary of podcast listeners nor podcast creators. For Spotify to spend a considerable sum of money on a medium that is not its core business (i.e. music) represents a significant shift in strategy. In this blog, I explore why Spotify is embarking on this journey, and the value Spotify can deliver in this space.\nUnexpected Competition To understand this sudden shift in strategy, we need to understand the current state of the podcast industry. According to Statista,\n Back in 2006, only 22 percent of the adult population in the United States was aware of podcasting. By 2020, this figure had risen to 75 percent. Podcasting is an increasingly popular pastime in the US, and there were an estimated 88 million podcast listeners in the country in 2019. Forecasts suggest that the number of podcast listeners will surpass 160 million in 2023 after increases of around 20 million each year.\n When consumers are not in Spotify\u0026rsquo;s app listening to music, they are listening to podcasts in a different app. This represents a threat to Spotify\u0026rsquo;s ad-supported free product and a loss of ad-revenue from its free users (Spotify\u0026rsquo;s premium product is not affected by this because the subscription cost per user is fixed regardless of listening time). To serve relevant ads and, in return, increase its CPM for advertisers, Spotify needs to know its users intimately. This means that Spotify needs its users to spend as much of their digital lives as possible in its walled garden. The quickest way for Spotify to enable this is to build a podcast streaming capability and stream all available podcasts through its music app. This is precisely what Spotify started doing in 2018. Since then, Spotify has quickly ramped up the number of podcast titles available on its platform with increasing engagement every quarter.\nHow Podcasts Work It is important to understand the open podcast ecosystem before moving forward. Podcasts are delivered through a technology called RSS (Rich Site Summary). If you\u0026rsquo;ve seen this icon on the internet before, then you have come across an RSS feed.\n  RSS Icon\n  An RSS feed acts as a content-distribution tool and is often used by websites to distribute web content such as new articles, blogs, and podcasts. It is an XML file that holds metadata and location of the podcast content, which in most cases, is the audio file.\nThe publisher sets up a public RSS feed URL which is used by the listener in a podcast player to subscribe to the podcast i.e. the podcast player downloads new episodes as they are published. Of course, in modern times, any capable podcast app indexes the most popular podcasts and provides users with search functionality to discover the podcasts rather than inputting podcast URLs. Notice the beauty of this ecosystem because both sides of this publisher-listener transaction are open. On the publisher side, the podcast feed URL is available publicly without any authentication to be consumed by anybody who understands the XML structure of the feed. On the listener side, the listener is free to use their favorite podcast player (there are many out there\u0026hellip;maybe too many üòÑ). The downside to this open nature of the ecosystem is that it creates challenges for measurement and monetization as we\u0026rsquo;ll see in the rest of this article.\nSpotify\u0026rsquo;s Business Model Spotify made it possible for anyone to pay $10 a month and have access to almost any song ever released! By doing so, Spotify might have single-handedly solved the piracy problem for the music industry and proved a business model exists where consumers will pay for music. Buoyed by Spotify\u0026rsquo;s success, major giants like Apple, Amazon \u0026amp; Microsoft, and many others have tried to replicate Spotify\u0026rsquo;s strategy \u0026ndash; albeit to varying degrees of success.\n   Source: https://www.statista.com/chart/20826/music-streaming-services-with-most-subscribers-global-fipp/)\n  Spotify has built an impressive business model in a crowded market despite being a late entrant in the music streaming business. Pandora, which once was the darling of the industry, has been continually losing users to Spotify. Pandora, which rose to prominence by helping users discover new music through its recommendation algorithm, was always marred by two fundamental limitations \u0026ndash; limited catalog and a limited number of song skips due to licensing restrictions. In comparison, Spotify offered unlimited song skips and a bigger catalog in its free tier and was able to get many users to switch from Pandora. These free users would later go on to become Spotify\u0026rsquo;s paying users as Spotify delivered better value in its premium product and added restrictions on its free plan (restricted song skips on mobile apps etc.) The chart below is evidence of what happened next. Pandora has been consistently losing users, while Spotify now almost has three times the number of Monthly-Active-Users (MAUs) as Pandora.\nToday, Spotify is seeing increased growth quarter-over-quarter in both its ad-free and premium products with most of its revenue coming from its premium product.\nSpotify\u0026rsquo;s Podcast Investments 2019 was a year that really set the foundations for Spotify\u0026rsquo;s podcast strategy. Spotify spent nearly $500 million in acquiring \u0026ndash; Anchor, Gimlet Media, and Parcast/Cutler Media. Anchor, which bills itself as \u0026ldquo;The easiest way to make a podcast\u0026rdquo;, supplies tools that make it easy for podcasters to create, distribute and monetize podcasts. Gimlet and Parcast, on the other hand, produce some of the most popular podcasts out there, such as StartUp, Reply All, Homecoming, Mogul, Serial Killers, Unsolved Murders, Cults and Conspiracy Theories and many more.\nWith these acquisitions, Spotify is pivoting into an \u0026ldquo;Audio\u0026rdquo; company \u0026ndash; and no longer a music-only company. Here is what Spotify CEO Daniel Ek had to say about these acquisitions in his essay titled \u0026ldquo;Audio-First\u0026rdquo;:\n That\u0026rsquo;s why we announced today the strategic acquisitions of two podcasting companies, Gimlet and Anchor. These companies serve two different, distinct roles in the industry. Gimlet is one of the best content creators in the world, with unique, celebrated podcast shows like Homecoming, which was recently adapted into a critically acclaimed show on Amazon Prime, and the internet culture hit Reply All. And Anchor has completely reimagined the path to audio creation, enabling creation for the next generation of podcasters worldwide \u0026ndash; 15 billion hours of content on the platform during Q4. These companies are best-in-class, and together we will offer differentiated and original content. Gimlet and Anchor will position us to become the leading platform for podcast creators around the world and the leading producer of podcasts.\n These acquisitions play in different parts of the podcast ecosystem but help Spotify cater to both sides of the podcast ecosystem \u0026ndash; producers and listeners. Spotify believes it can extract value from the podcast ecosystem in a way no one has been able to do until now. An indicator of the importance of the podcast strategy to Spotify\u0026rsquo;s business can be judged by the number of mentions of the word \u0026ldquo;podcast\u0026rdquo; in its recent quarterly earnings releases.\nSo far, 2020 is turning out to be another podcast investment year for Spotify. There\u0026rsquo;s a good reason why Spotify has spent close to a billion dollars on signing exclusive deals and buying podcast studios. From the Q4 2019 quarterly report:\n We continue to see exponential growth in podcast hours streamed (up approximately 200% Y/Y) and are now seeing clear indications that podcast usage is driving increased overall engagement and retention. We have seen early indications that our investments in podcasts are having a **positive impact on conversion of free to paid users.\n And from the Q3 2019 quarterly report:\n For music listeners who do engage in podcasts, we are seeing increased engagement and increased conversion from Ad-Supported to Premium. Some of the increases are extraordinary, almost too good to be true. We\u0026rsquo;re working to clean up the data to prove causality, not just correlation. **Still, our intuition is the data is more right than wrong, and that we\u0026rsquo;re onto something special.\n With these investments, Spotify is aiming to add value, not just for the user but to its bottom-line as well. And it is clear that Spotify is having success that even it did not predict so soon.\nSpotify\u0026rsquo;s Podcast Strategy Spotify\u0026rsquo;s podcast strategy hinges on becoming an \u0026ldquo;Aggregator\u0026rdquo; of podcasts, as described in Ben Thompson\u0026rsquo;s Aggregation Theory. Ben writes,\n The value chain for any given consumer market is divided into three parts: suppliers, distributors, and consumers/users. The best way to make outsize profits in any of these markets is to either gain a horizontal monopoly in one of the three parts or to integrate two of the parts such that you have a competitive advantage in delivering a vertical solution.\n Today, Spotify acts as the distributor of the audio content from suppliers i.e. the music labels (Warner Music Group, Universal Music, Sony Music etc.) and podcast producers (NPR, iHeartRadio, PRX, Wondery etc.). There are other distributors as well who are distributing the same content.\n     With the 2019 and 2020 investments, Spotify is beginning to differentiate itself from being just a podcast app and positioning itself as a supplier of podcasts.\nSpotify will now be able to offer exclusive content on its platform. If this sounds like something you\u0026rsquo;ve heard before, then it is üòâ This is exactly what\u0026rsquo;s happening in the video streaming market with everyone looking to build their library of original content. I expect podcasts to be the next platform where platforms will compete on original content.\nBesides offering exclusive content, Spotify\u0026rsquo;s building a platform where current podcasts that are published in the open model might become exclusive to Spotify for better monetization opportunities. These are what I call Spotify\u0026rsquo;s \u0026ldquo;Killer Features\u0026rdquo; and the topic of discussion in the next topic.\n  Spotify\u0026rsquo;s Killer Features The inertia of entrenched workflows is such that they are tough to change. Most users simply do not abandon an existing app to try out a shiny new app. I am often surprised at how many people do not take the time to explore all the knobs and dials in the settings of an app they use every day. Therefore, to get a user to adopt a new app, you need to offer significantly more value, and more importantly, that value needs to be observable with the default settings.\nBen\u0026rsquo;s Aggregation Theory again,\n This has fundamentally changed the plane of competition: no longer do distributors compete based upon exclusive supplier relationships, with consumers/users an afterthought. Instead, suppliers can be commoditized leaving consumers/users as a first order priority. By extension, this means that the most important factor determining success is the user experience: the best distributors/aggregators/market-makers win by providing the best experience, which earns them the most consumers/users, which attracts the most suppliers, which enhances the user experience in a virtuous cycle.\n This essentially means that Spotify needs to offer both Suppliers and Consumers a much better user experience for Spotify to become the platform of choice. Otherwise, users will continue to listen in their existing podcast apps. On the other hand, publishers have no incentive to publish exclusively on Spotify\u0026rsquo;s platform. At a high-level Spotify\u0026rsquo;s will provide the following benefits to both suppliers and consumers:\n Algorithmic Discovery Analytics \u0026amp; Measurement Targeted Advertising \u0026amp; Monetization Original \u0026amp; Exclusive Content  1. Algorithmic Discovery Today, a user discovers the podcast title on their own through the internet, friends, family, etc. This model is remarkably like how consumers used to discover music. This model worked fine when there were few good podcasts, but with the explosion of new material on the podcast scene, finding enjoyable content is becoming akin to finding a needle in a haystack.\n    Today, new music discovery is primarily done through algorithmic recommendations that are based on demographics, genre, mood, similarity, etc. Spotify is no stranger to this model, having transformed music discovery with playlists like Discover Weekly and Daily Mix. Now, Spotify introducing a similar model to podcast consumption and discovery.\n  First, Spotify recently introduced podcast playlists such as Daily Podcasts, Editorial playlists \u0026ndash; Best Podcasts of the Week, Crime Scene, and Brain Snacks and to help with the pandemic blues \u0026ndash; Daily Wellness. Here\u0026rsquo;s an example from Spotify of how Daily Podcasts playlist makes podcast discovery easier:\n  Spotify\u0026rsquo;s algorithms analyze your podcast behavior \u0026ndash; like recent streams and follows.\n  Then, based on your listening history and the podcast type, we\u0026rsquo;ll recommend the next best episodes for you.\n  That might be the next sequential episode in a podcast you\u0026rsquo;re already listening to (think Dog Tales and How\u0026rsquo;s Work with Esther Perel), a recent stand-alone evergreen episode in another show (maybe Amy Schumer Presents: 3 Girls 1 Keith or Certified Buckets), or a timely episode from a daily updating podcast (like Horoscope Today or The Journal).\n  Don\u0026rsquo;t worry \u0026ndash; no spoilers here! If you\u0026rsquo;ve never listened to a story-driven sequential show we think you\u0026rsquo;d like, you\u0026rsquo;ll get the trailer or pilot episode first \u0026ndash; to see if it catches your eye (er, ear).\n  The importance of these editorial playlists cannot be understated. As Steve Benjamins\u0026rsquo;s experience proves that being included in the \u0026ldquo;Discover Weekly\u0026rdquo; playlist is the primary reason for his $800 per month income. Steve writes:\n Every Monday my music gets a spike in streams on Spotify. You could set a watch to it \u0026ndash; it\u0026rsquo;s that consistent.\nWhat makes Monday so special?\nWell every Monday Spotify sends out a new Discover Weekly playlist. Discover Weekly is an algorithmic playlist \u0026ndash; which means its personalized with songs Spotify thinks the user would like.\nNo other promotional tactic in music comes close to Discover Weekly in delivering new listeners in such a low-effort, high volume way.\nBack in 2013 I would spend hours cold-emailing bloggers. I would be lucky if I got a hit and got 1,000 plays on one of my songs. It was labor intensive.\nNow algorithmic playlists like Discover Weekly send 1,000 new listeners every week without any work on my part. This is amazing. Cold outreach sucks. It sucks for the artist and it sucks for the bloggers. Spotify deserves a lot of credit for here.\n Second, Spotify is borrowing a leaf out of Netflix\u0026rsquo;s recommendations strategy. Like Netflix Prize before it, which aimed at making Netflix\u0026rsquo;s recommendation engine more accurate, Spotify announced the \u0026ldquo;Spotify Podcast Dataset and TREC Challenge\u0026rdquo;. This dataset holds raw audio and transcripts of 100,000 episodes from thousands of different shows on Spotify. With this research challenge, Spotify is trying to understand the content of podcasts (e.g. what exactly is being covered, by whom, and how?) and, and how to use this information to connect users to shows that align with their interests. This data will help answers questions such as:\n  How to identify podcasts that interview Barack Obama, as opposed to those that talk about him?\n  What are the most important parts of a 45-minute episode?\n  Which podcasts are \u0026ldquo;high quality\u0026rdquo; or \u0026ldquo;informative\u0026rdquo; or \u0026ldquo;interesting\u0026rdquo;?\n  With these answers, Spotify will be able to recommend better not just shows but a segment within a specific episode that might align with your interests. These recommendations have the potential to change podcast consumption forever and build a moat for Spotify, which will be hard to overcome or replicate.\n  Spotify recommendation engine can suggest podcasts or even episodes that might be related to your existing subscriptions\n2. Analytics \u0026amp; Measurement Reporting and measurement of listener demographics are not easy due to the decentralized podcast distribution model through RSS feeds. The podcast feed publishing system acts as a dumb 1-way delivery pipe to the user\u0026rsquo;s podcast player of choice. This has made publishers produce creative strategies such as audience surveys, coupon codes, vanity URLs, etc. to derive proxy metrics for ad impressions, audience segments, etc.\nTo solve this problem, Spotify launched the \u0026ldquo;Spotify for Podcasters\u0026rdquo; dashboard. Here is an excerpt from the launch blog post:\n At its core, Spotify for Podcasters is a discovery and analytics dashboard. One where you can both submit your show to Spotify and dive deep into engagement and demographic data for your podcast, tracking things like average listening times, episode streams, and total listeners. With so many podcasts out there, it\u0026rsquo;s more important than ever that you have the data you need to help you understand and grow your audience. That\u0026rsquo;s exactly what your dashboard is designed to provide.\n   Spotify has already done the hard work of building the tools for tracking music engagement. Therefore, it is only natural that those same tools can be extended to podcast publishers. \u0026ldquo;Spotify for Podcasters\u0026rdquo; dashboard is designed to provide these analytics and engagement tracking tools for publishers to track what kind of content resonates with their listeners and adjust.\n3. Targeted Advertising \u0026amp; Monetization While other digital mediums such as online retail and social media have figured out advertising models, podcast monetization remains a tough challenge for publishers. To sell ad spots, a publisher needs to build relationships with brands and provide podcast consumption metrics and listener demographics. In the podcast ecosystem, these metrics and listener demographics are not easily discoverable as I described in the last section and how Spotify will add value in this area. Spotify compares the current state of advertising in the podcast ecosystem to that in the print medium.\n \u0026ldquo;\u0026hellip;the podcast industry measures audience, reach, and impact much like you would a full-page ad in a magazine. Advertisers generally have a sense for who they\u0026rsquo;re reaching, based on survey data and the magazine\u0026rsquo;s target audience. Total circulation measures the number of doorsteps that the issue hits, but there\u0026rsquo;s no precise data on how many readers actually opened the magazine, let alone reached or acted on the ad.\u0026rdquo;\n Spotify is in a unique position to solve these challenges because it has more personalized data on its users than any of the podcast apps. More importantly, it has already built this kind of targeted ad technology to monetize its free music users. Spotify has launched two key features to enable podcast monetization.\nFirst, Spotify launched Streaming Ad Insertion (SAI) technology to dynamically insert ads into user\u0026rsquo;s podcast streams based on what it knows about the user, like where they are located, type of device they use, age, etc. Spotify posits that SAI can \u0026quot;offer intimacy and quality of traditional podcast ads with the precision and transparency of modern-day digital marketing.\u0026quot; So instead of your favorite podcast host talking through the benefits of a product that might be irrelevant to you, you might hear a more personalized ad based on your listening habits and interests, which might be good or bad depending on your take on advertisements.\n  Spotify\u0026rsquo;s podcast streaming model also helps as the ads can be inserted dynamically into the podcast stream instead of being pre-baked into the downloaded audio file. With SAI, Spotify offers the easiest way to monetize podcasts for creators \u0026ndash; very YouTube-like. Theoretically, in the future, a publisher could just tick a checkbox saying they want to opt their podcast into ads, and Spotify would take care of everything \u0026ndash; ad bidding, ad insertions, etc. It\u0026rsquo;s conceivable that the Spotify could even allow publishers to replace the generic ads with more targeted ones and receive a higher payout compared to advertising on other platforms. In the end, you\u0026rsquo;d have the same podcast stream with generic ads in the podcast apps that download the podcast and targeted ads in the Spotify stream.\n  Second, Spotify is launching In-App Offers. Podcast listening usually happens in parallel with another activity like running, workout, cooking, etc. Therefore, it\u0026rsquo;s easy to miss the in-podcast advertising offers. To combat this, podcast show hosts repeat these offer codes and unique URLs multiple times to make sure the listener doesn\u0026rsquo;t miss the offer. In-App Offers is designed to reduce this friction and make it easy to connect users with advertiser offers. Listeners can redeem deals when they open the Spotify app and navigate to the podcast page. Spotify elucidates that this will lead to one fewer \u0026lsquo;w-w-w-dot\u0026rsquo; spelling lesson from our favorite podcast creators.\n  4. Original and Exclusive Content For every song that is streamed on Spotify\u0026rsquo;s platform, it pays a royalty fee to the music labels who own the rights to the song. As Spotify\u0026rsquo;s userbase grows, the fixed costs also grow. The only way for Spotify to increase its margins is to negotiate better deals with the music labels, which is easier said than done. At some point, the ROI on such negotiations is not going to be worth it, and Spotify needs to come up with a better way to increase its gross margin. To combat this, Spotify is taking a leaf out of Netflix\u0026rsquo;s original content strategy. Netflix\u0026rsquo;s gross margin has seen a significant uptick since it started investing in original content in 2013.\nThe 2019 acquisitions (Gimlet, Anchor \u0026amp; Parcast) were the first manifestations of this strategy. Since then, Spotify has acquired Bill Simmons' The Ringer, struck deals with President Barack Obama and Michelle Obama\u0026rsquo;s production company \u0026ndash; Higher Ground for an exclusive podcast, Joe Rogan for the \u0026lsquo;The Joe Rogan Experience\u0026rsquo;, Warner Bros for DC Super Heroes and Super Villains exclusive podcast, Kim Kardashian West for a criminal-justice podcast. If every major media company creating their streaming service in the streaming wars proves anything, it\u0026rsquo;s that having a strong lineup of original content is the best way to retain and attract users. Spotify is just getting started, but the volume of original content released every quarter is increasing.\nConclusion Spotify is in a prime position to solve a lot of creator challenges and gain the first-mover advantage into what I\u0026rsquo;m calling the Podcast 2.0 era. Spotify\u0026rsquo;s latest quarterly earnings prove that Spotify is seeing success with its Podcast strategy. Because of this success, I expect others to follow just as they did in streaming music. Amazon has already embarked on a similar strategy by adding podcasts to its Prime Music offering. Early reports indicate competition is coming down the line from Apple as well. Rumors suggest Apple is currently negotiating deals for original podcasts on its platform. Apple, which would represent significant competition for Spotify because the Apple Podcasts app (previously iTunes) has historically been the top used app for podcast listening, has never capitalized on its podcast popularity so it remains to be seen how potent they can be against Spotify and now Amazon.\nPodcast ecosystem is going to be an exciting space to watch as it evolves over the next few years. There are three key trends to watch as this evolution plays out:\n Our music apps are going to be streaming podcasts and, in the process, more targeted ads. An avenue to monetization is about to be opened for the podcast creators. If you have interesting content, this might be the best time to be a podcaster! On the flip side, it might not be the best time for the open podcast ecosystem and podcast apps not named Spotify, Amazon Music or Apple Podcasts. We are about to see balkanization of the podcast ecosystem which will resemble the video streaming ecosystem. Until now, every podcast title has been available on every podcast very reminiscent of the early days of Netflix streaming. Now a days, every media conglomerate is focusing on creating a streaming offering around the content they own instead of licensing it out to the established streamers like Netflix, Hulu etc.  ","permalink":"https://singhkays.com/blog/how-spotify-is-killing-the-open-podcast-ecosystem/","summary":"Earlier this year, when Spotify announced that \u0026ldquo;The Joe Rogan Experience\u0026rdquo; would stream exclusively on Spotify, it sent shockwaves throughout the podcast ecosystem. This deal \u0026ndash; reportedly worth over $100 million \u0026ndash; is one of the most lucrative podcast deals. The presence of this deal, let alone the magnitude, is rare for the podcast ecosystem, which is built on open principles i.e. all podcasts are available everywhere. Therefore, the concept of exclusivity does not exist in the vocabulary of podcast listeners nor podcast creators.","title":"How Spotify is Killing the Open Podcast Ecosystem"},{"content":"January is usually a big month for tech because the Consumer Electronics Shows kicks off every year in Las Vegas. This year was no different as various manufacturers brought their latest products to showcase.\nSamsung and LG 2020 TVs to support AV1 decoding We have been waiting all of 2019 to see consumer devices that can decode AV1 and CES did not disappoint! Both Samsung and LG announced their upcoming 2020 TVs will be capable of full hardware decode of 8K AV1 videos from sources such as YouTube. Read more about the announcements below.\n http://www.lgnewsroom.com/2020/01/lg-to-unveil-2020-real-8k-tv-lineup-featuring-next-gen-ai-processor-at-ces-2020/ https://news.samsung.com/global/samsung-electronics-unveils-2020-qled-8k-tv-at-ces  SVT-AV1 0.8.1 Released With Palette support for 10-bit and detailed documentation to help developers implement SVT-AV1 workflows. This seems like it was mainly a housekeeping release which is always good. Sometimes you need to step back and make sure you\u0026rsquo;re paying the tech debt! For full SVT-AV1 0.8.1 release notes visit this link below.\n https://github.com/OpenVisualCloud/SVT-AV1/releases/tag/v0.8.1  Rav1e January Releases Rav1e had a busy month with an official 0.2.1 + 2 weekly pre-releases. The included changes include smaller binaries, speed improvement on speed 10 mode among other smaller changes. See the full list of changes below.\n https://github.com/xiph/rav1e/releases/tag/v0.2.1 https://github.com/xiph/rav1e/releases/tag/p20200115 https://github.com/xiph/rav1e/releases/tag/p20200127  Previous ecosystem updates  AV1 Ecosystem Update December 2019 AV1 Ecosystem Update November 2019 AV1 Ecosystem Update October 2019 AV1 Ecosystem Update September 2019 AV1 Ecosystem Update August 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-january-2020/","summary":"January is usually a big month for tech because the Consumer Electronics Shows kicks off every year in Las Vegas. This year was no different as various manufacturers brought their latest products to showcase.\nSamsung and LG 2020 TVs to support AV1 decoding We have been waiting all of 2019 to see consumer devices that can decode AV1 and CES did not disappoint! Both Samsung and LG announced their upcoming 2020 TVs will be capable of full hardware decode of 8K AV1 videos from sources such as YouTube.","title":"AV1 Ecosystem Update: January 2020"},{"content":"Introduction It\u0026rsquo;s not often you see so many logos of tech giants¬†on one page backing the same technology. In my experience, every enterprise has developed a case of¬†NIH¬†and come up with their standards. No surprise then that there\u0026rsquo;s an XKCD describing this phenomenon!\nBut when the AV1 1.0.0 spec was finalized in 2018, with the backing of so many giants, the world knew AV1 would be a serious piece of tech. With the spec finalized, the race was on to get AV1 integrated into your favorite software \u0026amp; hardware for encoding, decoding, and viewing media. By the end of 2018, AV1 adoption was moving at a healthy pace and completed significant milestones necessary to mainstream adoption. Some of these were:\n Browser support (Firefox, Chrome, Vivaldi) Streaming support (see AV1 launch playlist on YouTube) Encoder support in FFmpeg¬† Open-source encoder (rav1e) Open-source decoder (dav1d) Video player support (VLC) MediaInfo support for viewing AV1 Passionate early adopter community (see¬†https://www.reddit.com/r/AV1/)  In 2019, the main goals for AV1 were to get usable encoding times, SoC support for hardware decoding, and continued adoption. Here are the major highlights of 2019 for AV1.\nEncoders   Intel SVT-AV1 Encoder¬†- Intel surprised everyone by getting into the AV1 encoder game with the open-source SVT-AV1 project. The goal of the project was to build an encoder targeting performance levels applicable to both VOD and live encoding/transcoding video applications. SVT-AV1 has been under active development in 2019 and probably has the best speed/quality tradeoff at the moment. In what might be the most significant vote of confidence for this encoder, Netflix announced a collaboration with Intel and plans to experiment and adopt SVT-AV1 as their AV1 encoder of choice. Read more the announcement below as well as my updates on SVT-AV1 development throughout the year.\n Intel, Netflix to Deliver AV1 Scalable Codec to Power Next-Gen Compression Tech for Visual Workloads [Netflix Tech Blog] Introducing SVT-AV1: a scalable open-source AV1 framework [April] SVT-AV1\u0026rsquo;s Big Update [May] SVT-AV1 is making strides! [June] SVT-AV1 v0.6.0 Released [July] rav1e and SVT-AV1 Updates [September] SVT-AV1 0.7.0 Released [November] SVT-AV1 v0.7.5 Released [December] SVT-AV1 0.8.0 Released    rav1e encoder¬†- rav1e is another open-source encoder in the AV1 ecosystem. rav1e\u0026rsquo;s goals are to be the fastest and safest encoder. 2019 was a big year for rav1e as it saw major development and many releases. Like SVT-AV1 / Netflix partnership,¬†rav1e announced it\u0026rsquo;s own partnership with the popular video streaming site, Vimeo. Read more about how the year went for rav1e below.\n AV1: Setting a new standard for video codecs [Vimeo Engineering Blog] Behind the scenes of AV1 at Vimeo 3 Important Takeaways from the Vimeo AV1 Announcement by AV1 co-author Luc Trudeau [July] rav1e and SVT-AV1 Updates [September] rav1e Weekly Pre-release [October] rav1e weekly pre-releases in October [November] rav1e 0.1 released [December] rav1e v0.2.0: Winter Solstice released    Visionular Aurora Encoder -¬†I first blogged about Visionular\u0026rsquo;s Aurora encoder¬†in my¬†May 2019 update. At that time, I was skeptical about the claims. Still, later in the year, Dr. Zoe Liu (Visionular\u0026rsquo;s Co-Founder \u0026amp; President), presented more info about the encoder at industry conferences and shed more light on the testing results and features. Aurora AV1 claims to beat libaom encoder 2-pass cpu-0 by ~33% and x265 2-pass placebo by ~42% on the VMAF model while being 14.6x and 4.4x times faster respectively! Exciting claims, but as this is a closed source encoder, it\u0026rsquo;s not available to test. In 2020, hopefully, we\u0026rsquo;ll hear more about the progress and implementation of this encoder. Read more about my updates below.\n Visionular Aurora AV1 codec claims it\u0026rsquo;s faster and better than x265 Visionular\u0026rsquo;s Aurora AV1 encoder shows promise    Cisco, EVE, Millicast, NGCodec encoders - The AV1 encoder ecosystem had a few other encoders added to the roster. Still, we didn\u0026rsquo;t hear much about these encoders outside of the Big Apple Video 2019 conference. Hopefully, 2020 will shed some more light on these. More details below.\n EVE AV1 Encoder Cisco\u0026rsquo;s real-time AV1 video encoder Millicast\u0026rsquo;s real-time AV1 video encoder NGCodec shows off AV1 encoding with their FPGA encoders    Decoders   Dav1d¬†- dav1d is an AV1 cross-platform decoder, open-source, and focused on speed. In 2019, the dav1d team focused on writing assembly code across a wide spectrum of CPUs with SSE2, SSE3, ARMv7, ARMv8, AVX-2 capabilities, which led to impressive performance gains. With such broad coverage of CPUs and performance improvements, it was no surprise to see browsers switch to dav1d as their AV1 decoder of choice instead of aomdec. If I had to summarize 2019 for dav1d in one word, it would be \u0026quot;Speed!\u0026quot; Read more below.¬† Dav1d 0.3.0 release Firefox 67 release makes AV1 decoding default on all desktop platforms dav1d 0.4.0 FFmpeg 4.2 released with support for AV1 decoding through dav1d dav1d becomes default AV1 decoder in FFmpeg dav1d 0.5.0 \u0026amp; 0.5.1 release dav1d 0.5.0 performance benchmarks dav1d is the default AV1 decoder in Chrome 74    Google\u0026rsquo;s LIBGAV1 - Google surprised everyone in the AV1 community by announcing gav1, Google\u0026rsquo;s AV1 decoder. gav1 is the decoder Google included in Android 10 to enabled AV1 decoding. It is surprising Google built its decoder despite the fantastic performance of dav1d on mobile devices. But competition is always good for consumers! We have competition in the AV1 encoding space and now in the AV1 decoding space as well! It\u0026rsquo;ll be interesting to see how things progress.\n Google drops LIBGAV1 bombshell on AV1 decoders space Playing AV1 videos with ExoPlayer libgav1 Source Code    Hardware Decoders - Getting a healthy ecosystem of hardware devices that can decode AV1 video is an essential step in the mainstream adoption of AV1. H.264, VP9, and even H.265 are universally supported in the most popular consumer devices such as smartphones, Roku and Fire TV sticks, etc. If AV1 is to dethrone H.264 and VP9 on streaming services such as YouTube and Netflix, then the SOCs in these consumer devices will need to support hardware decoding. In 2019, there were many announcements of upcoming products that will launch in 2020. For me, the most significant news was MediaTek beating Qualcomm to AV1 decoding in a smartphone SOC with Dimensity 1000. It looks like we won\u0026rsquo;t see a 2020 Android flagship smartphone with a Snapdragon chip that supports hardware AV1 decode. Here are some of the other notable news in 2019:\n Amphion Semiconductor Hardware decoder Realtek demonstrates first 8K AV1 Decoder and 4K UHD Set-top Box SoCs Broadcom BCM7218X STB SoC Comes with AV1 Hardware Decoding, WiFi 6 Hardware decode demo of AV1 on Youtube Chips\u0026amp;Media Launches Wave510A Hardware AV1 Decoder IP The Tale of Two next-gen SOCs - Snapdragon 865 and MediaTek Dimensity 1000 SDMC DV8919 Amlogic S905X4 Android TV 10 TV Box Supports AV1 Decoding     OS Adoption  Windows 10 support for AVIF - By the time 2019 rolled around, AV1 decoding was already possible on Windows through the use of¬†AV1 Video Extension in the Window Store. With the Windows 10 May 2019 update, Windows also gained support for AVIF image format. Android Q/10 gets AV1 support - Google also announced support for native AV1 decoding in Android 10. With this announcement, Apple is the only OS manufacturer missing from the AV1 support party. Hopefully, 2020 will be the year Safari users can watch videos in something other than H.264 on YouTube!  Streaming adoption The compression benefit offered by AV1 makes it a perfect platform for the streaming services to adopt. With the shift to cord-cutting, video traffic is expected to be the majority of internet traffic. Therefore, streaming services are looking to save every bit they can while delivering video so that they can reach areas with spotty or low-speed internet connections. In 2019, we saw YouTube, Facebook, Netflix, and Vimeo experimenting with AV1 video, which means AV1 is well on its way to becoming the dominant streaming platform. Here are talks on how YouTube, Facebook \u0026amp; Netflix are currently encoding and serving AV1.\n Prod AV1 at YouTube AV1 in Facebook by Jae Hoon Kim AV1 Encoding at Netflix by Liwei Guo  Partnerships 2019 was a year in which companies in the AOMedia consortium needed to get serious about their AV1 adoption plans and boy they did! We saw the emergence of alliances that will bring about serious competition in this space. Here\u0026rsquo;s who got together:\n Intel SVT-AV1 + Netflix -¬†Intel, Netflix to Deliver AV1 Scalable Codec to Power Next-Gen Compression Tech for Visual Workloads Mozilla \u0026amp; Xiph\u0026rsquo;s Rav1e + Vimeo - AV1: Setting a new standard for video codecs YouTube + ?? - It\u0026rsquo;s unclear what encoder YouTube is using. Hopefully, 2020 will shed more light on this topic.¬†  Conference Talks \u0026amp; Presentations AV1 was on the roster for most of the video focused conference with a talk or two. Here are some of the best talks I found that will give you more insight into the goings-on in the ecosystem.\n AV1: One Year Later @ Mile High Video 2019 by Nathan Egge \u0026amp; Brion Vibber Past, Present \u0026amp; Future of AV1 @ AllThingsRTC 2019 by Debargha Mukherjee (Principal Software Engineer @ Google working on libaom) Machine Learning for AOM/AV1 and its Applications in Real-Time Communication @ AllThingsRTC 2019 by Dr. Zoe Liu Big Apple Video 2019 AV1 Presentations  SVT AV1 Overview, Latest Performance Results and Roadmap Aurora: An AV1 Encoder for VoD and Real Time Communications Recent trends in live cloud video transcoding using FPGA acceleration Towards a healthy AV1 ecosystem for UGC platforms High performance AV1 coding with dav1d and Eve Cisco AV1 encoding in video collaboration   Alliance for Open Media 2019 Research Symposium Playlist  Predictions for 2020  AV1 decoding will start showing up in more devices  Sneak Peek: As I\u0026rsquo;m writing this after CES 2020, it is confirmed that 2020 TVs from Samsung and LG will support hardware decode of AV1 videos.   We might see a new Fire TV or Roku product with support for AV1 decoding Netflix might start testing AV1 decoding on Desktop and supported consumer devices  Let\u0026rsquo;s hope for an exciting 2020! AV1 Ecosystem updates  AV1 Ecosystem Update December 2019 AV1 Ecosystem Update November 2019 AV1 Ecosystem Update October 2019 AV1 Ecosystem Update September 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-2019-year-in-review/","summary":"Introduction It\u0026rsquo;s not often you see so many logos of tech giants¬†on one page backing the same technology. In my experience, every enterprise has developed a case of¬†NIH¬†and come up with their standards. No surprise then that there\u0026rsquo;s an XKCD describing this phenomenon!\nBut when the AV1 1.0.0 spec was finalized in 2018, with the backing of so many giants, the world knew AV1 would be a serious piece of tech.","title":"AV1 2019: A Year In Review"},{"content":"dav1d 0.5.2 \u0026lsquo;Asiatic Cheetah\u0026rsquo; released dav1d ended the year with another performance improvement release. Dubbed the \u0026ldquo;Asiatic Cheetah\u0026rdquo; this release brings the following improvements:\n ARM32 optimizations for loopfilter, ipred_dc|h|v Add section-5 raw OBU demuxer Improve the speed by reducing the L2 cache collisions Fix minor issues, including compilation on some OSes  Release notes for dav1d 0.5.2 \u0026lsquo;Asiatic Cheetah\u0026rsquo;\nrav1e v0.2.0: Winter Solstice released Building on the official 0.1.0 release in November, rav1e had a busy December with 3 releases. Overall, rav1e got a lot faster which is only good news for AV1 encoding! Here are the improvements included in the 0.2.0 release.\n Faster, overall 40%-70% faster than v0.1.0 depending on the encoding settings. Optional serialization/deserialization of the encoding parameters through the feature serialize  Optional cli advanced commands to use it.   The builds are now using the dwarf debug format for the targets that support it, before it was a mixture of dwarf and stabs due to the nasm defaults. Added a \u0026ndash;benchmark hidden flag for the cli for MacOS and Linux. documentation is now available on docs.rs.  Source: rav1e v0.2.0: Winter Solstice release notes\nAnd, these are the improvements from the weekly pre-releases.\n Faster, around 20% more compared to the last pre-release  More assembly optimizations from dav1d, mainly impacting AArch64 Forward transform SIMD, to be accounted for the largest part of this week speedup Simplifications and refactoring in the Motion Estimation and Scene Change   Optional serialization/deserialization of the encoding parameters through the feature serialize  Optional cli advanced commands to use it.   The builds are now using the dwarf debug format for the targets that support it, before it was a mixture of dwarf and stabs due to the nasm defaults. Slightly faster. 60%-80% reduction in the resident set depending on the number of tiles in use. Now the resident set is nearly independent from the number of tiles in use.  Source:\n 2019-12-15 Weekly Pre-release 2019-12-01 Weekly Pre-release  Luca Barbato, one of the rav1e and dav1d contributors, recently presented detailed technical information about the improvements included in 0.2.0 release as well as the rav1e roadmap. It\u0026rsquo;s an interesting presentation with a lot more information on what features and the use cases the team is working on. You can view Luca\u0026rsquo;s presentation here https://people.xiph.org/~negge/LVS2019.pdf.\nSVT-AV1 v0.8.0 released Not to be left behind, SVT-AV1 project also ended the year on high with another official release. Here are the improvements included.\nEncoder  Preset Optimizations Single-core execution memory optimization [-lp 1 -lad 0] Rate estimation update enhancements On / off flags for feature run-time switching Auto-max partitioning algorithm support Multi-pass partitioning depth support Remove deprecated RC mode 1 and shifter RC mode 2 and mode 3 to mode 1 and mode 2 respectively Update cost calculation for CDEF Filtering Intra-Inter compound for 10-bit Eigth-pel optimization AVX512 Optimizations AVX2 Optimizations  Decoder  Initial multi-threading support Decoder optimizations / cleanup  Source: SVT-AV1 codec 0.8.0 release notes\nSDMC DV8919 Amlogic S905X4 Android TV 10 TV Box Supports AV1 Decoding Over the past few months, we\u0026rsquo;ve seen reports of SOCs in development that support AV1 hardware decoding but no actual products. SDMC DV8919 appears to be the first Android TV box that leverages Amlogic\u0026rsquo;s new S905X4 chip which supports AV1 4K120p hardware decoding.\nSource: https://www.cnx-software.com/2019/12/22/sdmc-dv8919-amlogic-s905x4-android-tv-10-tv-box-supports-av1-decoding/\nProduct Page for SDMC DV8919\nPrevious ecosystem updates  AV1 Ecosystem Update November 2019 AV1 Ecosystem Update October 2019 AV1 Ecosystem Update September 2019 AV1 Ecosystem Update August 2019 AV1 Ecosystem Update July 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-december-2019/","summary":"dav1d 0.5.2 \u0026lsquo;Asiatic Cheetah\u0026rsquo; released dav1d ended the year with another performance improvement release. Dubbed the \u0026ldquo;Asiatic Cheetah\u0026rdquo; this release brings the following improvements:\n ARM32 optimizations for loopfilter, ipred_dc|h|v Add section-5 raw OBU demuxer Improve the speed by reducing the L2 cache collisions Fix minor issues, including compilation on some OSes  Release notes for dav1d 0.5.2 \u0026lsquo;Asiatic Cheetah\u0026rsquo;\nrav1e v0.2.0: Winter Solstice released Building on the official 0.1.0 release in November, rav1e had a busy December with 3 releases.","title":"AV1 Ecosystem Update: December 2019"},{"content":"I recently discovered the importance of being in control of the notifications on your smartphone. When my recent LinkedIn post went viral, I received many comments and connection requests, which led to a constant buzzing of notifications from the LinkedIn app on my phone. This is never fun when you‚Äôre trying to concentrate üòä\nPre-Requisites  Install the LinkedIn Android app . A fairly recent version of Android. This guide is based on Android 9 behavior.  Steps to customize the app notifications   To get started, locate the LinkedIn app in your app drawer or on the home screen.\n  Long press and hold until additional app options show up.\n  Tap on the little ‚Äúi‚Äù icon. This might be different for different phones and Android skins.\n  Now tap on ‚ÄúNotifications‚Äù in the app section. This will bring you to a screen with a list of notifications.\n  Scroll down until you see ‚ÄúAdvanced‚Äù and tap it.\n  Now tap on ‚ÄúAdditional Settings in the app‚Äù.\n  In the app, tap ‚ÄúPush‚Äù.\n  In ‚ÄúPush‚Äù section, you can control notifications of every type of push notification the LinkedIn app will send.\n  In my case, I wanted to manage the notifications for comments and invites. Those are found in the ‚ÄúConversations‚Äù and ‚ÄúNetwork‚Äù section.\n  And that‚Äôs it! With the above steps completed your phone should be much more peaceful üòä\nContact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/customize-linkedin-android-app-notifications/","summary":"I recently discovered the importance of being in control of the notifications on your smartphone. When my recent LinkedIn post went viral, I received many comments and connection requests, which led to a constant buzzing of notifications from the LinkedIn app on my phone. This is never fun when you‚Äôre trying to concentrate üòä\nPre-Requisites  Install the LinkedIn Android app . A fairly recent version of Android. This guide is based on Android 9 behavior.","title":"How to Customize LinkedIn Android App Notifications"},{"content":"What is LinkedIn? I have never really discovered the value of LinkedIn until about a year ago when I started using it seriously to search for a new job opportunity. I have always viewed it as a Facebook clone with a horrible and inconsistent UI. But I was surprised to discover that LinkedIn had updated their UI with a copy-paste job from Facebook. Using LinkedIn is now a much more pleasant experience!\nAnyone who needs a refresher of the old LinkedIn UI should look at the screens below. Seeing the text density this UI in 2020 gives me shivers!\nThe Post Goes Up This brings me to the point of this blog post üòä Late in 2019, I decided to leave Microsoft and accepted an opportunity at Oracle‚Äôs Cloud Infrastructure team in Seattle. Saying goodbye to the friends and colleagues I had worked with during my 6 years with the Azure team was an emotional event. I had learned so much during my time there and worked with some fantastic people. I wanted to let my LinkedIn network and colleagues who I had worked with know about this change in my life. So, I crafted a message reflecting on my time at Microsoft and its transformation recounting how lucky I was to be a part of it. Then I posted expecting it to be a regular post like any other. What happened next kept surprising me. Day-after-day.\nThe Aftermath As of writing this blog, my post had 90+ comments and ~290,000 views! I also got numerous profile views, which led to 600+ connections requests.\nTypically, the graph on ‚ÄúWho viewed your profile‚Äù feature on LinkedIn is pretty empty for my profile as my profile hardly gets any views. Once this post went up, the graph went through the roof to heights I didn‚Äôt know existed. This is how it looked for the week after the post went up.\nWhat I Learnt   The LinkedIn post visibility filter has a significant effect on who sees your message. With the visibility set to ‚ÄúAnyone‚Äù, there‚Äôs a good chance a lot of people not in your immediate network (1st, 2nd, or 3rd connections) will view your post. This is precisely what happened with my post. I was surprised by the power of the social graph and how information can reach diverse audiences all around the world.\n  With so many connection requests and messages, it pays dividends to be in control of your LinkedIn app‚Äôs push notifications. Otherwise, it‚Äôs easy to turn your phone into a constant ringing bell! To customize the LinkedIn Android app mobile push notifications, see this blog post.\n  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/what-happens-when-your-linkedin-post-goes-viral/","summary":"What is LinkedIn? I have never really discovered the value of LinkedIn until about a year ago when I started using it seriously to search for a new job opportunity. I have always viewed it as a Facebook clone with a horrible and inconsistent UI. But I was surprised to discover that LinkedIn had updated their UI with a copy-paste job from Facebook. Using LinkedIn is now a much more pleasant experience!","title":"What Happens When Your LinkedIn post goes viral!"},{"content":"The Tale of Two next-gen SOCs - Snapdragon 865 and MediaTek Dimensity 1000 Last month, we saw the release of SOCs expected to power next-gen flagship smartphones. Since the AV1 standard as formalized, the community has been waiting to see when SOC manufacturers add hardware support for AV1 decoding. It looks like we'll be waiting a lot longer for such a chip from Qualcomm. In what might come as a shock, MediaTek announced the first SOC to feature such support with their new Dimensity 1000 chip. Qualcomm meanwhile announced the Snapdragon 865 SOC which focused on 5G support and camera improvements this year.\nMore Info:\n MediaTek Press Release Qualcomm Press Release  rav1e 0.1 released Rav1e got its first official release, published during the Video Dev Days 2019 in Tokyo. Here are the included features:\n Intra and inter frames 64x64 superblocks 4x4 to 64x64 RDO-selected square and 2:1/1:2 rectangular blocks DC, H, V, Paeth, smooth, and a subset of directional prediction modes DCT, (FLIP-)ADST and identity transforms (up to 64x64, 16x16 and 32x32 respectively) 8-, 10- and 12-bit depth color 4:2:0 (full support), 4:2:2 and 4:4:4 (limited) chroma sampling 11 speed settings (0-10) Near real-time encoding at high speed levels Rate control (single-pass and two-pass) Temporal RDO Scene cut detection CLI tool and C API  Downloads @ https://github.com/xiph/rav1e/releases/tag/0.1.0\nIn more rav1e progress, u/dwbuiten on reddit noticed that rav1e got included in ffmpeg with the following commit. Hopefully, this means that in an upcoming ffmpeg release, we\u0026rsquo;ll have a common tool to encode with any of the open AV1 encoders.\nSVT-AV1 v0.7.5 released Not to be left behind, SVT-AV1 also got a major release last month. Here are the features included:\nEncoder\n RDOQ for 10-bit Inter Intra Class pruning at MD-Staging Global Motion Vector support for 8-bit and 10-bit Interpolation Filter Search support for 10-bit Palette Prediction support 2-pass encoding support ATB 10-bit support at the encode pass Simplified MD Staging [only 3 stages] Inter-Inter and Inter-Intra Compound for 10-bit Intra Path for 10-bit Filter Intra Prediction New-Near and Near-New support OBMC Support for 8-bit and 10-bit RDOQ Chroma ATB Support for Inter Blocks Temporal Filtering for 10-bit Eight-pel support in predictive ME MCTS Tiles support Added AVX512 Optimizations Added AVX2 Optimizations  Decoder\n SuperRes support Reference Frame Scaling support 12-bit support Annex B support  Downloads @ https://github.com/OpenVisualCloud/SVT-AV1/releases/tag/v0.7.5\nHandbrake 1.3.0 released with AV1 decoding support Handbrake is one of the most popular encoding tools. Users have been waiting for Handbrake to add support for AV1 encoders for a while. While we didn't get that support in 1.3.0 release, it\u0026rsquo;s a start. Full changelog is available @ https://handbrake.fr/news.php?article=43\n¬†AV1 on the YouTube \u0026amp; Facebook YouTube has long been leading the charge for streaming AV1 on the web. Until now, because of the speed of encoding AV1, the resolution was limited to 720p. However, u/toggleton on reddit noticed that YouTube was now encoding some 4K videos in AV1.\n  In addition to YouTube, Facebook was also spotted streaming in AV1 by u/Ktr4ks on reddit.\nPrevious ecosystem updates  AV1 Ecosystem Update October 2019 AV1 Ecosystem Update September 2019 AV1 Ecosystem Update August 2019 AV1 Ecosystem Update July 2019 [AV1 Ecosystem Update June 2019](https://www.singhkays.com/blog/  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-november-2019/","summary":"The Tale of Two next-gen SOCs - Snapdragon 865 and MediaTek Dimensity 1000 Last month, we saw the release of SOCs expected to power next-gen flagship smartphones. Since the AV1 standard as formalized, the community has been waiting to see when SOC manufacturers add hardware support for AV1 decoding. It looks like we'll be waiting a lot longer for such a chip from Qualcomm. In what might come as a shock, MediaTek announced the first SOC to feature such support with their new Dimensity 1000 chip.","title":"AV1 Ecosystem Update: November 2019"},{"content":"Let\u0026rsquo;s start this month\u0026rsquo;s roundup with a faster decoder!\ndav1d 0.5.0 \u0026amp; 0.5.1 release In October, dav1d saw two new releases with some fantastic speed improvements. Here is a summary:\n Large improvements in speed on SSSE3 CPU (up to 40% speedup) Speed improvements on AVX-2 (for 4-7%) Speed improvements on ARM64 (up to 10%) and ARM32. 0.5.1 is a minor release which brings improvements in speed for SSE2 CPUs (up to 50% speedup), and ARMv7 CPUs (up to 41% speedup).  Detailed release notes can be found at:\n https://github.com/videolan/dav1d/releases/tag/0.5.0 https://github.com/videolan/dav1d/releases/tag/0.5.1  Performance numbers can be found at:\n http://www.jbkempf.com/blog/post/2019/dav1d-0.5.0-release-fastest  Google drops LIBGAV1 bombshell on AV1 decoders space While the dav1d team was busy optimizing dav1d for all platforms (even ARM), Google dropped a decoder of their own - gav1. It is not clear why Google didn't just use dav1d for Android as gav1 significantly lags behind dav1d in decoding performance according to the performance testing done by Phoronix.\nMore details on this decoder can be found at:\n https://chromium.googlesource.com/codecs/libgav1/ https://medium.com/google-exoplayer/playing-av1-videos-with-exoplayer-a7cb19bedef9  Chips\u0026amp;Media Launches Wave510A Hardware AV1 Decoder IP Chips\u0026amp;Media announced the beginning of licensing of industry's first AV1 video decoder - its Wave510A hardware decoder IP. Wave510A supports decoding up to 4K60p but can be scaled out to handle 4K120p and 8K60p video as well.\nMore details below:\n https://www.anandtech.com/show/15003/chipsmedia-launches-wave510a-hardware-av1-decoder-ip Product page - https://en.chipsnmedia.com/page/product_view/5919  Socionext Breaks New Ground in Real-Time AV1 Encoding with AWS Japanese system-on-chip technology provider Socionext showcased a solution that enables cloud-based AV1 real-time encoding, ensuring a consistent high-quality video stream while significantly reducing processing time and delivery costs.\nHere\u0026rsquo;s how it works: Capture content with a¬†JVC \u0026ldquo;CONNECTED CAM\u0026rdquo;¬†camera that incorporates an encoder and supports the Zixi protocol. The JVC camera is the only professional camera compatible with the Zixi protocol, a mechanism that uses Forward Error Correction (FEC) and Automatic Repeat Request (ARQ) packet loss recovery. The signal output from the JVC camera is sent to MediaConnect for cloud ingress. The signal is then input to an EC2 F1 instance, encoded to next-generation compression codec AV1 in real-time, and transmitted via CloudFront to the intended audience.\nSocionext showcased tremendous quality difference while reducing the bitrate requirements by 60% (4 Mbps vs 1.6 Mbps)\nMore details at:\n https://aws.amazon.com/blogs/media/socionext-breaks-new-ground-in-real-time-av1-encoding-with-aws/  rav1e weekly pre-releases in October rav1e had 1 release in October. Here are the major changes:\n SSSE3 support Aarch64 neon support FlipADST Additional asm tests (CDEF, Inverse transform). Make sure all the dependencies are using the same version of¬†syn, reducing the overall build time.  Full details at:\n https://github.com/xiph/rav1e/releases/tag/20191023  Tencent joins AV1 codec group Alliance for Open Media In October AV1 membership got a high profile member added in the form of Tencent. Tencent has joined at the board level, which is the first tier of the organization. Full details at the link below:\n https://aomedia.org/tencent-joins-av1-codec-group-alliance-for-open-media/  Previous ecosystem updates  AV1 Ecosystem Update September 2019 AV1 Ecosystem Update August 2019 AV1 Ecosystem Update July 2019 AV1 Ecosystem Update June 2019 AV1 Ecosystem Update May 2019 AV1 Ecosystem Update April 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-october-2019/","summary":"Let\u0026rsquo;s start this month\u0026rsquo;s roundup with a faster decoder!\ndav1d 0.5.0 \u0026amp; 0.5.1 release In October, dav1d saw two new releases with some fantastic speed improvements. Here is a summary:\n Large improvements in speed on SSSE3 CPU (up to 40% speedup) Speed improvements on AVX-2 (for 4-7%) Speed improvements on ARM64 (up to 10%) and ARM32. 0.5.1 is a minor release which brings improvements in speed for SSE2 CPUs (up to 50% speedup), and ARMv7 CPUs (up to 41% speedup).","title":"AV1 Ecosystem Update: October 2019"},{"content":"Let\u0026rsquo;s start this month\u0026rsquo;s roundup with the release of two of our favorite encoders - rav1e and SVT-AV1!¬†rav1e rav1e finally has a new weekly pre-release with the following updates:\nImprovements\n More API documentation Better error reporting Nicer error messages in the cli application Explicit validation of the encoder configuration The input Frame type can be expressed Added cargo-fuzz support and documented its usage Better rate-control support Two-pass rate-control support Additional speedups over all the speed levels on x86_64  Changes\n Tiles are now expressed in linear units (before were log2-units) The for color config enum variants now use the AV1 spec names The C-API is now part of the main repo, use cargo-c to build it send_frame can consume bare Frames Speed preset overhaul and rebalance  Fixes\n Invalid encoder settings, that would trigger panics on execution, are now caught on validation phase. Desync caused by a discrepancy of what would be the tile dimension and the loop restoration filter dimension when using certain tile sizes.¬†  The updated binaries and source code can be downloaded from the below link.\n https://github.com/xiph/rav1e/releases/tag/20190926  SVT-AV1 On the same day as the rav1e release above, SVT-AV1 also announced version 0.7.0. Here are the release notes:\nEncoder\n Enhanced MRP Reference Frames Intra Inter Compound QP Modulation support MFMV Support MD Staging design [Up to 4 MD stages and 3 prediction classes: Intra / Inter / Compound] Compound Motion prediction 10-bit Mode Decision support for Intra Thread safe resource allocation Added AVX512 Optimizations Added AVX2 Optimizations   Decoder\n Screen Content Tools Temporal MV scan support Inter support Screen Content Tools support Post Processing Filters support Compound Mode (InterInter \u0026amp; InterIntra) Tool support Decoder Film Grain support   Build and Testing\n Improve CI Improve build scripts Improve cmake lists Improve Unit Test Coverage API update Bug fixes  dav1d is now the default AV1 decoder in ffmpeg Credit to https://www.reddit.com/user/DominicHillsun/ and https://www.reddit.com/u/MrSmilingWolf/ for posting about this in this reddit thread\nCommit dc0806dd25882f41f6085c8356712f95fded56c7 by James Almer on 15 Sep, 2019 made dav1d the preferred AV1 decoder in FFmpeg. Details @ https://git.ffmpeg.org/gitweb/ffmpeg.git/commit/dc0806dd25882f41f6085c8356712f95fded56c7\nBroadcom BCM7218X STB SoC Comes with AV1 Hardware Decoding, WiFi 6 Broadcom BCM7218X announced the worlds first single-chip SOC with AV1 decoding support. BCM7218X is targeted for set-top box applications. The SoC supports all the HDR formats (HDR/HDR10+, HLG, Dolby Vision) as well as HDMI 2.1 output. Here is the full set of features:\nFeatures\n HDMI 2.1 output OpenGL¬Æ ES 3.1 and Vulkan¬Æ 1.1 capable graphics engine Verimatrix VideoMark NexGuard Watermark Single USB 2.0 DRD port Single eMMC interface Advanced audio decoding (dual-language) Advanced motion-adaptive de-interlacing Multiple audio/video output options are provided:  HDMI 2.1-compliant output with HDCP 2.3 I2S digital output for use with external video/audio DACs   HDR output support on the primary compositor only (CMP0, routed across HDMI) SDR-to-HDR conversion on the primary display path HDR-to-SDR conversion on the primary display path HDR-to-SDR conversion on other display paths (HDR10/10+ and HLG) HDR standards:  HDR10/10+ (all paths) HLG (all paths) Dolby Vision (single layer on the main path of the primary display) Prime (on the main path of the primary display)    Hardware decode of AV1 on Youtube It looks like the Broadcom SoC for STB applications will be joined by a Realtek SoC soon. We saw a demonstration of the Realtek RTD1319 / RTD1311 SoC decoding Youtube AV1 stream in hardware. The video can be seen below.¬†  ¬†Weekly build of libaom AV1 FFmpeg docker image To enable experimentation with the latest builds of libaom AV1, I\u0026rsquo;ve started publishing a weekly build of libaom AV1 in the form of a docker image. The details on how to get and deploy this docker image can be found below.\nhttps://www.singhkays.com/blog/docker-image-av1-ffmpeg-libaom/\nPaint.NET adds AVIF decoding support The popular image editing software for Windows, Paint.NET added AVIF decoding support in the latest 4.2.2 beta build 7186. To enable this you need Windows 10 v1809+ and Microsoft\u0026rsquo;s AV1 Codec (download: https://www.microsoft.com/p/av1-video-extension-beta/9mvzqvxjbq9v)\nFind more detail below https://forums.getpaint.net/topic/115055-paintnet-422-beta-build-7186/\nPrevious ecosystem updates  AV1 Ecosystem Update August 2019 AV1 Ecosystem Update July 2019 AV1 Ecosystem Update June 2019 AV1 Ecosystem Update May 2019 AV1 Ecosystem Update April 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-september-2019/","summary":"Let\u0026rsquo;s start this month\u0026rsquo;s roundup with the release of two of our favorite encoders - rav1e and SVT-AV1!¬†rav1e rav1e finally has a new weekly pre-release with the following updates:\nImprovements\n More API documentation Better error reporting Nicer error messages in the cli application Explicit validation of the encoder configuration The input Frame type can be expressed Added cargo-fuzz support and documented its usage Better rate-control support Two-pass rate-control support Additional speedups over all the speed levels on x86_64  Changes","title":"AV1 Ecosystem Update: September 2019"},{"content":"This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we\u0026rsquo;ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:\n https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/ https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/ https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/  Respond to video indexing complete event Once the video is indexed, we can get the list of scenes from the video and encode them. To do this, we need to create another Logic App that will get triggered when a video indexing complete event is sent.\n  Start by creating another Logic App (I named mine \u0026ldquo;video-insights-logic-app\u0026rdquo;).\n  Add an action \u0026ldquo;When a HTTP request is received\u0026rdquo; and fill in the details as shown below.\n  Next, we\u0026rsquo;ll need to get the video indexer account access token so we can get the video index. Add a \u0026ldquo;Get Account Access Token\u0026rdquo; step like shown below\n  Now that we have an access token, we can get the video index. Add a \u0026ldquo;Get Video Index\u0026rdquo; step and configure like shown below.\na. The tricky part is the video id field as that is available as \u0026ldquo;dynamic content\u0026rdquo; as of this writing. After a bit of trial and error and looking at the output of the \u0026ldquo;When a HTTP request is received\u0026rdquo; step, I saw the video id was a field that was returned in the output JSON. Here\u0026rsquo;s an example output of the HTTP request step\n{ \u0026#34;headers\u0026#34;: { \u0026#34;Connection\u0026#34;: \u0026#34;Keep-Alive\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;prod-19.westus2.logic.azure.com\u0026#34;, \u0026#34;Content-Length\u0026#34;: \u0026#34;0\u0026#34; }, \u0026#34;queries\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;fcd5b84859\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Processed\u0026#34; } } b. From here, I was able to access the video id with the following expression - triggerOutputs()['queries']['id']\n   Next, let\u0026rsquo;s save the retrieved video index to our \u0026ldquo;insights\u0026rdquo; file share. To do this add a \u0026ldquo;Create File\u0026rdquo; Azure File Storage action. First time you add this action, you\u0026rsquo;ll need to create a connection like shown below. Key thing to keep in mind is to use the same storage account we created in Part 2 i.e. \u0026ldquo;serverlessncodermedia\u0026rdquo;.\nWhile configuring the \u0026ldquo;Create file\u0026rdquo; action, use the following dynamic expressions:\n File name - concat(body('Get_Video_Index')?['name'], '-insights','.json') File content - body('Get_Video_Index')?['videos'][0]['insights']['shots']    Now, create a function app in Azure Portal. You can view this tutorial to get started. I named mine \u0026ldquo;serverless-encoder-functions\u0026rdquo;. Within this function app, create two functions named \u0026ldquo;parse-shots\u0026rdquo; and \u0026ldquo;ffpmeg-concat\u0026rdquo; like shown below. The source code (__init__.py file ) for these functions can be found at the link below\n https://github.com/singhkays/av1-serverless-shot-based-transcoder-azure/tree/master/functions    Back to our \u0026ldquo;encoding-logic-app\u0026rdquo;, add an Azure Functions step and select your function app (mine is \u0026ldquo;serverless-encoder-functions\u0026rdquo;) and then the \u0026ldquo;parse-shots\u0026rdquo; function as shown below.\nTo configure the \u0026ldquo;parse-shots\u0026rdquo; function, use the following dynamic expression for \u0026ldquo;Request Body\u0026rdquo; parameter to get the actual shots from the returned video index - body('Get_Video_Index')?['videos'][0]['insights']['shots']\nThen, add the needed headers for our function to work correctly like shown below.\n  Add a for-each loop to create the container instances that will encode the individual shots. Start by consuming the output of the previous azure function step like shown below.\nAdd an action \u0026ldquo;Crete Container Group\u0026rdquo; and configure it like shown below. Some parameters to note are:\n Container Group Name \u0026ndash; Use dynamic expression items('For_each')?['name'] Containers \u0026ndash; Use the dynamic content \u0026ldquo;Current item\u0026rdquo; entry for For each. Don\u0026rsquo;t forget to encase this within array brackets as that\u0026rsquo;s the expected input by the Azure Container Instance API OS Type \u0026ndash; Use Linux as the docker image we\u0026rsquo;re using is Linux based Volumes mounted \u0026ndash; We\u0026rsquo;ll mount the \u0026ldquo;source\u0026rdquo; and \u0026ldquo;shots\u0026rdquo; file share. \u0026ldquo;source\u0026rdquo; will be used to read the user uploaded video. \u0026ldquo;shots\u0026rdquo; will be used to place the encoded shot video file.     Now, in the for-each loop we added in previous step, we\u0026rsquo;ll add an \u0026ldquo;Until\u0026rdquo; loop. This loop will need to run until the provisioningState for the previously created container group is \u0026ldquo;succeeded\u0026rdquo;. To this \u0026ldquo;Until\u0026rdquo; action we\u0026rsquo;ll add a delay of 1 minute so we limit the number of API calls we make. Then to actually query the provisioningState, we\u0026rsquo;ll add a \u0026ldquo;Get properties of a container group\u0026rdquo; action and use the provisioningState dynamic content of this action as the check statement in the \u0026ldquo;Until\u0026rdquo; loop.\n  Now to terminate the for-each loop, we need to determine if all the container instances have succeeded successfully. This requires us to check if the state of the container group is \u0026ldquo;succeeded\u0026rdquo;. For this, we\u0026rsquo;ll create another \u0026ldquo;until\u0026rdquo; action which is mostly similar to the one we added in the previous step. There is a key difference, which is that the \u0026ldquo;until\u0026rdquo; loop will check for the state of the container group and not the provisioningState.\n   Now that the encoding is complete, we can clean up all the container instances that were created. To do this, add a \u0026ldquo;Delete container group\u0026rdquo; action and configure like shown below.\n For the \u0026ldquo;Container Group Name\u0026rdquo;, use the following expression value - items('For_each')?['name']    At the end of the above set of steps, you\u0026rsquo;re \u0026ldquo;for-each\u0026rdquo; action should look like below.\nTo make sure, we don\u0026rsquo;t run into Azure Container Instances quota limits, I set concurrency control on the for-each loop to the max allowed of 50 which means at any given time only 50 shots will be encoded concurrently. The concurrency settings can be accessed from the \u0026ldquo;settings\u0026rdquo; menu as shown above. Unfortunately, there doesn\u0026rsquo;t seem to be a way to set a higher limit without turning off concurrency control completely. If you have a high enough Azure Container Instances quota limits, then you don\u0026rsquo;t need to worry about this.\n  Now it\u0026rsquo;s time to join the individual encoded shot files into the output video. For this we created the \u0026ldquo;ffmpeg-concat\u0026rdquo; function before. Let\u0026rsquo;s add an action to invoke this function and pass in the appropriate header parameters as shown below.\nFor the \u0026ldquo;Request Body\u0026rdquo; parameter, use the expression value - body('Get_Video_Index')?['videos'][0]['insights']['shots']\n  Next, we\u0026rsquo;ll save the ffmpeg concat file our \u0026ldquo;ffmpeg-concat\u0026rdquo; function generated previously. Us the following expression values.\n File name \u0026ndash; concat(body('Get_Video_Index')?['name'],'-concat','.txt') File content \u0026ndash; Use \u0026ldquo;body\u0026rdquo; dynamic content of the previous \u0026ldquo;ffmpeg-concat\u0026rdquo; action    It\u0026rsquo;s time to put the individual encoded shots together into a singular video file. To do this we\u0026rsquo;ll create a container instance like shown below and pass in the requisite commands.\nYou can use the following JSON definitions\nContainers \u0026ndash;\n[ { \u0026#34;name\u0026#34;: \u0026#34;concat-ffmpeg\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;offbytwo/ffmpeg\u0026#34;, \u0026#34;resources\u0026#34;: { \u0026#34;requests\u0026#34;: { \u0026#34;cpu\u0026#34;: 1, \u0026#34;memoryInGB\u0026#34;: 0.5 } }, \u0026#34;command\u0026#34;: [ \u0026#34;/opt/ffmpeg/bin/ffmpeg\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;concat\u0026#34;, \u0026#34;-safe\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;/aci/insights/@{body(\u0026#39;Create_file_2\u0026#39;)?[\u0026#39;Name\u0026#39;]}\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;copy\u0026#34;, \u0026#34;-y\u0026#34;, \u0026#34;/aci/output/@{body(\u0026#39;Get_Video_Index\u0026#39;)?[\u0026#39;name\u0026#39;]}-output.mkv\u0026#34; ], \u0026#34;volumeMounts\u0026#34;: [ { \u0026#34;mountPath\u0026#34;: \u0026#34;/aci/insights/\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;insights\u0026#34;, \u0026#34;readOnly\u0026#34;: true }, { \u0026#34;mountPath\u0026#34;: \u0026#34;/aci/shots/\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;shots\u0026#34;, \u0026#34;readOnly\u0026#34;: true }, { \u0026#34;mountPath\u0026#34;: \u0026#34;/aci/output/\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;output\u0026#34;, \u0026#34;readOnly\u0026#34;: false } ] } } ] Volumes (don‚Äôt forget to first add this additional parameter)\n[ { \u0026#34;azureFile\u0026#34;: { \u0026#34;readOnly\u0026#34;: true, \u0026#34;shareName\u0026#34;: \u0026#34;shots\u0026#34;, \u0026#34;storageAccountKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;storageAccountName\u0026#34;: \u0026#34;serverlessencodermedia\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;shots\u0026#34; }, { \u0026#34;azureFile\u0026#34;: { \u0026#34;readOnly\u0026#34;: true, \u0026#34;shareName\u0026#34;: \u0026#34;insights\u0026#34;, \u0026#34;storageAccountKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;storageAccountName\u0026#34;: \u0026#34;serverlessencodermedia\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;insights\u0026#34; }, { \u0026#34;azureFile\u0026#34;: { \u0026#34;readOnly\u0026#34;: false, \u0026#34;shareName\u0026#34;: \u0026#34;output\u0026#34;, \u0026#34;storageAccountKey\u0026#34;: \u0026#34;\u0026#34; \u0026#34;storageAccountName\u0026#34;: \u0026#34;serverlessencodermedia\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;output\u0026#34; } ] In the Logic App, this looks like below\n   Create another until loop and configure it like below. We\u0026rsquo;ll use this to wait until the merging of the files is done so that we can take another action like sending an email as well as deleting the container group.\n  Conclusion This concludes Part 3. Hopefully, this gives you inspiration to build a similar solution on Azure.\nAV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video!  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/","summary":"This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we\u0026rsquo;ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:","title":"Part 3: Building a scalable 'shot-based' serverless AV1 video encoder in Azure"},{"content":"Motivation While trying to try out the latest features for the libaom AV1 encoder, I\u0026rsquo;ve been trying to figure out how to get a hold of the latest binary. As of writing of this blog, I haven\u0026rsquo;t come across any source on the web that publishes a binary of libaom AV1 encoder. Often while trying to get a hold of the latest changes in libaom, you have to build the source yourself which takes time. Therefore, I took it upon myself to publish a weekly build of FFmpeg with the latest available libaom source @ https://aomedia.googlesource.com/aom.\nConfiguration  Latest release of FFmpeg (v4.2.1 as of writing this blog) Latest commit in the master branch from https://aomedia.googlesource.com/aom/+/refs/heads/master at the time of build Built on Ubuntu 18.04 LTS Built with GCC 8 Built every Sunday @ 00:00 UTC time FFmpeg build also includes x264, x265, VP9, VMAF, LAME, AAC, OPUS  Download The docker image is available @ Docker Hub - singhkays/ffmpeg-av1-libaom\nUsage If you haven\u0026rsquo;t used docker containers before, I suggest reading the below links first:\n Get started with Docker Install Docker Community Engine  Running the AV1 docker container The command below will run the AV1 container in interactive mode and map your current working directory to /usr/workspace.\ndocker run -it --name ffmpegcontainer -v $(pwd):/usr/workspace singhkays/ffmpeg-av1-libaom:latest bash\nAV1 ecosystem updates  AV1 Ecosystem Update July 2019 AV1 Ecosystem Update June 2019 AV1 Ecosystem Update May 2019 AV1 Ecosystem Update April 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video!  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/docker-image-av1-ffmpeg-libaom/","summary":"Motivation While trying to try out the latest features for the libaom AV1 encoder, I\u0026rsquo;ve been trying to figure out how to get a hold of the latest binary. As of writing of this blog, I haven\u0026rsquo;t come across any source on the web that publishes a binary of libaom AV1 encoder. Often while trying to get a hold of the latest changes in libaom, you have to build the source yourself which takes time.","title":"Now Available: Weekly build of libaom AV1 + FFmpeg docker image"},{"content":"AVIF in Spectrum lib While browsing for AV1/AVIF updates, I noticed this commit to Facebook\u0026rsquo;s open source Spectrum library that adds support for AVIF format.\n https://github.com/facebookincubator/spectrum/commit/89b87bee831d3c7aabd0ad327fb118ce699df55d  Spectrum is an image transcoding library for iOS and Android that is meant to be integrated into apps for image operations. Hopefully this means that we\u0026rsquo;ll see apps supporting AVIF format soon!\nFFmpeg 4.2 release FFmpeg 4.2 codenamed \u0026ldquo;Ada\u0026rdquo; was released on August 5th, 2019. It brought with it support for AV1 decoding through libdav1d decoder. This should make it possible for applications which integrate FFmpeg to build in support for decoding AV1 files. For the full release notes visit the below link.\n https://ffmpeg.org/index.html#pr4.2  dav1d 0.4.0 In July, dav1d got it\u0026rsquo;s 4th major release codenamed \u0026ldquo;Cheetah\u0026rdquo;. Here are the changes included in this release\n 25% speedup on ARM64 Minor improvements on SSE and ARM Major improvements to RAM usage (halving the RAM used in some cases!)  https://code.videolan.org/videolan/dav1d/-/tags/0.4.0\nlibaom updates libaom seems to be coming along nicely with some fairly substantial improvements this month!\n  ~37% reduction in memory for multi-thread and ~18% reduction in memory use for single-thread for encoding 1080p video using 4x2 tiles and 8 threads (credit to u/AutoAltRef6 for noticing)\n  4% reduction in memory usage for 4K+ videos (credit to u/AutoAltRef6 for noticing)\n  ~5% and ~3.5% encode time reduction for cpu-used 3 and 4 (credit to u/AutoAltRef6 for noticing)\n  Another ~10% speed improvement for cpu-used 3 and 4 (credit to u/DominicHillsun for noticing)\n  ~57% memory reduction when encoding 4k videos over 33 frames (credit to u/DominicHillsun for noticing)\n  Convolutional Neural Networks Based Texture Modeling For AV1 The following research paper released in August discusses how using a different coding method for \u0026ldquo;perceptually insignificant\u0026rdquo; regions in the frame can lead to substantial data rate reductions while maintaining visual quality. Some of this research was presented by Dr. Zoe Liu in her \u0026ldquo;Aurora AV1 encoder\u0026rdquo; presentation at Big Apple Video conference 2019 back in June. I suspect these neural network based techniques are what allow the Aurora encoder to show so much promise at this early stage. The paper can be found at the link below.\n https://arxiv.org/pdf/1908.02875.pdf  Online AV1 converter You an encoding format has gone mainstream when websites start popping online allowing you to upload any video and convert it to the format in question :). I found one such website last month. Enjoy!\nhttps://convertio.co/av1-converter/\nPrevious ecosystem updates  AV1 Ecosystem Update July 2019 AV1 Ecosystem Update June 2019 AV1 Ecosystem Update May 2019 AV1 Ecosystem Update April 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-august-2019/","summary":"AVIF in Spectrum lib While browsing for AV1/AVIF updates, I noticed this commit to Facebook\u0026rsquo;s open source Spectrum library that adds support for AVIF format.\n https://github.com/facebookincubator/spectrum/commit/89b87bee831d3c7aabd0ad327fb118ce699df55d  Spectrum is an image transcoding library for iOS and Android that is meant to be integrated into apps for image operations. Hopefully this means that we\u0026rsquo;ll see apps supporting AVIF format soon!\nFFmpeg 4.2 release FFmpeg 4.2 codenamed \u0026ldquo;Ada\u0026rdquo; was released on August 5th, 2019.","title":"AV1 Ecosystem Update: August 2019"},{"content":"If May and June were F1 race cars in terms of speed of AV1 development, then July would probably be a Honda Civic. After numerous exciting announcements in the previous month, July felt like everyone\u0026rsquo;s on vacation, which is probably true because summer months tend to be slow as the school\u0026rsquo;s out. So, this update will be a short one as I\u0026rsquo;m out on vacation as well :)\nMile High Video 2019 Nathan Egge of Mozilla and Brion Vibber of Wikimedia presented a session recapping AV1\u0026rsquo;s progress in the last year. Here\u0026rsquo;s a recap of the most important parts of the presentation\n Live encode and playback demo in all major browsers (even Safari!) using the dav1d decoder. The Safari demo was done using a WebAssembly shim called ogv.js. ogv.js includes a build of the dav1d AV1 decoder which works well enough in Safari at low resolutions currently. Once the WebAssembly threading and SIMD support matures, the higher resolutions should also become playable in browsers without native AV1 support 4K decoding on an iPad Pro showing that it\u0026rsquo;s possible to decode a 4K AV1 file even in software! 1 in 8 videos played in Firefox in July 2019 were AV1!  AV1 live encode and playback demo at #mhv2019 AV1 in @firefox (ARM+x86), @googlechrome, @MicrosoftEdge, Safari and @videolan VLC, all using dav1d.\nEncoded live with @intel SVT-AV1 in @DASH_IF (360p to 1080p) format. pic.twitter.com/pyrj2sXfYv\n\u0026mdash; VideoLAN (@videolan) July 31, 2019  For the details of other demos shown, I\u0026rsquo;ve embedded the presentation below.\nSwitch Media \u0026ldquo;Working with the AV1 codec\u0026rdquo; presentation Kevin Staunton-Lambert of Switch Media posted his presentation about working with AV1. It has some useful info on how to use AV1 as well as why AV1 achieves better compression. The slides are embedded below.\nXilinx acquires NGCodec In last month\u0026rsquo;s ecosystem update, I talked about NGCodec impressive presentation about real time AV1 encoding using their upcoming FPGA encoder. Well, this month the folks over at Xilinx seem to have been impressed by the work NGCodec team has done with their existing solutions (read: Twitch\u0026rsquo;s real time VP9 deployment) and announced they are acquiring NGCodec. The announcement can be found below.\nBuffer Be Gone! Xilinx Acquires NGCodec to Deliver High-Quality, Efficient Cloud Video Encoding\nrav1e and SVT-AV1 updates July continued the development progress on the SVT-AV1 and rav1e encoders. While there were no major releases, I counted\n 59 PRs merged for SVT-AV1 89 PRs merged for rav1e  Looking at the commit activity, July was a pretty slow month for SVT-AV1 development compared to June. libvips now supports compressing images in AVIF format libvips, a fast image processing library with low memory needs will soon add support for AVIF compression through libheif support. See the Github discussion below.\n https://github.com/libvips/libvips/issues/1364  Previous ecosystem updates  AV1 Ecosystem Update June 2019 AV1 Ecosystem Update May 2019 AV1 Ecosystem Update April 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video! Building a scalable \u0026lsquo;shot-based\u0026rsquo; serverless AV1 video encoder in Azure  Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-july-2019/","summary":"If May and June were F1 race cars in terms of speed of AV1 development, then July would probably be a Honda Civic. After numerous exciting announcements in the previous month, July felt like everyone\u0026rsquo;s on vacation, which is probably true because summer months tend to be slow as the school\u0026rsquo;s out. So, this update will be a short one as I\u0026rsquo;m out on vacation as well :)\nMile High Video 2019 Nathan Egge of Mozilla and Brion Vibber of Wikimedia presented a session recapping AV1\u0026rsquo;s progress in the last year.","title":"AV1 Ecosystem Update: July 2019"},{"content":"This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we\u0026rsquo;ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:\n https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/ https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/ https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/  The solution To implement this solution, we need an algorithm that splits the input video into shots. Fortunately for us, Microsoft Video Indexer supports this scenario. Before getting started we\u0026rsquo;ll setup Video Indexer in our subscription. For the rest of the steps, here\u0026rsquo;s a quick overview of what\u0026rsquo;s going to happen:\n User uploads an MP4 video file to Azure Blob Storage Because of the Azure Event Grid integration with Azure Blob Storage, a file upload event triggers a notification The event notification is consumed by the first Logic App. The first step in the Logic App is to upload the video to Microsoft Video Indexer service Once the video is indexed, we retrieve the video insights and store it in the \u0026ldquo;insights\u0026rdquo; Azure File share While the video indexing is happening, we also copy the video file from Azure Blob Storage to the \u0026ldquo;source\u0026rdquo; Azure File share where it can be accessed by container instances later When the indexing is complete, an \u0026ldquo;Indexing complete\u0026rdquo; notification is sent to trigger the second Logic App In the second Logic App, the first step is to retrieve the video insights saved earlier Next, we use an Azure Function to parse the shots data and create our container instance definitions as well as shots encoding commands for each container instance Now we can use the Logic App-Container Instance connector to create container instances based on container instance definitions defined in the last step As the container instances finish their respective encoding jobs, they save the output video in the \u0026ldquo;shots\u0026rdquo; Azure File share Next, we trigger another Azure Function to iterate over the output files and create a ffmpeg concat file Once we have a concat file, we create another container instance with ffmpeg installed to execute the concat file The output of the preview container instance i.e. all the encoded shots files that are combined to one file is saved in the \u0026ldquo;output\u0026rdquo; Azure File share The user can then download the encoded file from the \u0026ldquo;output\u0026rdquo; Azure File share  User Experience While building this solution, I wanted to keep the user experience simple. Hence a user needs to take only these steps:\n Upload an MP4 video file to a specified Azure Blob Storage Account Download the encoded file from the \u0026ldquo;output\u0026rdquo; Azure File share  Implementation Details Setup Microsoft Video Indexer   Start by going to https://vi.microsoft.com/en-us/ and logging in with your Azure account\n  Once logged in, click \u0026ldquo;Create new account\u0026rdquo;\n  Once you\u0026rsquo;ve logged into your Azure subscription, fill in the details for the Video Indexer instance you\u0026rsquo;d like to create.\n  It can take a few minutes for the Video Indexer to connect to your subscription. Once that is done, copy the account id of your new account\n  Now login with your Azure subscription at https://api-portal.videoindexer.ai/developer and copy the Primary or Secondary key\n  That\u0026rsquo;s it! Now Video Indexer instance is all setup in your subscription  Blob upload events   Create a storage account. I named mine \u0026ldquo;serverlessn codermedia\u0026rdquo;\n  In the storage account, create a container called \u0026ldquo;media\u0026rdquo; in the \u0026ldquo;Blobs\u0026rdquo; section. This is where the user will upload an .MP4 video file.\n  In the \u0026ldquo;Files\u0026rdquo; section, add 4 new file shares\na. insights \u0026ndash; we\u0026rsquo;ll store the insights about indexed video hereb. output \u0026ndash; we\u0026rsquo;ll store the full encoded video here that the user can downloadc. shots \u0026ndash; we\u0026rsquo;ll store the individual encoded shots video files hered. source \u0026ndash; we\u0026rsquo;ll store the user uploaded video file here for access by the container instances  Once the storage account is created, click the \u0026ldquo;Events\u0026rdquo; section of the storage account. In the \u0026ldquo;Events\u0026rdquo; section, use the \u0026ldquo;When a new blob is uploaded\u0026rdquo; quick start logic app to get started.  Next screen shows the Azure Blob Storage and Azure Event Grid connections   First create the connection for the storage account you just created   Next, sign into Azure Event Grid with your current Azure subscription. Once you\u0026rsquo;ve done these steps, you should see the following screen showing green status!\n  Hit continue and you should now land on the Logic Apps designer\n  In the \u0026ldquo;When a resource event occurs\u0026rdquo;a. select Event Type Item of Microsoft.Storage.BlobCreatedb. Add two new parameters \u0026ndash; \u0026ldquo;Suffix Filter\u0026rdquo; with value \u0026quot;.mp4\u0026quot; and \u0026ldquo;Subscription Name\u0026rdquo; with value anything you want  In the \u0026ldquo;If true\u0026rdquo; section g. Delete all steps except \u0026ldquo;Compose\u0026rdquo;\n   Your Logic App at this point should look like below\n  Save the logic app with whatever name you choose. In this solution, I named it as \u0026ldquo;video-indexer-logic-app\u0026rdquo;\n  Upload video to Microsoft Video Indexer   After the \u0026ldquo;Compose\u0026rdquo; action, add a \u0026ldquo;Create SAS URI by path\u0026rdquo; action\na. For the \u0026ldquo;Blob path\u0026rdquo;, choose the \u0026ldquo;Outputs\u0026rdquo; from the previous Compose action. You will have to click \u0026ldquo;See more\u0026rdquo; to see the output from the Compose action.b. Make sure you\u0026rsquo;re connected to the same Azure Blob Storage connection we defined earlier (storage-la-conn in this case)\n  Now add a \u0026ldquo;Get Account Access Token\u0026rdquo; action for Video Indexer (V2) connector.\na. The first time you do this, you will need to enter the Video Indexer API Key we copied earlier and enter a name for this Logic App-Video Indexer connectionb. Once the connection is created, select the location you deployed your Video Indexer instance to earlier.c. Select the account Id we saved earlierd. Select \u0026ldquo;Yes\u0026rdquo; for \u0026ldquo;Allow Edit\u0026rdquo;  Now add a \u0026ldquo;Upload video and index\u0026rdquo; step and fill in the following details as shows in the image.   For the Video Name field you can choose any name or make it dynamic using the expression tab to enter split(triggerBody()?[\u0026lsquo;subject\u0026rsquo;], \u0026lsquo;/')?[6]. This splits the input video Uri to just the file name that was uploaded Copy user video to \u0026ldquo;source\u0026rdquo; Azure File share   Now we need to copy the source video file to the \u0026ldquo;source\u0026rdquo; Azure File share so that our encoding containers instances can access it. For that, add a \u0026ldquo;Create container group\u0026rdquo; action and configure it like shown below.\nWe\u0026rsquo;re using a small wget container that will download the video from the SAS Uri we generated earlier and then copy it to \u0026ldquo;source\u0026rdquo; Azure File Share. Note that we\u0026rsquo;re using a minimal docker image, therefore we\u0026rsquo;ll need to use \u0026ldquo;\u0026ndash;no-check-certificate\u0026rdquo; with wget to download from HTTPS SAS Uri of Azure Blob Storage.\nNote that I\u0026rsquo;m creating this container in a new resource group \u0026ldquo;encoding-containers-rg\u0026rdquo; to keep a dedicated resource group for creating container instances.\nFor the containers field, you can use the following JSON to configure easily\n[ { \u0026#34;name\u0026#34;: \u0026lt;select output Video Id of ‚ÄúUpload and index‚Äù step, \u0026#34;properties\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;inutano/wget\u0026#34;, \u0026#34;resources\u0026#34;: { \u0026#34;requests\u0026#34;: { \u0026#34;cpu\u0026#34;: 1, \u0026#34;memoryInGB\u0026#34;: 0.5 } }, \u0026#34;command\u0026#34;: [ \u0026#34;wget\u0026#34;, \u0026#34;--no-check-certificate\u0026#34;, \u0026#34;-O\u0026#34;, \u0026#34;/aci/source/\u0026lt; enter into expression tab split(triggerBody()?[\u0026#39;subject\u0026#39;], \u0026#39;/\u0026#39;)?[6] \u0026gt;\u0026#34;, \u0026lt;Insert Web Url i.e. SAS Uri we generated earlier\u0026gt; ], \u0026#34;volumeMounts\u0026#34;: [ { \u0026#34;mountPath\u0026#34;: \u0026#34;/aci/source/\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;source\u0026#34;, \u0026#34;readOnly\u0026#34;: false } ] } } ]   Next, add an \u0026ldquo;Until\u0026rdquo; action to check for the completion of the previous container instance. Before filling in the details of the \u0026ldquo;Until\u0026rdquo; action, add a \u0026ldquo;Delay\u0026rdquo; and \u0026ldquo;Get properties of a container group\u0026rdquo; action like below.\nOnce this is done, now you can fill in the details of the \u0026ldquo;Until\u0026rdquo; action like below. NOTE: there are a few different state variables that show up. Choose the one I highlighted in the image below. Also in the advanced mode make sure the value is following to make sure you\u0026rsquo;ve selected the correct variable\n@equals(body('Get_properties_of_a_container_group')?['properties']?['instanceView']?['state'], 'Succeeded')\n  Now for some cleanup! Let\u0026rsquo;s add a \u0026ldquo;Delete container group\u0026rdquo; action\n  First logic app created! At the end of above steps, your first logic app \u0026ldquo;video-indexer-logic-app\u0026rdquo; should look like below. I chose to leave the \u0026ldquo;If false\u0026rdquo; condition empty. You can setup an email notification for example if you choose to do so.\nEnd of Part 2 This is the end of Part 2. In Part 3, we\u0026rsquo;ll actually encode the shots and combine the shots into 1 video file.\n https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video!  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/","summary":"This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we\u0026rsquo;ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:","title":"Part 2: Building a scalable 'shot-based' serverless AV1 video encoder in Azure"},{"content":"It\u0026rsquo;s been a pretty busy for me professionally which is why this month\u0026rsquo;s AV1 ecosystem update is coming in pretty late. It\u0026rsquo;s been one of the most exciting months for AV1 development and a lot to catch up on! With so much news this month, it is starting to feel like we\u0026rsquo;re at the cusp of something big! (which we hope AV1 will be )\nYoutube pauses AV1 rollout Currently, YouTube is the biggest streaming platform delivering AV1 video and is responsible for the majority of AV1 video consumption on the internet. But a recent message posted to AV1 subreddit announced that YouTube was pausing the rollout of AV1. The reason was not shared but AV1 seems to be performing well at YouTube with the intent to expand its use soon. Here\u0026rsquo;s the full message:\nHey all, YT engineer here. We've stopped serving AV1 on YT for a bit for a boring, internal, procedural reason, not related to its performance. (It's actually performing well and we were about to expand its use further.) It'll be back up soon. Thanks for your patience!  Reddit thread: AV1 on YouTube paused for boring procedural reason\nRealtek demonstrates first 8K AV1 Decoder and 4K UHD Set-top Box SoCs At Computex 2019, Realtek demonstrated RTD2983 SoC can support decoding 8K resolution videos encoded using the AV1, HEVC, and VP9 codecs. The chip can process all HDR formats, reduce noise, upscale, and perform all the other functions common for processors for televisions and digital media players.¬†Realtek also announced RTD1311, a 4k UHD set-top box SoC capable of decoding AV1. The chip also supports HEVC 1080P encoder, all HDR standards, diverse output interfaces such as HDMI 2.1, USB3.0, and PCI-e, along with built-in far-field voice recognition.\nAnnouncements below\n  Realtek 8K Video Decoder and Processing IC (RTD2893) Wins Best Choice of the Year at COMPUTEX TAIPEI 2019\n  Realtek Launches Worldwide First 4K UHD Set-top Box SoC (RTD1311), Integrating AV1 Video Decoder and Multiple CAS Functions \n  Anandtech has more details here - Realtek Demonstrates RTD2893: A Platform for 8K Ultra HD TVs¬†Conferencing! There were two conferences in June, AllThingsRTC 2019 and then Big Apple Video, where a lot of new information about AV1 was shared. We heard updates on the following topics which are all covered later in this update:\n libaom AV1 encoder Aurora AV1 encoder SVT-AV1 encoder rav1e AV1 encoder NGCodec FPGA encoder for AV1 EVE AV1 encoder  Past, Present \u0026amp; Future of AV1 Debargha Mukherjee (Principal Software Engineer @ Google working on libaom) opened the AllThingsRTC keynote titled \u0026ldquo;Past, Present and Future of AV1\u0026rdquo;. This presentation can be seen below   Visionular\u0026rsquo;s Aurora AV1 encoder shows promise I first heard about the Aurora AV1 encoder last month and commented on the ambitious claims made. This month, we got more information about Aurora and it\u0026rsquo;s exciting! Zoe Liu, co-founder \u0026amp; President of Visionular presented about their Aurora AV1 encoder and how machine learning has been applied to enhance the encoder. Zoe had a busy June presenting first at AllThingsRTC and then at Big Apple Video. Both can be seen below as well as some of the slides comparing Aurora to libaom AV1 encoder as well as x265.\n     SVT-AV1 v0.6.0 released June continued to be a very active month for SVT AV1. I reported in May that 40 PRs were merged. Well June just beat that record! There were 51 PRs merged in June with the week of June 16th merging 216 commits which is the highest in the history of the project in one week!\nAlso in June, version 0.6.0 was released with the following updates\n Initial decoder implementation Static library support Alt-ref pictures - temporal filtering Adaptive Transform Block for INTRA Adaptive QP scaling Decoder - Support for Tiles and 10bit API - add option to calculate / report PSNR values Support for segmentation SIMD Optimizations Downsampling 2x2 filtering Handle incomplete SBs MACROS / trailing / tabs-spaces cleanup  Hassene Tmar, product lead for SVT-AV1 at Intel, was present at Big Apple Video to talk about the goals, improvements and the roadmap for SVT-AV1. Here are some of the slides from Hassene\u0026rsquo;s presentation as well as video of the presentation.\n  Rav1e + Vimeo = ‚ù§Ô∏è June was a pretty popular month for rav1e with 51 PRs merged!.\nBut the biggest news for rav1e was the partnership with Vimeo. Vimeo announced that they were adopting AV1 for their \u0026ldquo;Staff Picks\u0026rdquo; video category immediately. David Jervidal\u0026rsquo;s Staff Picked film \u0026ldquo;Capture the North\u0026rdquo; (below) is one example of the Vimeo videos leveraging AV1.\n   You can read more about the announcement here and behind the scenes engineering blog here.\nNGCodec shows off AV1 encoding with their FPGA encoders Oliver Gunasekara, founder of NGCodec, discussed their approach to use programmable hardware accelerateres (Xilinx FPGA\u0026rsquo;s) to replace Intel Xeon CPU\u0026rsquo;s at Big Apple Video 2019. Having successfully worked with Twitch for VP9 acceleration, Oliver showed off the next step in that journey - FPGA accelerated AV1 encoder. See more below:\n  Twitch talks about their AV1 adoption plan Twitch was also one of the speakers at Big Apple Video presenting their plan for AV1 adoption as well as their worries about the AV1 ecosystem. One of the most interesting things talked about in this presentation was the inclusion of Twitch proposed \u0026ldquo;Switch Frame\u0026rdquo; in AV1 specification that allows shorter segments in ABR, enabling low latency live streaming without the burden of using bit-consuming IDR frames. A segment can start with a \u0026ldquo;Switch Frame\u0026rdquo; and the video player can switch resolution at any segment boundary.\n  EVE AV1 encoder Ronald Bultje, who designed VP9 at Google previously, introduced the world to Efficient Video Encoder (EVE) for AV1 at Big Apple Video. EVE is a commercial encoder that promises to provide the best visual quality amongst the AV1 encoders. Here are some interesting slides from Ronald\u0026rsquo;s presentation especially the quality comparison versus libaom AV1. The whole presentation can also be viewed below.\n   Cisco\u0026rsquo;s real-time AV1 video encoder At Big Apple Video, Cisco showed a closed-source implementation of their AV1 encoder that real-time, high quality AV1 encoder optimized for video collaboration. The demo inlcuded real-time AV1 encoding and transmission in a Webex video meeting, with HD video at 720p30 and high- framerate desktop share at 1080p30. The demo encoding which was done on a commodity laptop was at half the bandwidth of H.264 for 720p30 and 2/3 bitrate of H.264 of for 1080p30. The implementation included a full cloud media stack which was used to encode to AV1 video rather than the commodity laptop, with AV1-enabled switching servers deployed on the internet, with complete end-to-end call signaling and resilient media transmission.\nRead more about Cisco\u0026rsquo;s implementation here https://blogs.cisco.com/collaboration/cisco-leap-frogs-h-264-video-collaboration-with-real-time-av1-codec\nWatch the live demo at the Big Apple Video presentation below:\n   Millicast\u0026rsquo;s real-time AV1 video encoder Cisco wasn\u0026rsquo;t the only demonstrating a real-time AV1 video encoder in June! At CommCon UK, Millicast announced availability of one-to-many, real-time low-latency video stream capability using AV1 in WebRTC. In a contrast to Cisco who declined to open-source their real time implementation, Millicast is committing to making the binaries publicly available for everyone to benchmark and test. There are also discussions around open-sourcing this implementation.\nRead more about the announcement below as well as the slides from the presentation.\nhttps://medium.com/millicast/millicast-demonstrates-real-time-video-broadcasting-using-av1-at-commcon-2019-6256f47d0065\nPrevious ecosystem updates  AV1 Ecosystem Update May 2019 AV1 Ecosystem Update April 2019  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video!  Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-june-2019/","summary":"It\u0026rsquo;s been a pretty busy for me professionally which is why this month\u0026rsquo;s AV1 ecosystem update is coming in pretty late. It\u0026rsquo;s been one of the most exciting months for AV1 development and a lot to catch up on! With so much news this month, it is starting to feel like we\u0026rsquo;re at the cusp of something big! (which we hope AV1 will be )\nYoutube pauses AV1 rollout Currently, YouTube is the biggest streaming platform delivering AV1 video and is responsible for the majority of AV1 video consumption on the internet.","title":"AV1 Ecosystem Update: June 2019"},{"content":"This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we\u0026rsquo;ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:\n https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/ https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/ https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/  Streaming video takes center stage Streaming video has now become the main source of content consumption for many consumers. The number of consumers paying for streaming video services has skyrocketed in recent years. A recent survey by Deloitte concluded that for the first time more US consumers pay for streaming video services (69%) than they do for cable or satellite TV (65%). It is not surprising that streaming video has taken over given the excellent ad-free user experience.\nThe key component to making streaming video possible is the internet bandwidth because the quality of video being streamed is directly proportional to number of bits used to represent the pixels in the video i.e. bitrate. Therefore, a video with a higher resolution (i.e. larger number of pixels) requires a higher bitrate which translates to the user needing more bandwidth to stream the video successfully. To make this business model work without requiring every user to sign up for the highest speed internet plan, streaming video providers rely on video compression codecs such as H.264, VP9, H.265 etc. These codecs allow delivery of physical media (Blu-ray) like quality when viewed at normal TV -\u0026gt; couch distances for a fraction of the bitrate.\nThere\u0026rsquo;s a problem in paradise The video compression space is always evolving due to the constraints placed by available internet bandwidth especially in mobile scenarios. The most popular video codec in use today is AVC/H.264 codec which is owned by the Motion Picture Experts Group (MPEG). Before a content creator can distribute video in H.264 format It\u0026rsquo;s successor H.265 was approved in 2013 and expected to offer about 25% to 50% bitrate savings for the same quality. However, H.265 has not been able to capture the market in the same way H.264 did due to its patent licensing fees which can be as high as $25 million annually. Youtube is one of the most notable streaming properties to skip H.265 adoption and rely on Google\u0026rsquo;s own VP9 codec. When one of the top video streaming sites doesn\u0026rsquo;t adopt the latest and greatest, you know there\u0026rsquo;s a problem!\nA problem is just an opportunity! In 2015, a bunch of internet, content creator and browser companies realized this problem and formed the Alliance for Open Media (AOMedia) which features some of the biggest names including Amazon, Apple, ARM, Cisco, Facebook, Google, IBM, Intel, Microsoft, Netflix and NVIDIA. The first order of business for AOMedia consortium is to deliver a state-of-the-art codec that is also royalty free. AV1, released in 2018 fulfills that vision and promises to deliver 30% better compression than H.265! Youtube has already started testing videos with AV1 through its TestTube page. Netflix has also shown support for AV1 by calling it \u0026ldquo;our primary next-gen codec\u0026rdquo;.\nVideo codecs generations diagram by Tsahi Levent-Levi (source)  AV1 is based largely on Google\u0026rsquo;s VP9 codec and incorporates tools and technologies from Mozilla\u0026rsquo;s Daala, Cisco\u0026rsquo;s Thor, and Google\u0026rsquo;s VP10 codecs. In its current form, the AV1 encoder is quite slow compared to existing H.265 \u0026amp; H.264 encoders. But there are efforts underway by folks at Mozilla and Xiph to build an AV1 encoder that\u0026rsquo;s focused purely on speed from scratch \u0026ndash; rav1e!\nShots, Shots, Shots! Until the encoding speed of the AV1 encoders fares better when compared to existing encoders, this proof of concept introduces a potential way to speed up the overall encoding tasks. It does this by splitting the input video into \u0026ldquo;shots\u0026rdquo; and is inspired by Netflix\u0026rsquo;s approach to parallelizing their video encoding process. \u0026ldquo;Shots\u0026rdquo; as Netflix describes are \u0026ndash; \u0026ldquo;portions of video with a relatively short duration, coming from the same camera under fairly constant lighting and environment conditions. It captures the same or similar visual content, for example, the face of an actor standing in front of a tree and‚Ää\u0026mdash;‚Äämost important‚Ää\u0026mdash;‚Ääit is uniform in its behavior when changing coding parameters.\u0026quot;\nThe solution Strap in! This is going to be a long one!\nTL;DR To implement this solution, we need an algorithm that splits the input video into shots. Fortunately for us, Microsoft Video Indexer supports this scenario. Before getting started we\u0026rsquo;ll setup Video Indexer in our subscription. For the rest of the steps, here\u0026rsquo;s a quick overview of what\u0026rsquo;s going to happen:\n User uploads an MP4 video file to Azure Blob Storage Because of the Azure Event Grid integration with Azure Blob Storage, a file upload event triggers a notification The event notification is consumed by the first Logic App. The first step in the Logic App is to upload the video to Microsoft Video Indexer service Once the video is indexed, we retrieve the video insights and store it in the \u0026ldquo;insights\u0026rdquo; Azure File share While the video indexing is happening, we also copy the video file from Azure Blob Storage to the \u0026ldquo;source\u0026rdquo; Azure File share where it can be accessed by container instances later When the indexing is complete, an \u0026ldquo;Indexing complete\u0026rdquo; notification is sent to trigger the second Logic App In the second Logic App, the first step is to retrieve the video insights saved earlier Next, we use an Azure Function to parse the shots data and create our container instance definitions as well as shots encoding commands for each container instance Now we can use the Logic App-Container Instance connector to create container instances based on container instance definitions defined in the last step As the container instances finish their respective encoding jobs, they save the output video in the \u0026ldquo;shots\u0026rdquo; Azure File share Next, we trigger another Azure Function to iterate over the output files and create a ffmpeg concat file Once we have a concat file, we create another container instance with ffmpeg installed to execute the concat file The output of the preview container instance i.e. all the encoded shots files that are combined to one file is saved in the \u0026ldquo;output\u0026rdquo; Azure File share The user can then download the encoded file from the \u0026ldquo;output\u0026rdquo; Azure File share  User Experience While building this solution, I wanted to keep the user experience simple. Hence a user needs to take only these steps:\n Upload an MP4 video file to a specified Azure Blob Storage Account Download the encoded file from the \u0026ldquo;output\u0026rdquo; Azure File share  Results Below are the results of the speedup I was able to achieve using this solution. Continue on to Parts 2 \u0026amp; 3 to see how to build this solution.\nTest setup  To obtain these results I used the following docker image with a build of libaom AV1 https://hub.docker.com/r/offbytwo/ffmpeg Parallelism - 50x i.e. only 50 shots were encoding concurrently at any given time  Here is the total time it took to run the pipeline in each of the cases. If you look at the absolute total time, the improvement is ~7x with a 50x parallelisation factor. With a higher number of concurrent encodes, this number would be greater. However, in the case of shot-based encoding solution, there\u0026rsquo;s a big caveat below that needs to be considered.\nAbsolute numbers    Encoder type Time     Shot-based encoder (50x parallel) ~3 hrs*   Linear encoding 21.8 hrs    * - The times you see above are the total times it took for the pipeline to complete. In the shot-based solution the longest time it took to encode was 3 hours for shot 141 which were the credits. The total length of this shot was 1 minute 17 seconds. If you ignore this scene, then majority of the shots completed in less than 45 minutes\nPercentiles I\u0026rsquo;ve also plotted calculated the time taken to encode at various percentiles as shows below so we get a better idea of what the speedup is at these different data points. One example from the below data is the median (P50) speedup is 145x and at P99 the speedup is 20x!\n   Percentile Time (minutes) Speedup     50 9 145x   67 18 73x   90 37 35x   95 46 29x   99 66 20x   100 181 7x    Scatter Plot of time distribution Here is a scatter plot distribution of shot # vs the time taken to encode.\nNOTE: Because of the 50X parallelisation factor, majority shots #s \u0026lt; 50, spent around 10 minutes in queue waiting to begin encoding. The time here represents the total of time spent in queue + encoding time. If we increased the parallelisation factor and reduced the time spent in queue, then the distribution of time taken for shot #s \u0026lt; 50 would resemble those with shot # \u0026gt; 50.\nTo view the details and timecodes of the shots, view this JSON file\n https://github.com/singhkays/av1-serverless-shot-based-transcoder-azure/blob/master/tears-of-steel-shots-timecodes.json  End of Part 1 This is the end of Part 1. In Part 2, I will walk through step by step on how to implement this solution.\n https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/  AV1 resources  AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders It\u0026rsquo;s time to replace GIFs with AV1 video!  Contact Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/","summary":"This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we\u0026rsquo;ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:","title":"Part 1: Building a scalable 'shot-based' serverless AV1 video encoder in Azure"},{"content":"May was another amazing month for the AV1 codec! We saw great progress in the SVT-AV1 encoder, Android update news and some surprising news out of China!\nSVT-AV1 is making strides! Let\u0026rsquo;s start with SVT-AV1 encoder, the current encoder of choice for Netflix, being developed by the folks at Intel. In May, version 0.5.0 was released with the following features:\n 8 bit / 10 bit 4:2:0 up to 4K60p resolutions Presets 0-8 New API, FFmpeg, GStreamer plugins Rate control support (VBR, CVBR) Block sizes from 4x4 to 128x128 Non-square blocks Tiles Deblocking / CDEF / Restoration filters Film Grain Warped motion estimation Intra block copy Trellis quantized coefficient optimization Support for 4 and 5 layers prediction structures Chroma search in MD Multi-reference picture support  Other notable updates   May also saw the most number of commits to the SVT-AV1 Github repo as shown by the graph below. There were also 40 PRs merged in the month of May.   With so many new features, it was no suprise to see Phoronix report the performance boosts during their testing.   A reddit user Balance-, noted that SVt-AV1 now offered higher quality than x264, x265 \u0026amp; VP9 for the first time.\n  There was another PR merged that reduced the memory consumption by 35-70% across all presets!\n   https://github.com/OpenVisualCloud/SVT-AV1/releases/tag/v0.5.0 https://www.phoronix.com/scan.php?page=news_item\u0026amp;px=SVT-AV1-Ending-May-Faster https://www.reddit.com/r/AV1/comments/bt7l7a/svtav1_now_offers_higher_quality_than_x264_x265/ https://github.com/OpenVisualCloud/SVT-AV1/pull/2420  Android Q gets AV1 support May was also the month when the annual Google I/O conference was held. Onc of the announcements out of Google I/O was that the newest version of Android, codenamed Q, will support AV1 by default. This will surely be another step towards increasing the AV1 adoption.\n https://android-developers.googleblog.com/2019/03/introducing-android-q-beta.html  Firefox 67 release makes AV1 decoding default on all desktop platforms With the release of Firefox 67, AV1 decoding is now enabled by default on all desktop platforms (Windows, OSX and Linux) for both 32-bit and 64-bit systems. Firefox 67 is also the first time the AV1 decoder has switched to dav1d by default. Sponsored by the Alliance for Open Media, dav1d is a joint effort between the French non-profit VideoLAN and the greater FFmpeg open source audio/video community. In the April ecosystem update, I talked about the dav1d 0.3.0 release and the performance improvements it brought with it, so it\u0026rsquo;s very exciting to see Firefox use dav1d by default!\n https://hacks.mozilla.org/2019/05/firefox-brings-you-smooth-video-playback-with-the-worlds-fastest-av1-decoder/  Visionular Aurora AV1 codec claims it\u0026rsquo;s faster and better than x265 Another piece of interesting news was the Visionular Aurora AV1 codec that I first read about in this summary of LiveVideoStackCon Shanghai 2019. In this presentation it is claimed that Aurora AV1 beats libaom encoder by ~33% and x265 by ~42% on VMAF model.\nFrom Visionular website, Auorara claims to improve encoding speed by 32.2% against x265 veryslow which is very surprising and the first time I\u0026rsquo;m hearing about an AV1 encoder being better in quality and faster than x265. It\u0026rsquo;ll be interesting to see if we find out more info and are able to test this encoder in the coming months.\nBBC compares AV1 \u0026amp; VVC Joint Video Experts Team (JVET) is currently working on the successor to the H.265/HEVC codec which is called Versatile Video Coding (VVC). VVC is currently in development and is to be finalised in 2020. In this test BBC, VVC performed 27% better than the HEVC for HD sequences and 35% for UHD sequences. Also, in this test AV1 was shown to perform similar to HEVC. Without any encoding parameters and details on testing methodology, I would call this test flawed as AV1 has consistently shown to perform better than HEVC.\nAmphion Semiconductor Hardware decoder Amphion Semoconductor announced the availalability of its 4K/UHD capable hardware decoder for AV1. I beleive this might be the first hardware SoC designed to decode AV1.\n https://www.amphionsemi.com/news/ https://www.businesswire.com/news/home/20170306005675/en/AMPHION-releases-2-extended-performance-variants-highly  Previous updates  AV1 Ecosystem Update: April 2019  Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-may-2019/","summary":"May was another amazing month for the AV1 codec! We saw great progress in the SVT-AV1 encoder, Android update news and some surprising news out of China!\nSVT-AV1 is making strides! Let\u0026rsquo;s start with SVT-AV1 encoder, the current encoder of choice for Netflix, being developed by the folks at Intel. In May, version 0.5.0 was released with the following features:\n 8 bit / 10 bit 4:2:0 up to 4K60p resolutions Presets 0-8 New API, FFmpeg, GStreamer plugins Rate control support (VBR, CVBR) Block sizes from 4x4 to 128x128 Non-square blocks Tiles Deblocking / CDEF / Restoration filters Film Grain Warped motion estimation Intra block copy Trellis quantized coefficient optimization Support for 4 and 5 layers prediction structures Chroma search in MD Multi-reference picture support  Other notable updates   May also saw the most number of commits to the SVT-AV1 Github repo as shown by the graph below.","title":"AV1 Ecosystem Update: May 2019"},{"content":"Bitstream spec  https://aomediacodec.github.io/av1-spec/  Encoder Implementations SVT-AV1 Homepage  https://01.org/svt  Source repo  https://github.com/OpenVisualCloud/SVT-AV1  User-Guide  https://github.com/OpenVisualCloud/SVT-AV1/blob/master/Docs/svt-av1_encoder_user_guide.md  Roadmap Trello page\nMicrosoft Azure whitepaper  https://01.org/sites/default/files/documentation/svt_azure_wp.pdf  Amazon Web Services (AWS) Whitepaper  http://01.org/sites/default/files/documentation/svt_aws_wp.pdf  Mailing List  http://lists.01.org/mailman/listinfo/svt-av1  aomenc Homepage and Source repo  https://aomedia.googlesource.com/aom/  rav1e Homepage, Source repo  https://github.com/xiph/rav1e  Decoder Implementations dav1d Homepage, Source repo  https://code.videolan.org/videolan/dav1d  Presentations   Mozilla @ NAB 2019 [April 2019 by Nathan Egge]\n  AOM - AV1How does it work? [July 2017 by Pascal Massimino]\n  Videos   Video @Scale 2018 - Yue Chen, Google Yue Chen, Senior AV1 Engineer at Google, gives a technical overview of the AV1 video codec.\n  YouTube AV1 Playlist Beta\n  The AV1 Video Codec @ The Linux Conf (New Zealand, Jan 2019)\n  Introducing AV1 and Open Video Codecs by Nathan Egge and Michael Bebenita\n  HEVC vs AV1 by Ian Trow\n  Into the Depths: The Technical Details behind AV1 by Nathan Egge\n  Comparisons  MSU Codec Comparison 2018  Software   ffmpeg builds (4.1+)\n  Microsoft AV1 Video Extension (Beta) for Windows 10\n  dav1d decoder (Included in VLC player 3.0.5+)\n  Windows builds\n  aomenc\n  rav1e\n  SVT-AV1\n    Research Papers  An Overview of Core Coding Tools in the AV1 Video Codec  ","permalink":"https://singhkays.com/blog/av1-wiki-resources-tools/","summary":"Bitstream spec  https://aomediacodec.github.io/av1-spec/  Encoder Implementations SVT-AV1 Homepage  https://01.org/svt  Source repo  https://github.com/OpenVisualCloud/SVT-AV1  User-Guide  https://github.com/OpenVisualCloud/SVT-AV1/blob/master/Docs/svt-av1_encoder_user_guide.md  Roadmap Trello page\nMicrosoft Azure whitepaper  https://01.org/sites/default/files/documentation/svt_azure_wp.pdf  Amazon Web Services (AWS) Whitepaper  http://01.org/sites/default/files/documentation/svt_aws_wp.pdf  Mailing List  http://lists.01.org/mailman/listinfo/svt-av1  aomenc Homepage and Source repo  https://aomedia.googlesource.com/aom/  rav1e Homepage, Source repo  https://github.com/xiph/rav1e  Decoder Implementations dav1d Homepage, Source repo  https://code.videolan.org/videolan/dav1d  Presentations   Mozilla @ NAB 2019 [April 2019 by Nathan Egge]","title":"AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders"},{"content":"It\u0026rsquo;s been an exciting time following the progress of the royalty free video codec AV1 over the past year and April might just be the most exciting active month in the amount of news we got about AV1! It\u0026rsquo;s not every day that media industry giants such as Netflix, Google, Mozilla, Microsoft, Apple, Amazon, ARM, Facebook, Nvidia, Intel, Cisco and many others agree on the same technology stack!\nSamsung joins the party The month started with Samsung announcing they were joining the Alliance of Open Media Board at the highest level.\nSamsung Joins the Alliance for Open Media Board of Directors\nIntel and Netflix are joining forces At NAB 2019, Netflix announced they had selected Intel\u0026rsquo;s SVT-AV1 encoder for their workflow.\nAlthough surprising at first, given the gulf in visual quality between the aomenc encoder vs the SVT-AV1 encoder at the moment, Netflix posted a techblog few days later explaining the rationale.\n At Netflix, we believe that the AV1 ecosystem would benefit from an alternative clean and efficient open-source encoder implementation. There exists at least one other alternative open-source AV1 encoder, rav1e. However, rav1e is written in Rust programming language, whereas an encoder written in C has a much broader base of potential developers. The open-source encoder should also enable easy experimentation and a platform for testing new coding tools. Consequently, our requirements to the AV1 software are as follows:\n   Easy to understand code with a low entry barrier and a test framework Competitive compression efficiency on par with the reference implementation Complete toolset and a decoder implementation sharing common code with the encoder, which simplifies experiments on new coding tools Decreased encoder runtime that enables quicker turn-around when testing new ideas   MSU Codec Comparison 2018 In April, we also got the yearly Moscow State University codec comparison report. This can be viewed below\nAs expected, AV1 came in first place!\nMozilla\u0026rsquo;s NAB 2019 presentation At NAB 2019, we also heard from Mozilla on the latest technical and business progress of AV1 and accomplishments in the last year. The presentation is embedded below:\ndav1d 0.3.0 release Near the end of April, we saw 0.3.0 release of dav1d decoder codenamed \u0026lsquo;Sailfish\u0026rsquo;. This release brought with it another set of awesome speedups compared to 0.2.1\n +24% performance on SSSE3 +26% performance on SSE4.1 +4% performance on AVX2 +12% performance on Arm64  Ewout ter Hoeven wrote an amazing summary here capturing all the pull requests that made the improvement as well as many charts showing performance improvements amongst different videos.\nSVT-AV1\u0026rsquo;s big update After going silent for most of the month, SVT-AV1 got a big commit with many new features!\n Trellis Multi-reference pictures support Chroma search Tiles enc dec mismatch fix / tiles bitrate overhead fix Enhanced Adaptive Depth partitioning algorithm Cabac Update New M0-M8 Preset tuning Quality and Stability bug fixes  AVIF POC and libraries Kagami Hiiragi published a very interested PoC for the AV1 derived image format \u0026ndash; AVIF here and demonstrated how to use AVIF in the browsers today.\nReach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/av1-ecosystem-update-april-2019/","summary":"It\u0026rsquo;s been an exciting time following the progress of the royalty free video codec AV1 over the past year and April might just be the most exciting active month in the amount of news we got about AV1! It\u0026rsquo;s not every day that media industry giants such as Netflix, Google, Mozilla, Microsoft, Apple, Amazon, ARM, Facebook, Nvidia, Intel, Cisco and many others agree on the same technology stack!\nSamsung joins the party The month started with Samsung announcing they were joining the Alliance of Open Media Board at the highest level.","title":"AV1 Ecosystem Update: April 2019"},{"content":"In Azure, every VM has a persistent OS Disk that is used for booting the VM and contains the operating system. In addition to an OS disk, each VM also has a temporary disk that is present on the compute cluster hosting your VM.\nWhy is my OS disk not @ /dev/sda? In most cases the OS disk is /dev/sda but in some odd cases it is not. This is not an Azure specific issue but a default Linux behavior. The ordering in which Linux enumerates SCSI devices is nondeterministic. It scans SCSI devices in the order they appear on the PCI Bus. Therefore, whichever disk is enumerated first is /dev/sda.\nOK, so how to identify my disks? To resolve this problem, use persistent naming. There are four ways to use persistent naming in Linux:\n filesystem label UUID ID path.  Generally, it is recommend to use the filesystem label or UUID for Azure Linux VMs.\nLet there be disks! OS and temporary disks When the Azure Linux agent is installed on a VM, the agent uses udev rules to construct a set of symbolic links under the /dev/disk/azure path. There, /dev/disk/azure is the first place you should look. Using this path, we can identify the different disk types attached to the VM as well the LUNs for data disks.\nWe can take a look at these symbolic links to identify the disks.\nkay@uuidvm:~$ ls -l /dev/disk/azure total 0 lrwxrwxrwx 1 root root 9 Apr 30 17:48 resource -\u0026gt; ../../sdb lrwxrwxrwx 1 root root 10 Apr 30 17:48 resource-part1 -\u0026gt; ../../sdb1 lrwxrwxrwx 1 root root 9 Apr 30 17:48 root -\u0026gt; ../../sda lrwxrwxrwx 1 root root 10 Apr 30 17:48 root-part1 -\u0026gt; ../../sda1 lrwxrwxrwx 1 root root 11 Apr 30 17:48 root-part14 -\u0026gt; ../../sda14 lrwxrwxrwx 1 root root 11 Apr 30 17:48 root-part15 -\u0026gt; ../../sda15 drwxr-xr-x 2 root root 120 Apr 30 22:24 scsi1 Based on the above output, we can identify the following disks and their paths:\n /dev/disk/azure/root-part1 - OS Disk /dev/disk/azure-resource-part1 - Temporary/Resource Disk  Data Disks For data disks, we can use the tree command like shown below. Using this command, we can also identify the LUN numbers for the data disks\nkay@uuidvm:~$ tree /dev/disk/azure /dev/disk/azure ‚îú‚îÄ‚îÄ resource -\u0026gt; ../../sdb ‚îú‚îÄ‚îÄ resource-part1 -\u0026gt; ../../sdb1 ‚îú‚îÄ‚îÄ root -\u0026gt; ../../sda ‚îú‚îÄ‚îÄ root-part1 -\u0026gt; ../../sda1 ‚îú‚îÄ‚îÄ root-part14 -\u0026gt; ../../sda14 ‚îú‚îÄ‚îÄ root-part15 -\u0026gt; ../../sda15 ‚îî‚îÄ‚îÄ scsi1 ‚îú‚îÄ‚îÄ lun0 -\u0026gt; ../../../sdc ‚îú‚îÄ‚îÄ lun0-part1 -\u0026gt; ../../../sdc1 ‚îú‚îÄ‚îÄ lun9 -\u0026gt; ../../../sdd ‚îî‚îÄ‚îÄ lun9-part1 -\u0026gt; ../../../sdd1 Based on the above output, we can identify the following data disks and their LUNs\n lun0-part1 \u0026ndash; Data Disk 1 mounted at LUN 0 lun9-part2 \u0026ndash; Data Disk 2 mounted at LUN 9  In Azure, the VM disks properties page looks like below\nA disk by any other name Now, we need to find how to refer to these disks in our scripts and applications. For that, we\u0026rsquo;ll run the following command\nkay@uuidvm:~$ sudo blkid -s UUID /dev/sdb1: UUID=\u0026#34;420dd50e-9a61-4e26-9d24-5d399065ec52\u0026#34; /dev/sda1: UUID=\u0026#34;eb5f4234-4e60-46a9-a0dc-76fd1a593cdd\u0026#34; /dev/sda15: UUID=\u0026#34;D183-43BF\u0026#34; /dev/sdc1: UUID=\u0026#34;27230452-56a6-4aba-9c90-77071488ece5\u0026#34; /dev/sdd1: UUID=\u0026#34;28372da4-8adc-4be0-b1a8-7f51248f91ab\u0026#34; With the above information, we can refer to our boot disk in the ls command as follows\nkay@uuidvm:~$ ls -l /dev/disk/by-uuid/eb5f4234-4e60-46a9-a0dc-76fd1a593cdd lrwxrwxrwx 1 root root 10 Apr 30 17:48 /dev/disk/by-uuid/eb5f4234-4e60-46a9-a0dc-76fd1a593cdd -\u0026gt; ../../sda1 Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/how-to-identify-azure-linux-vm-disks/","summary":"In Azure, every VM has a persistent OS Disk that is used for booting the VM and contains the operating system. In addition to an OS disk, each VM also has a temporary disk that is present on the compute cluster hosting your VM.\nWhy is my OS disk not @ /dev/sda? In most cases the OS disk is /dev/sda but in some odd cases it is not. This is not an Azure specific issue but a default Linux behavior.","title":"How to identify boot, temp and data disks in Azure Linux VMs"},{"content":"It is 2019 and we need to make a decision about GIFs (no, not that one! We‚Äôre never going to be able to decide that one!). GIFs take up a massive amount of space (often multiple megabytes!) and if you‚Äôre a web developer, then that‚Äôs completely against your ethos! As a web developer, you want to minimize the bits your users need to download so that your website loads fast. That‚Äôs why you minify javascript, optimize PNGs, JPEGs and sometimes turn JPEGs to WebPs as well. But then what about the venerable GIF?\nWhere we are going, we don‚Äôt need no GIFs! If your goal is to improve your website\u0026rsquo;s loading performance, then a GIF needs to be yanked! But then how do you have moving pictures? The answer is a video. And in most cases, you‚Äôll get better quality as well as almost 50-90% size savings! In life, most things have a pro and a con. When you‚Äôre replacing a GIF with a video, in majority of the cases you‚Äôll be hard pressed to find a con\nReplace all the GIFs! Fortunately, replacing GIFs with video has now been common for a few years so the tools needed to pull off this trick are already in play. In this blog, I‚Äôm not going to break new ground, but improve upon what already exists. So, here‚Äôs the lowdown on what you can currently do:\n Take a GIF and convert it into video Encode it with H.264 or VP9 codec i.e. compress it and package in a MP4 of WebM container Replace animated GIF \u0026lt;img\u0026gt; elements with \u0026lt;video\u0026gt; Set the video to play automatically, sliently and in a loop to replicate the GIF functionality  Google has a good documentation page describing the process.\nIt is 2019 It‚Äôs 2019. Tech moves forward and we need to move with it. Until now you‚Äôve had two choices of codecs that are widely adopted across all browsers and platforms for encoding the video:\n H.264 ‚Äì Introduced in 2003 and the most widely used codec today VP9 ‚Äì Introduced in 2013 and achieves up to 50% more compression compared to H.264 most of the times but it can look worse sometimes according to this discussion on reddit.   NOTE: Even though H.265 is the next-gen version of H.264 and competes with VP9, I\u0026rsquo;m not including it in this comparison becuase of lack of browser support as noted on https://caniuse.com/#feat=hevc. Licensing costs is the major reason why H.265 is not as widely adopted as H.264 and why Alliance of Open Media consortium is working a royalty-free codec i.e. AV1.\n Remember, our goal is to reduce the humongous GIF to as small a size as possible to improve our webpage loading time. It wouldn‚Äôt be 2019 if we didn‚Äôt have a new video compression standard we could encode to. This is called AV1. With AV1, we are able to achieve ~30% more compression compared to VP9. Exciting! :)\nServing you AV1 since 2019! On desktop Recently, support for decoding AV1 video has been enabled in desktop versions of Google Chrome 70 and Mozilla Firefox 65. At present, support in Firefox is buggy and can cause crashes but is expected to improve with the adoption of the dav1d decoder in Firefox 67. For more info on the dav1d decoder and the latest release, see dav1d 0.3.0 release: even faster!.\nOn smartphones For smartphones, the support is lacking at present but that\u0026rsquo;s to be expected due to the lack of hardware decoders. Without hardware decoders, the decoding can be done in software without any hiccups but it would cause an increase in battery consumption. The first set of mobile SOCs with hardware decoding support for AV1 are expected to come to market in 2020.\nTarget audience of this article AKA \u0026ldquo;If mobile users can\u0026rsquo;t decode, then why adopt AV1?\u0026rdquo; AV1 is a fairly new codec and we\u0026rsquo;re at the beginning of it\u0026rsquo;s adoption curve. Think of this article as the build-it phase of \u0026ldquo;If you build it, they will come\u0026rdquo; approach. We know with desktop browser support, we can enable a subset of the market and reduce the amount of data downloaded. We an also employ a strategy where we can fallback to supported codecs on user devices if AV1 support is not enabled. When these users upgrade to devices with AV1 support, they will automatically get the smaller AV1 video. To enable this we\u0026rsquo;ll need to create a video tag like below which will allow us to serve the videos in this preference order - AV1-\u0026gt;VP9-\u0026gt;H.264. If a user has a really old browser or a device that cannot decode any of the videos (highly unlikely with H264 video inluded), then they would just get the GIF file üòû\n\u0026lt;video style=\u0026#34;display:block; margin: 0 auto;\u0026#34; autoplay loop muted playsinline poster=\u0026#34;RollingCredits.jpg\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;media/RollingCredits.av1.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;media/RollingCredits.vp9.webm\u0026#34; type=\u0026#34;video/webm\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;media/RollingCredits.x264.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;media/RollingCredits.gif\u0026#34;\u0026gt; \u0026lt;/video\u0026gt; The AV1 recipe Creating an AV1 video is pretty simple. Download the latest build of ffmpeg for your platform from here and use the below commandline. We‚Äôre going to be using a 2-pass encoding mode to achieve a target bitrate. For this, we‚Äôll run ffmpeg twice. In the first pass we‚Äôll output to a null file descriptor, not an actual file. This generates a logfile that ffmpeg needs for the second pass.\n# Linux or Mac ## Pass 1 ffmpeg -i input.mp4 -c:v libaom-av1 -b:v 200k -filter:v scale=720:-1 -strict experimental -cpu-used 1 -tile-columns 2 -row-mt 1 -threads 8 -pass 1 -f mp4 /dev/null \u0026amp;\u0026amp; \\ ## Pass 2 ffmpeg -i input.mp4 -pix_fmt yuv420p -movflags faststart -c:v libaom-av1 -b:v 200k -filter:v scale=720:-1 -strict experimental -cpu-used 1 -tile-columns 2 -row-mt 1 -threads 8 -pass 2 output.mp4 # Windows ## Pass 1 ffmpeg.exe -i input.mp4 -c:v libaom-av1 -b:v 200k -filter:v scale=720:-1 -strict experimental -cpu-used 1 -tile-columns 2 -row-mt 1 -threads 8 -pass 1 -f mp4 NUL \u0026amp;\u0026amp; ^ ## Pass 2 ffmpeg.exe -i input.mp4 -pix_fmt yuv420p -movflags faststart -c:v libaom-av1 -b:v 200k -filter:v scale=720:-1 -strict experimental -cpu-used 1 -tile-columns 2 -row-mt 1 -threads 8 -pass 2 output.mp4 Here‚Äôs an explanation of what the command line options do\n-i - Used to specify the input file -pix_fmt - Use to specify the 4:2:0 chroma subsampling for the color information in the video. There are many different pixel formats but 4:2:0 is the most compatible, hence we specify that here. -c:v - Used to specify the encoder to use i.e. AV1 in this case -b:v ‚Äì Used to specify the average bitrate we want to achieve -filter:v scale - ffmpeg‚Äôs scale filter to reduce the resolution of the video. We specify this in the X:-1 format which tells ffmpeg to reduce the width of the video to X while and automatically set height that maintains the aspect ratio -strict experimental - Used because AV1 is a fairly new encoder -cpu-used - Horribly named parameter but this is way to select the level of quality we want to achieve. Valid values are 0-4. Lower values (i.e. closer to 0) mean more quality as well as more encoding time taken -tile-columns - Used to achieve multi-threading. Tells the AV1 encoder to split the scene into separate columns which can then be encoded independently of each other, thereby increasing CPU usage -row-mt ‚Äì Similar concept as columns above but for rows within those columns -threads - # of threads the encoder can use -pass - Which pass the command executes -f - Only used in the first pass. Specifies the format of the output file in the second pass i.e. MP4 in this case -movflags faststart - Enables fast start of video by moving some data to the beginning of the file. This allows the video to be played before it is completely downloaded GIF recipe For generating the GIF, I used the below command. To reduce the size of the GIF, I scaled the GIF to 720px wide and 12 fps instead of 24 fps source video.\n./ffmpeg -i /mnt/c/Users/kasing/Desktop/ToS.mov -ss 00:08:08 -t 12 -filter_complex \u0026#34;[0:v] fps=12,scale=720:-1\u0026#34; -y scene2.gif Test Results The proof is in the pudding, right? Let‚Äôs see why AV1 is the right codec for this choice of work. I took the open source video Tears of Steel available here https://mango.blender.org/ and encoded it to approximately similar bitrates for AV1, VP9, H.264 codecs. The resulting files are looping below so you can compare between them.\n NOTE 1: If a file below doesn‚Äôt load for you, it‚Äôs possible you‚Äôll need to update your browser. If your browser doesn\u0026rsquo;t work, I suggest using browsing in a Chromium based browser such as Chrome, Vivaldi, Brave or Opera. Here\u0026rsquo;s the latest on browser support for AV1 https://caniuse.com/#feat=av1\n  NOTE 2: For Firefox 66 on Linux, you\u0026rsquo;ll need to set the media.av1.enabled flag to true in about:config\n  NOTE 2: I\u0026rsquo;m not including the GIFs inline below due to their large size and amount of data it will take to load this page! (Also would be ironic as that\u0026rsquo;s what I\u0026rsquo;m to get us away from :)). But you can view the GIFs here https://github.com/singhkays/its-time-replace-gifs-with-av1-video/blob/master/GIFs\n Scene 1 @ 200 Kbps This is a high motion scene so it really stresses the encoders at low bitrates. We quickly see how bad H.264 is at this bitrate exhibiting extreme blockiness. VP9 improves things a bit but you can still notice some blockiness. AV1 clearly wins in this test rendering a clearly better image.\nH.264  VP9  AV1  Scene 2 @ 200 Kbps This scene shows off a lot of translucent CGI generated content. The results are a lot closer than the last scene but overall AV1 ends up being the best.\nH.264  VP9  AV1  Scene 3 @ 100 Kbps In this scene, we really dial down the bitrate to 100 Kbps and the results are no surprise. AV1 maintains it‚Äôs advantage at this low bitrate as well!\nH.264  VP9  AV1  Encore To really drive home the point of the amount of space savings compared to a GIF ‚Äì The total size of all the videos embedded above is \u0026hellip;. 1.62 MB!! That‚Äôs right. 1,708,032 freakin bytes! For comparison, here‚Äôs the GIF and AV1 video size for each of the scenes\n    GIF AV1     Scene 1 11.7 MB 0.33 MB   Scene 2 7.27 MB 0.18 MB   Scene 3 5.62 MB 0.088 MB    Absolutely mind blowing! Isn‚Äôt it?\n NOTE: I haven\u0026rsquo;t listed out the file sizes for VP9 and H264 because they are very similar to AV1 because of using the same bitrate for all codecs. Also, it would be redundant to add two more columns with similar sizes just to make the point that these codecs offer much better quality than GIF at highly reduced file sizes.\n Changelog 2019-04-28\n Published v1  2019-05-09\n Updated size of Scene 2 GIF to 7.27 MB. This was erroneously specified as 9.06 MB before. Added links to GIFs based on Hacker News comment Added info about why H.265 wasn\u0026rsquo;t included in this comparison Added a link to latest browser support for AV1 Added more info on desktop vs browser compatibility  Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/its-time-replace-gifs-with-av1-video/","summary":"It is 2019 and we need to make a decision about GIFs (no, not that one! We‚Äôre never going to be able to decide that one!). GIFs take up a massive amount of space (often multiple megabytes!) and if you‚Äôre a web developer, then that‚Äôs completely against your ethos! As a web developer, you want to minimize the bits your users need to download so that your website loads fast. That‚Äôs why you minify javascript, optimize PNGs, JPEGs and sometimes turn JPEGs to WebPs as well.","title":"It's time to replace GIFs with AV1 video!"},{"content":"Azure Video Indexer is one of my favorite services! It provides some amazing features such as:\n Identify faces and celebrities Extract text and objects (e.g. cat, table, car etc.) Detect scenes and shots Emotion and sentiment detection Audio effects such as clapping, silence \u0026amp; speech  The full list of features can be viewed at https://vi.microsoft.com/en-us/\nGet the credits rolling! Recently, Video Indexer announced they‚Äôve added the capability to detect rolling credits in the videos. One of the key scenarios enabled by this feature is the ability for video owners to identify a natural point in the video where they can recommend the next episode or show aka Netflix autoplay experience as shown below:\nTesting the rolling credits! To test this out, I uploaded an open source video by the Blender foundation ‚Äì Tears of Steel to Video Indexer. Once the video has completed indexing, I downloaded the insights JSON from the video details page like shown below:\nRolling credits JSON object can be accessed in the two places\n The labels object currently with id = \u0026quot;-1\u0026quot;. The full path is jsonObj[\u0026quot;summarizedInsights\u0026quot;][\u0026quot;labels\u0026quot;][4][\u0026quot;id\u0026quot;] The \u0026ldquo;framePatterns\u0026rdquo; object with id = \u0026quot;0\u0026quot;. The full path is jsonObj[\u0026quot;videos\u0026quot;][0][\u0026quot;insights\u0026quot;][\u0026quot;framePatterns\u0026quot;][0][\u0026quot;id\u0026quot;]  The Rolling Credits object for the Tears of Steel has the following time values according to Video Indexer\n{ \u0026#34;id\u0026#34;: -1, \u0026#34;name\u0026#34;: \u0026#34;RollingCredits\u0026#34;, \u0026#34;appearances\u0026#34;: [ { \u0026#34;startTime\u0026#34;: \u0026#34;0:10:31\u0026#34;, \u0026#34;endTime\u0026#34;: \u0026#34;0:11:50\u0026#34;, \u0026#34;startSeconds\u0026#34;: 631, \u0026#34;endSeconds\u0026#34;: 710 } ] } The results When looking through the actual video, I noticed that there are a non-traditional set of credits that start at 9 min 49 second. This is surprising as Video Indexer thinks the credits should begin at 10 min 31 second mark.\nWhen we look at the 10 min 31 second mark, I see the traditional ‚ÄúRolling Credits‚Äù that move up slowly, start as expected. At first I was surprised but then I realized Video Indexer isn\u0026rsquo;t taking into account the different ending credit design. Maybe that\u0026rsquo;ll come in the future but this should be good enough to achieve our Netflix auto-play scenario! :) Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/detect-rolling-credits-video-indexer/","summary":"Azure Video Indexer is one of my favorite services! It provides some amazing features such as:\n Identify faces and celebrities Extract text and objects (e.g. cat, table, car etc.) Detect scenes and shots Emotion and sentiment detection Audio effects such as clapping, silence \u0026amp; speech  The full list of features can be viewed at https://vi.microsoft.com/en-us/\nGet the credits rolling! Recently, Video Indexer announced they‚Äôve added the capability to detect rolling credits in the videos.","title":"Detect Rolling Credits with Azure Video Indexer"},{"content":"We‚Äôre living in a golden age of web browser choice. But before I begin this story, I need to take you back to 2006. You see back in 2006 as a young technologist, my choices of a web browser were limited. It was either Internet Explorer or Mozilla Firefox. But then one day while browsing through PC World magazine, I discovered an alternate option ‚Äì Opera.\nOpera had many differentiated features such as a customizable streamlined user interface as well as being more memory efficient and faster than Firefox. There were many other features that made Opera my go-to browser but the most important for my browsing on a 256 Kbps turned out to be the ‚ÄúInstant-back‚Äù. Normally, when you press the back button in a browser, it will try to reload the page but in Opera the page loaded from cache, so the back action was instant!\nGoogle has a say In September 2008, everything changed when Google decided to enter the browser market with Chrome. I remember downloading the first beta of Chrome and thinking this is fantastic! What Chrome was lacking in features, it made up in speed. Since then, Chrome has gained massive popularity and become the most popular browser in the market. These days, Chrome enjoys a position of dominance that Internet Explorer once held. All new websites were developed to work with Internet Explorer, something which developers do for Chrome today. Looking at the Google trends chart over the last 15 years below will give you an idea of how Chrome‚Äôs popularity has risen over time.\nThe \u0026ldquo;Other Chromes\u0026rdquo; Along with the release of Chrome, Google also provided majority of the source code used to build Chrome in the form of Chromium project. Using this source code, many other companies have been able to build alternate browsers on the same stable and fast engine that powers Chrome. Free from having to invest resources in building and maintaining a rendering engine, these companies have been able to focus on adding features that are missing from the Chromium source such as syncing of settings and bookmarks as well as features that are sometimes not even available in Chrome (e.g. Opera introduced video pop out 2 years before Chrome). And because these browsers are built on a Chromium source, they are able to access the extensions in the Chrome Web store as well.\nI‚Äôm calling these browsers - ‚ÄúThe Other Chromes‚Äù. This blog is a summary of the budding alternate Chromium based browser market and how these browsers are vying to take market share away from Chrome with their unique features. These browsers have been increasing in number as well as popularity. Part of the charm of these browsers is that they allow privacy focused users to step outside of Google‚Äôs ecosystem without compromising on performance.\nOpera   Before adopting Chromium projects WebKit engine and later Blink engine in 2013, Opera developed its own Presto engine. With the move to the Chromium source, Opera lost many of its distinctive features such as integrated Opera mail. Since then, Opera has been busy differentiating itself from Chrome with its unique features. Here are some of the standout features:\n1. Video Picture-in-Picture (PiP) ‚Äì I find this the most impressive feature of Opera. Video PiP was introduced in April 2016, which is a full two years before Chrome got the same feature. Still, I find Opera‚Äôs picture-in-picture more useful. Currently, Chrome‚Äôs PiP requires two right clicks to activate compared to Opera which has a dedicated floating button on the video to activate PiP. Opera‚Äôs PiP is also a lot more useful as it shows video controls such as the video name, button for skipping to next video, volume control and video time indicator. You can even click the video name in the PiP window to be taken back to the tab in the browser! Chrome has a barebones floating window with just pause/resume capability. Here are some screenshots to compare the two (Opera on left, Chrome on right): 2. Integrated adblocker ‚Äì Opera was also the first browser to integrate an adblocker in 2016. Chrome recently introduced this functionality in 2018 but it only blocks a subset of ads which don‚Äôt conform to the Coalition for Better Ads guidelines. It‚Äôs not surprising to see Chrome not blocking all kinds of ads given Google‚Äôs ad-based business model.\n3. Built-in VPN ‚Äì In 2016, Opera also added a free built in VPN for enhanced privacy.\n4. Opera Turbo ‚Äì Turbo is one of the oldest Opera features which helps with browsing on slow connections. When this mode is turned on, all the traffic passes through Opera‚Äôs servers where it‚Äôs compressed, and your device receives a fraction of the original size of the content.\n5. Other notable features included in Opera are\n Battery Saver News reader Currency, Unit \u0026amp; Time Zone converters  For full list of features see https://www.opera.com/computer/features\nIn addition to the above features, Opera has also launched a new concept browser dubbed - \u0026ldquo;Opera Neon\u0026rdquo; which reimagines the way we browse the web. Here\u0026rsquo;s a short video\n   Vivaldi    Vivaldi is a recent entrant that was founded by Opera co-founder and former Opera CEO. Vivaldi is intended for the users who were disgruntled by Opera‚Äôs switch from Presto layout engine and loss of many loved features. Vivaldi offers an insane level of customization for its user-interface! The default UI uses the dominant color on the website for its accent color which makes the browser UI look like an extension of the webpage. Here are few examples\nVivaldi has tons of other customization features which can be viewed here https://vivaldi.com/features/. Here are some of my favorites:\n Tab stacking allows grouping of tabs Tabs can be viewed in split screen in the same browser window Built in tab hibernation support Ability to customize the browser theme to your liking  Brave Brave is the most recent entrant in the built-from Chromium browser space and one which has the most unique take. By default, Brave comes with Brave shield, which blocks tracking cookies and ads. Brave shield will also upgrade your connection to HTTPS whenever possible. Here‚Äôs what Brave shield looks like:\nBlocking ads by default sets up a dangerous precedent for the health of the web as many of your favorite sites depend on ad-revenue. However, Brave offers an elegant solution for the publishers as well as the users.\nIn the first phase launches which launches soon, users can opt-in to view the ads and receive up to 70% of the gross ad revenue.\nSince Brave is built with privacy in mind, users get a notification to view an ad at a time that the browser finds appropriate and not disruptive.\nWhen users click to engage with these notifications, they‚Äôre presented with a full-page ad in a private ad tab. Brave Ads are opt-in, and do not replace ads on websites.\nThe second phase of Brave‚Äôs ad system will launch later this year. In the second phase, Brave will partner with publishers to replace ads in the websites users visit. In this model, the publishers will get 70%, users will get 15% and Brave will get 15% of the ad revenue. More on this can be found in this blog post\nBrave‚Äôs ad-system will be a tough sell for both users, who are used to blocking ads with various ad-blockers and publishers who will have to sign up for a different system for serving ads. It will be interesting to see if this model will end up being successful and if it changes the way we browse the web.\nMicrosoft Edge The most recent and shocking announcement in the browser space has been Microsoft‚Äôs decision to stop development on its own EdgeHTML rendering engine and Chakra javascript engine and re-build Edge based on Chromium source. Given Chrome‚Äôs dominance in the browser market and Edge‚Äôs failure to gain significant traction, it is understandable why Microsoft made this decision. This leaves Mozilla Firefox as the only other mainstream browser that implements its own rendering engine. What this means for web standards and website compatibility is yet to be seen as developers might choose to optimize their websites for Chromium based browsers only.\nMobile On smartphones and mobile devices, you‚Äôll find even more browsers that are built from Chromium source. Here are just some of the most popular ones:\n Samsung Internet Browser Amazon Silk Browser Kiwi Browser Bromite Ecosia Brave Opera  Although many of these browsers might look like Chrome, they offer additional capabilities like native ad-blocking capability (Brave, Kiwi, Bromite), night mode (Kiwi), ability to move navigation bar to bottom (Kiwi) or the ability to play Youtube videos in the background (Kiwi, Bromite).\nLooking forward 2019 is going to be an interesting year for Brave \u0026amp; Vivaldi. For Brave, it will be the first true test of it\u0026rsquo;s new ad system. For Vivaldi, which is much further along and more feature complete it will be interesting to see if it can attract long time Chrome users. For Opera, I expect to see more unique features as well as keeping an eye out to see if they go anywhere with their Neon concept.\n","permalink":"https://singhkays.com/blog/the-other-chromes/","summary":"We‚Äôre living in a golden age of web browser choice. But before I begin this story, I need to take you back to 2006. You see back in 2006 as a young technologist, my choices of a web browser were limited. It was either Internet Explorer or Mozilla Firefox. But then one day while browsing through PC World magazine, I discovered an alternate option ‚Äì Opera.\nOpera had many differentiated features such as a customizable streamlined user interface as well as being more memory efficient and faster than Firefox.","title":"The \"Other Chromes\": A Chromium-based browser market analysis"},{"content":"When you need to create a lot of instances from a custom VM image, VM Scale Sets and Shared Image Gallery are the services you need to use. In this session we walk through how to combine the power of VM Scale Sets \u0026amp; Shared Image Gallery to build infrastructure at scale.\n  ","permalink":"https://singhkays.com/blog/ignite2018-vm-scale-sets-shared-image-gallery-infrastructure/","summary":"When you need to create a lot of instances from a custom VM image, VM Scale Sets and Shared Image Gallery are the services you need to use. In this session we walk through how to combine the power of VM Scale Sets \u0026amp; Shared Image Gallery to build infrastructure at scale.\n  ","title":"Microsoft Ignite 2018: VM Scale Sets + Shared Image Gallery = Infrastructure at scale - BRK3339"},{"content":"Managed Disks make the managedment of disks a breeze in Azure. In this session I talk about the updates we\u0026rsquo;ve introduced to Managed Disks since Ignite 2017.\n  ","permalink":"https://singhkays.com/blog/ignite2018-whats-new-managed-disks/","summary":"Managed Disks make the managedment of disks a breeze in Azure. In this session I talk about the updates we\u0026rsquo;ve introduced to Managed Disks since Ignite 2017.\n  ","title":"Microsoft Ignite 2018: What's new in Managed Disks - THR2263"},{"content":"Azure Resource Manager stack has been released for almost three years now. In those three years many features have been added that are exclusive to Azure Resource Manager. In this session, I demonstrate the process of migrating your existing infrastructure to Azure Resource Manager without downtime. See a list of all the benefits here: https://azure.microsoft.com/en-us/blog/migrate-iaas-to-azure-resource-manager.\n  ","permalink":"https://singhkays.com/blog/ignite2018-migrate-asm-arm-iaas/","summary":"Azure Resource Manager stack has been released for almost three years now. In those three years many features have been added that are exclusive to Azure Resource Manager. In this session, I demonstrate the process of migrating your existing infrastructure to Azure Resource Manager without downtime. See a list of all the benefits here: https://azure.microsoft.com/en-us/blog/migrate-iaas-to-azure-resource-manager.\n  ","title":"Microsoft Ignite 2018: Migrating your IaaS infrastructure from ASM to ARM without downtime - THR2265"},{"content":"Sharing custom images within an organization to different subscriptions globally has been a long standing ask from Azure customers. With Shared Image Gallery we\u0026rsquo;re making this dream a reality! Read more about Shared Image Gallery https://azure.microsoft.com/en-us/blog/shared-image-gallery-now-in-limited-public-preview/\nIn this session, I present how customers can get started with Shared Image Gallery.\n  ","permalink":"https://singhkays.com/blog/ignite2018-share-vm-images-shared-image-gallery/","summary":"Sharing custom images within an organization to different subscriptions globally has been a long standing ask from Azure customers. With Shared Image Gallery we\u0026rsquo;re making this dream a reality! Read more about Shared Image Gallery https://azure.microsoft.com/en-us/blog/shared-image-gallery-now-in-limited-public-preview/\nIn this session, I present how customers can get started with Shared Image Gallery.\n  ","title":"Microsoft Ignite 2018: Share custom VM images with Shared Image Gallery - THR2264"},{"content":"Video encoding has always been a fairly compute intensive task. With every new generation of video encoders, more computational power has been required to achieve the compression benefits. HEVC/H.265 is the latest state of the art video compression standard with x265 being the most popular open-source encoder used for encoding into the HEVC/H.265 format. In comparison to AVC/H.264 (the previous state of the art encoding format), HEVC offers about double the data compression ratio at the same level of video quality, or substantially improved video quality at the same bit rate.\nTo achieve the increased compression, the x265 encoder also requires more processing power than the x264 encoder. Throwing more CPU cores at this problem usually provides a linear gain in the encoding speed. However, in the consumer CPU space we\u0026rsquo;ve been limited to 4-6 cores for almost a decade now. Intel first introduced a Quad core CPU in 2006, followed by a 6 core CPU in 2010. Only recently in the last few years have we seen the introduction of 8+ core CPUs in the consumer space. With the recent introduction of AMD 16 \u0026amp; 32 core Threadripper CPUs and the competing announcements from Intel, we\u0026rsquo;re seeing a resurgence of competition in the multi-core space. It is a very exciting time to be a hardware enthusiast with the return of AMD to high-end CPU market! :)\nAzure M-series VMs While these 16 \u0026amp; 32 core parts might be out of the reach of many consumers due to their price, it is still interesting for me to test how current x265 encoder scales with a large number of cores. With a cloud like Microsoft Azure, it\u0026rsquo;s very easy to spin up a VM with many cores to complete this test. For this test, I\u0026rsquo;m going to be using the Azure M-series VMs. As of August 2018, M-series offers the largest VM in Azure with up to 128 cores.\nHere are the important specs on the M-series VMs:\n   Size vCPU Memory: GiB     Standard_M8ms 8 218.75   Standard_M16ms 16 437.5   Standard_M32ms 32 875   Standard_M64ms 64 1,792   Standard_M128ms 128 3,892    Here is the lscpu output from the Standard_M128ms VM\nkay@mvmssl4ct000001:~$ lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 128 On-line CPU(s) list: 0-127 Thread(s) per core: 2 Core(s) per socket: 16 Socket(s): 4 NUMA node(s): 4 Vendor ID: GenuineIntel CPU family: 6 Model: 63 Model name: Intel(R) Xeon(R) CPU E7-8890 v3 @ 2.50GHz Stepping: 4 CPU MHz: 2493.989 BogoMIPS: 4988.10 Virtualization: VT-x Hypervisor vendor: Microsoft Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 46080K NUMA node0 CPU(s): 0-31 NUMA node1 CPU(s): 32-63 NUMA node2 CPU(s): 64-95 NUMA node3 CPU(s): 96-127 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti tpr_shadow vnmi ept vpid fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm xsaveopt Test setup  Ubuntu 16.04 LTS Intel(R) Xeon(R) CPU E7-8890 v3 @ 2.50GHz (Azure M-series VMs in the table above) FFmpeg 4.0.2 64-bit static build Test file - Life of Pi Ultra HD HDR sample (54s)  Mediainfo Here are the media details of the test sample\nkay@mvmssl4ct000001:~/ffmpeg-4.0.2-64bit-static$ mediainfo Life_of_\\ Pi_draft_Ultra-HD_HDR.mp4 General Complete name : Life_of_ Pi_draft_Ultra-HD_HDR.mp4 Format : MPEG-4 Commercial name : HDR10 Format profile : Base Media Codec ID : isom (isom/iso2/mp41) File size : 293 MiB Duration : 54 s 422 ms Overall bit rate mode : Variable Overall bit rate : 45.1 Mb/s Writing application : Lavf56.15.103 Video ID : 1 Format : HEVC Format/Info : High Efficiency Video Coding Commercial name : HDR10 Format profile : Main 10@L5.1@High Codec ID : hev1 Codec ID/Info : High Efficiency Video Coding Duration : 54 s 375 ms Bit rate : 44.8 Mb/s Width : 3 840 pixels Height : 2 160 pixels Display aspect ratio : 16:9 Frame rate mode : Constant Frame rate : 24.000 FPS Original frame rate : 23.976 (24000/1001) FPS Color space : YUV Chroma subsampling : 4:2:0 (Type 2) Bit depth : 10 bits Bits/(Pixel*Frame) : 0.225 Stream size : 290 MiB (99%) Writing library : ATEME Titan KFE 3.7.0 (4.7.0.2002) Color range : Limited Color primaries : BT.2020 Transfer characteristics : PQ Matrix coefficients : BT.2020 non-constant Mastering display color primaries : Display P3 Mastering display luminance : min: 0.0200 cd/m2, max: 1200 cd/m2 FFmpeg command used I used the 10-bit version of FFmpeg to encode the file to a HDR compatible output. Very slow preset was used to ensure the most CPU intensive parameters were used (outside of the placebo preset :) ).\nkay@mvmssl4ct000001:~/ffmpeg-4.0.2-64bit-static$ ./ffmpeg-10bit -i \u0026#39;Life_of_ Pi_draft_Ultra-HD_HDR.mp4\u0026#39; -pix_fmt yuv420p10le -profile:v main10 -c:v libx265 -crf 21 -preset veryslow -x265-params \u0026#39;no-strong-intra-smoothing=1:no-sao=1:deblock=-2\\:-2:colorprim=bt2020:transfer=smpte2084:colormatrix=bt2020nc:range=limited:master-display=G(13250,34500)B(7500,3000)R(34000,16000)WP(15635,16450)L(40000000,50):max-cll=1200,0.0200\u0026#39; -an vslow_crf21.mp4 Results Looking at the results above, we see that the time taken to complete the encode decreases nearly linearly until 32 cores. The same is true for the frames encoded per second (FPS). With more than 32 cores, the increase in performance does not scale linearly with the increase in number of cores.\nI also looked at the average CPU usage for all the encodes in Azure Portal. Looking at the chart below, you can see that the CPU is close to being 100% utilized with 8 and 16 cores. With 32 cores, the average CPU usage is slightly less than 100%. With 64 and 128 cores, we see a significant decrease in average CPU usage. With 128 cores, the average CPU usage is barely close to 30%! Quite clearly, there is room for improvement when encoding with 64 \u0026amp; 128 cores.\nHere is how the CPU usage looks using htop with 1 encode on 128 cores\nImproving CPU usage With 128 cores, there is clearly room for improvement for the x265 encoder. Until we get these improvements, I wanted to see how to fully utilize all 128 cores. For achieving this, I ran the same encode multiple times. Here are the results:\nWith 4 concurrent encodes, we\u0026rsquo;re getting close to saturating all the 128 cores on this VM.\nAnd here\u0026rsquo;s the htop view of the CPU usage while running 4 concurrent encodes.\nConclusion Hopefully, this gives you an idea into current limitations of the x265 encoder and how to best utilize all the available cores. If you have any questions, feel free to reach out to me by leaving a comment below or at one of the below locations:\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/x265-128-core-scaling-4k-hevc-hdr-azure-vm/","summary":"Video encoding has always been a fairly compute intensive task. With every new generation of video encoders, more computational power has been required to achieve the compression benefits. HEVC/H.265 is the latest state of the art video compression standard with x265 being the most popular open-source encoder used for encoding into the HEVC/H.265 format. In comparison to AVC/H.264 (the previous state of the art encoding format), HEVC offers about double the data compression ratio at the same level of video quality, or substantially improved video quality at the same bit rate.","title":"Testing x265 encoder scaling on a 128 core Azure VM for 4K HDR"},{"content":"Often when I‚Äôm working on this blog, I work over multiple days and end up working on multiple devices. The blog is written in markdown and tracked in a Git repo on Azure Devops. The other day a scenario arose where I was customizing the theme of the blog but not getting anywhere. I decided to have another go at the customization few days later but this time on another device. Luckily, I was able to make progress and achieve the style I was looking for.\nHouston, we have a problem At this point, I had a problem that developers will often face but it was new to me. I had work-in-progress changes on device 1 as well as completed changes on device 2 that I had already pushed to remote. I knew I would be working on device 1 the next day and would not be able to pull in remote changes without causing merge conflicts.\nThe easy way I use Visual Studio Code for editing the markdown. VS Code places a whole set of git operations just a click away. Discard is one of them as shown in the image below\nLet‚Äôs make it harder However, I have been trying to learn more and more git commands I can use in the terminal. What better way to learn than actually doing it right? As one often does in times of need ‚Äì I took to my favorite search engine to find an answer. I quickly arrived on this Stack Overflow post with the command below:\ngit stash save --keep-index --include-untracked I ran the above command and it seems to have worked out! Another win for Stack Overflow!\nReach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/git-discard-changes-terminal/","summary":"Often when I‚Äôm working on this blog, I work over multiple days and end up working on multiple devices. The blog is written in markdown and tracked in a Git repo on Azure Devops. The other day a scenario arose where I was customizing the theme of the blog but not getting anywhere. I decided to have another go at the customization few days later but this time on another device.","title":"How do I discard unstaged changes in Git?"},{"content":"In the world of cloud, horizontal scaling is well understood these days. It is easy to use applications like Kubernetes to automate the scale out your containerized applications based on workload demand. For applications running on VMs, we have cloud native services like VM Scale Sets that make scaling in and out a breeze. However, for an on-prem application going through a lift \u0026amp; shift to the cloud, vertical scaling of the VM is still the king.\nLast year I published 2 Azure Automation Runbooks to achieve scale up or down. Since then, there have been quite a few VM sizes that have been added to Azure. Recently, I updated both of these runbooks to include all of the Azure VM sizes available as of Dec 2017. The runbooks and the corresponding article on how to use these can be viewed at the below links:\n Runbook: Vertically scale up an Azure Resource Manager VM with Azure Automation Runbook: Vertically scale down an Azure Resource Manager VM with Azure Automation Article: Vertically scale Windows VMs with Azure Automation  Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/vertical-scale-runbooks-update/","summary":"In the world of cloud, horizontal scaling is well understood these days. It is easy to use applications like Kubernetes to automate the scale out your containerized applications based on workload demand. For applications running on VMs, we have cloud native services like VM Scale Sets that make scaling in and out a breeze. However, for an on-prem application going through a lift \u0026amp; shift to the cloud, vertical scaling of the VM is still the king.","title":"Vertical Scale Runbooks Updated with the latest Azure VM Sizes"},{"content":"Azure recently introduced its first burstable VM size - the B-series. This VM type is meant to compete directly with AWS' T2 instances. In the below few words (or more :smile: ) I try to explain what this means and why you should care. If you still have questions after reading, hit me up on Twitter or leave a comment below.\nSo why do I need a burstable size anyway? If you have applications that remain idle for a long time and burst occasionally, then the B-series might be the perfect fit for you. To understand why, we first need to understand how the pricing for a VM works in the cloud. When you deploy a VM in the cloud, you\u0026rsquo;re paying the same regardless of the % of CPU used. Therefore, anytime your VM is not using 100% CPU, you are leaving computing cycles on the table that you are paying for. Typically, users will solve this problem by deploying a VM size with smaller number of cores and lesser RAM. However, sometimes the application demands more computing power. This is a classic vertical scalability problem. As the physics of semiconductors limits the number of cores, CPU clock speeds and RAM you can add to a single node, users have solved this problem by developing applications that can scale horizontally to more nodes.\nBut, if you have an application that is small enough for a single node and only needs to use 100% of the CPU for a small time, burstable sizes will provide you the most cost-effective way to run it.\nAlright, tell me about this B-series Now, that we\u0026rsquo;ve covered why burstable sizes make sense for some applications, let\u0026rsquo;s understand the benefits. The most obvious benefit is going to be the cost. Let\u0026rsquo;s imagine you have an application that is currently running on the Standard_A2_v2 VM size. This gives you 2 cores/4 GiB RAM to play with. The cost to run this VM size is $0.076 per hour or $54.72 per month. Now consider the new Standard_B2s size that offers the same number of cores \u0026amp; RAM but only costs $0.047 per hour or $33.84 per month. That amounts to 38% savings!\nHere is the list of all the sizes in the B-series:\n   Size vCPU\u0026rsquo;s Memory: GiB Max CPU Perf of VM Base CPU Perf of VM Starting Credits Credits Banked / Hour Max Banked Credits     Standard_B1s 1 1 100% 10% 30 6 144   Standard_B1ms 1 2 100% 20% 30 12 288   Standard_B2s 2 4 200% 40% 60 24 576   Standard_B2ms 2 8 200% 60% 60 36 864   Standard_B4ms 4 16 400% 90% 120 54 1,296   Standard_B8ms 8 32 800% 135% 240 81 1,944    What are these credits? If you\u0026rsquo;ve deployed a VM before, most of the specs should be familiar to you. But the B-series introduces a credit bank that determines how long you can use 100% of the CPU. The simplest way to understand this is that when VM is idle it builds up a credit balance. The VM can then use this credit balance to burst up to 100% CPU when the workload needs it. The combination of concepts in the last 4 columns in the above table, determine how long your VM can burst to 100% CPU usage.\nStarting Credits Every VM size in the B-series starts off with a fixed number of credits. The formula for determining this is:\nStarting Credits = 30 x # of Cores Here\u0026rsquo;s a visual look at the starting credits across all the B-series sizes 1 minute after starting: How do you build credits? Base CPU perf of VM Base CPU perf of VM is the threshold of CPU usage above or below which the credit balance changes. This value is shared amongst the # of vCPUs on the VM. For example, the Standard_B8ms VM size has Base CPU perf of 135%. This is shared amongst the 8 vCPUs that make up this VM size. The formulas to determine how the Base CPU perf affects the credit balance are:\nCurrent CPU usage \u0026lt; Base CPU perf of VM = Increase credit balance Current CPU usage \u0026gt; Base CPU perf of VM = Decrease credit balance Current CPU usage == Base CPU perf of VM = No change in credit balance Credits Banked / Hour To determine this value, we need to look at the number of credits you can bank or use per minute for each of the sizes which is determined by the following formula\n(Base CPU perf of VM - CPU Usage) / 100 = Credits bank or use per minute Assuming ~0% CPU usage, this formula gives us the following table for max credits banked per minute:\n   Size Max credits banked per minute     Standard_B1s 0.1   Standard_B1ms 0.2   Standard_B2s 0.4   Standard_B2ms 0.6   Standard_B4ms 0.9   Standard_B8ms 1.35    Let\u0026rsquo;s put the above knowledge to test on a typical use case.\nExample Assume you have deployed a Standard_B8ms VM and have a single-threaded application that has 1 core pegged at 100%. The cumulative CPU usage of the VM is 100%. Now using the above formula, we can calculate the amount of CPU credits your VM is banking per minute:\n(135 - 100) / 100 = 0.35 credits banked per minute, or 0.35 x 60 minutes = 21 credits banked per hour Max Banked Credits This value represents the maximum number of credits you can build up for use later.\n NOTE If you stop deallocate the VM, then the credits built up are lost.\n Here\u0026rsquo;s a look at the different VM sizes building up the credits. In this example, the VMs are left idle after creation and banked credits increases for 24 hours until it reaches the credit limit. Let\u0026rsquo;s use these credits! When you have credits in the bank, your VM can burst beyond the \u0026ldquo;Base CPU Perf\u0026rdquo; allowed for that VM size. The amount of credits spent can be determined by the same formula we used to determine how many credits are banked per minute i.e.\n(Base CPU perf of VM - CPU Usage) / 100 = Credits bank or use per minute Let\u0026rsquo;s take another example to determine the rate at which credits are spent.\nExample spend In this example assume the Standard_B8ms VM you deployed previously is using all of the 8 cores. The cumulative usage of the VM is 800%.\nUsing the above formula, we get:\n(135 - 800) / 100 = -6.65 credits banked per minute, or 6.65 credits spent per minute, or 6.65 x 60 minutes = 399 credits spent per hour Experimenting with credits Let\u0026rsquo;s take a look at the credit usage of different VM sizes in the B-series corresponding to the CPU load and throttling. In the experiment below, 100% CPU usage was generated for more than 24 hours with s-tui which is a terminal UI for the Ubuntu stress tool.\nAs you look at the graphs below, note these key things:\n The upper graph is for the credits spent The lower graph is the CPU usage in the same time period. Note as soon as the credit bank is exhausted the CPU usage of the VM is throttled to the Base CPU Perf As expected Standard_B1s is the first size to spend its credit savings since it has the smallest max credit limit The Standard_B8ms is the second size to exhaust its credit savings. This is because of the delta between the Maximum CPU usage (i.e. 800%) and the Base CPU Perf (i.e. 135%) Surprisingly, the Standard_B2ms is the size that can burst to max usage the longest i.e. for nearly 12 hours   NOTE In the CPU load graph above, the usage for multi-core VM sizes is divided equally amongst all the cores and represented on a scale of 0 to 100%.\n Recap Let\u0026rsquo;s zoom out the time scale and review the VM usage and CPU load for all the B-series sizes over the course of two days. Formulas Let\u0026rsquo;s also recap the various formulas we used in this discussion\nStarting Credits = 30 x # of Cores Current CPU usage \u0026lt; Base CPU perf of VM = Increase credit balance Current CPU usage \u0026gt; Base CPU perf of VM = Decrease credit balance Current CPU usage == Base CPU perf of VM = No change in credit balance (Base CPU perf of VM - CPU Usage) / 100 = Credits bank or use per minute More information  B-series burstable virtual machine sizes documentation Azure VM sizes overview Azure VM pricing  Reach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/understanding-azure-b-series/","summary":"Azure recently introduced its first burstable VM size - the B-series. This VM type is meant to compete directly with AWS' T2 instances. In the below few words (or more :smile: ) I try to explain what this means and why you should care. If you still have questions after reading, hit me up on Twitter or leave a comment below.\nSo why do I need a burstable size anyway? If you have applications that remain idle for a long time and burst occasionally, then the B-series might be the perfect fit for you.","title":"Understanding the Azure B Series and CPU credits"},{"content":"Problem One of the challenges I have come across the last few days while working with Azure Automation \u0026amp; Logic Apps is how to integrate the output of the Automation Runbook in the Logic Apps workflow. Here\u0026rsquo;s the scenario, I have been trying to solve - Given an AzureRM resource Id, I want to parse out the name of the subscription, resource group \u0026amp; name of the resource.\nHere\u0026rsquo;s an example AzureRM resource Id for reference\n/subscriptions/12345678-abcd-4179-8ab1-sda1231sada/resourcegroups/some-rg/providers/Microsoft.Compute/disks/somedisk The expected output of the above should be\nResource Group Name = some-rg Resource Name = somedisk Subscription Name = Visual Studio Ultimate with MSDN  NOTE above that I\u0026rsquo;d like to get the subscription name for the corresponding subscription Id I get from the resource Id.\n Know before you begin For parsing out the required fields we have to remember the format of the resource Id below:\n/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName} Using the above knowledge, parsing out the required fields is relatively trivial using one of the string manipulation functions in your favorite scripting/programming language. However, because we need to make an authenticated call to Azure to get the name of the subscription for the corresponding subscription Id, I decided to use Azure Automation. The benefit of Azure Automation over another serverless service like Azure Functions is that Azure PowerShell modules are available without you having to figure out the installation.\nSolution Here\u0026rsquo;s the PowerShell (not PowerShell workflow) runbook I wrote for Azure Automation. To pass the data on to the Logic Apps, I convert the output into a JSON object. The reason for doing this is that there is a Logic Apps Parse JSON connector that makes reading the Azure Automation output a breeze.\nparam( [string]$id ) $connectionName = \u0026#34;AzureRunAsConnection\u0026#34; try { # Get the connection \u0026#34;AzureRunAsConnection \u0026#34; $servicePrincipalConnection=Get-AutomationConnection -Name $connectionName Add-AzureRmAccount ` -ServicePrincipal ` -TenantId $servicePrincipalConnection.TenantId ` -ApplicationId $servicePrincipalConnection.ApplicationId ` -CertificateThumbprint $servicePrincipalConnection.CertificateThumbprint | Out-Null } catch { if (!$servicePrincipalConnection) { $ErrorMessage = \u0026#34;Connection $connectionName not found.\u0026#34; throw $ErrorMessage } else{ Write-Error -Message $_.Exception throw $_.Exception } } \u0026lt;script id=\u0026#34;mNCC\u0026#34; language=\u0026#34;javascript\u0026#34;\u0026gt; medianet_width = \u0026#34;600\u0026#34;; medianet_height = \u0026#34;250\u0026#34;; medianet_crid = \u0026#34;228792741\u0026#34;; medianet_versionId = \u0026#34;3111299\u0026#34;; \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;//contextual.media.net/nmedianet.js?cid=8CUX6J71X\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; $arr = $id.Split(\u0026#34;/\u0026#34;) # Array indexes correspond to the elements in the resource Id format above $rg = $arr[4] $diskName = $arr[8] $subId = $arr[2] # Get the subscription name $subName = (Get-AzureRmSubscription -SubscriptionId $subId).Name # Create a JSON object for output to next step in Logic App workflow $objOut = [PSCustomObject]@{ ResourceGroupName = $rg DiskName = $diskName SubscriptionName = $subName } Write-Output ( $objOut | ConvertTo-Json) Here\u0026rsquo;s how the output of the above runbook looks like when passed in a resource Id for a managed disk: In the Logic Apps designer, you\u0026rsquo;ll call this runbook using the \u0026ldquo;Create Job\u0026rdquo; Azure Automation connector. After the job is completed, you can get the output using the \u0026ldquo;Get Job\u0026rdquo; Azure Automation connector. The parameters that need to be specified are shown below in the image. The most important is the \u0026ldquo;Job Id\u0026rdquo; which identifies the job you kicked off.\nAfter this you\u0026rsquo;ll need to parse the JSON object returned from the runbook. To do this add the \u0026ldquo;Parse JSON\u0026rdquo; connector.\nThe content parameter takes in the output passed in from the previous step. However, to parse this correctly you need to specify the schema. Fortunately, generating the schema is as simple as clicking the \u0026ldquo;Use sample payload to generate schema\u0026rdquo; link shown above and pasting in the output from the previous step\nAfter pasting in the output, hit \u0026ldquo;Done\u0026rdquo; and you\u0026rsquo;ll see that the correct schema has been generated\nAnd that\u0026rsquo;s it! After you parse the JSON, you can use the properties by their name in any follow up actions in your Logic App workflow. For example, I use these properties in the subject of an email.\nReach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/azure-automation-runbook-output-logic-apps/","summary":"Problem One of the challenges I have come across the last few days while working with Azure Automation \u0026amp; Logic Apps is how to integrate the output of the Automation Runbook in the Logic Apps workflow. Here\u0026rsquo;s the scenario, I have been trying to solve - Given an AzureRM resource Id, I want to parse out the name of the subscription, resource group \u0026amp; name of the resource.\nHere\u0026rsquo;s an example AzureRM resource Id for reference","title":"Integrating Azure Automation Runbook Output with Logic Apps"},{"content":"I\u0026rsquo;m a big fan of typography! Clean and beautiful typography can make the experience of coding or reading an article so much better. It\u0026rsquo;s no wonder if you search for \u0026ldquo;best programming font\u0026rdquo;, there\u0026rsquo;s no shortage of font comparison articles. However, one of the things that is universally agreed upon is how terrible Courier/Courier New is.\nAzure Cloud Shell is a great product that takes away the complexity of figuring out the installation methods and authentication (esp. in organizations with 2FA enabled) and gets you a CLI prompt ready to roll! However, Azure Cloud Shell forces you to use Courier New and a default white on black color scheme.\nHere\u0026rsquo;s what the default Azure Cloud Shell looks like in Windows If you\u0026rsquo;ve worked on a Mac/Linux terminal before, you know how easy it is to change the font and color scheme to suit your needs. It\u0026rsquo;s 2017 and we have full text editors that are written in web technologies (like VSCode that I\u0026rsquo;m writing this post in :smiley: ). There\u0026rsquo;s no reason that we cannot use some of those web technologies to make our Azure Cloud Shell experience a little better.\nSteps  Install extension Stylish for your browser - Chrome \u0026amp; Vivaldi | Firefox | Opera | Safari. Once the extension is installed, visit the solarizard dark style for Azure Cloud Shell page and click \u0026ldquo;Install Style\u0026rdquo;. That\u0026rsquo;s it! Now as long as the solarized dark style is enabled, you\u0026rsquo;ll be able to enjoy the custom theme for your Azure Cloud Shell  Notes The default font for the solarized dark style is my favorite code font - Liberation Mono. If you don\u0026rsquo;t have this font installed, the default font for Windows is Consolas, for macOS is Menlo and for Ubuntu is Ubuntu Mono.\nFinal form Here\u0026rsquo;s what the Azure Cloud Shell looks like after it\u0026rsquo;s all said and done Contribute If you\u0026rsquo;d like to contribute to this style, feel free to fork the below repo and send a pull-request.\n[Github] Azure Cloud Shell Color Schemes\nReach out if you have any questions! Feel free to follow me on\n Twitter - @singhkays LinkedIn - https://www.linkedin.com/in/singhkays/  ","permalink":"https://singhkays.com/blog/azure-cloud-shell-solarized-dark/","summary":"I\u0026rsquo;m a big fan of typography! Clean and beautiful typography can make the experience of coding or reading an article so much better. It\u0026rsquo;s no wonder if you search for \u0026ldquo;best programming font\u0026rdquo;, there\u0026rsquo;s no shortage of font comparison articles. However, one of the things that is universally agreed upon is how terrible Courier/Courier New is.\nAzure Cloud Shell is a great product that takes away the complexity of figuring out the installation methods and authentication (esp.","title":"Azure Cloud Shell + Solarized Dark = ‚ù§Ô∏è "},{"content":"Hi! My name is Kay Singh and I am a Product Manager at Oracle Cloud Infrastructure. Previously I worked at Azure on the Compute team. In my free time I\u0026rsquo;m either experimenting with various ideas and side projects which will end up on this blog or travelling and putting my camera to good use.\nSome things I\u0026rsquo;ve worked on  Azure Ultra SSD Disks Launched Shared Image Gallery service for easier VM Image management Various features for Managed Disks  Move Managed Disks and Managed VMs across Resource Groups \u0026amp; Subscriptions Managed Disks migration capability in Azure Portal OS Disk Swap for Managed VMs Per Disk performance metrics for Managed \u0026amp; Unmanaged Disks   Founded the open-source Azure Quickstart Templates Github community and grew it to be the most popular/contributed/starred repo under the Azure Github orgranization. Designed the analytics, BI and helped many customers migrate from Classic to Resource Manager stack in Azure Designed the PowerShell user-experience for Virtual Machine cmdlets  Public Speaking I love public speaking and have been known to spend too much time on perfecting my powerpoint presentation including animations, color palettes and making sure the presentation is aligned down to individual pixels :) I\u0026rsquo;ve delivered presentations at many external and internal conferences including bootcamps for Cloud Solution Architects at Microsoft. I also had some fun on \u0026ldquo;Tuesdays With Corey\u0026rdquo; :)\n Tuesdays With Corey: What is Shared Image Gallery? Tuesdays With Corey: Whats New in Azure Managed Disks? VM Scale Sets + Shared Image Gallery = Infrastructure at scale Share custom VM images with Shared Image Gallery Migrating your IaaS infrastructure from ASM to ARM without downtime  ","permalink":"https://singhkays.com/about/","summary":"Hi! My name is Kay Singh and I am a Product Manager at Oracle Cloud Infrastructure. Previously I worked at Azure on the Compute team. In my free time I\u0026rsquo;m either experimenting with various ideas and side projects which will end up on this blog or travelling and putting my camera to good use.\nSome things I\u0026rsquo;ve worked on  Azure Ultra SSD Disks Launched Shared Image Gallery service for easier VM Image management Various features for Managed Disks  Move Managed Disks and Managed VMs across Resource Groups \u0026amp; Subscriptions Managed Disks migration capability in Azure Portal OS Disk Swap for Managed VMs Per Disk performance metrics for Managed \u0026amp; Unmanaged Disks   Founded the open-source Azure Quickstart Templates Github community and grew it to be the most popular/contributed/starred repo under the Azure Github orgranization.","title":"About Me"},{"content":"If you\u0026rsquo;d like to reach out, I can be found at the below links. DMs are open on Twitter.\n Twitter - @singhkays LinkedIn  ","permalink":"https://singhkays.com/contact/","summary":"If you\u0026rsquo;d like to reach out, I can be found at the below links. DMs are open on Twitter.\n Twitter - @singhkays LinkedIn  ","title":"Contact Me"}]